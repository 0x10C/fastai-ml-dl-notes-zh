<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></head><body><pre name="6259" id="6259" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">SaveFeatures</strong>():<br>    features=<strong class="markup--strong markup--pre-strong">None</strong><br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, m):<br>        self.hook = m.register_forward_hook(self.hook_fn)<br>    <strong class="markup--strong markup--pre-strong">def</strong> hook_fn(self, module, input, output): self.features = output<br>    <strong class="markup--strong markup--pre-strong">def</strong> remove(self): self.hook.remove()</pre><p name="b8f8" id="b8f8" class="graf graf--p graf-after--pre">So we are basically going to start with <code class="markup--code markup--p-code">get_base</code> [<a href="https://youtu.be/nG3tT31nPmQ?t=1h50m37s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h50m37s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:50:37</a>]. Base is our base network and that was defined back up in the first section.</p><figure name="1288" id="1288" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_BDJmGsOK8kX9gHUyiQ3Xgw.png"></figure><p name="a160" id="a160" class="graf graf--p graf-after--figure">So get_base is going to be something that calls whatever f is and <code class="markup--code markup--p-code">f</code> is <code class="markup--code markup--p-code">resnet34</code>. So we are going to grab our ResNet34 and cut_model is the first thing that our convnet builder does. It basically removes everything from the adaptive pooling onwards, so that gives us back the backbone of ResNet34. So <code class="markup--code markup--p-code">get_base</code> is going to give us back the ResNet34 backbone.</p><pre name="dfdb" id="dfdb" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">UnetBlock</strong>(nn.Module):<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, up_in, x_in, n_out):<br>        super().__init__()<br>        up_out = x_out = n_out//2<br>        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)<br>        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, <br>                                          stride=2)<br>        self.bn = nn.BatchNorm2d(n_out)<br>        <br>    <strong class="markup--strong markup--pre-strong">def</strong> forward(self, up_p, x_p):<br>        up_p = self.tr_conv(up_p)<br>        x_p = self.x_conv(x_p)<br>        cat_p = torch.cat([up_p,x_p], dim=1)<br>        <strong class="markup--strong markup--pre-strong">return</strong> self.bn(F.relu(cat_p))</pre><pre name="b098" id="b098" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">Unet34</strong>(nn.Module):<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, rn):<br>        super().__init__()<br>        self.rn = rn<br>        self.sfs = [SaveFeatures(rn[i]) <strong class="markup--strong markup--pre-strong">for</strong> i <strong class="markup--strong markup--pre-strong">in</strong> [2,4,5,6]]<br>        self.up1 = UnetBlock(512,256,256)<br>        self.up2 = UnetBlock(256,128,256)<br>        self.up3 = UnetBlock(256,64,256)<br>        self.up4 = UnetBlock(256,64,256)<br>        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)<br>        <br>    <strong class="markup--strong markup--pre-strong">def</strong> forward(self,x):<br>        x = F.relu(self.rn(x))<br>        x = self.up1(x, self.sfs[3].features)<br>        x = self.up2(x, self.sfs[2].features)<br>        x = self.up3(x, self.sfs[1].features)<br>        x = self.up4(x, self.sfs[0].features)<br>        x = self.up5(x)<br>        <strong class="markup--strong markup--pre-strong">return</strong> x[:,0]<br>    <br>    <strong class="markup--strong markup--pre-strong">def</strong> close(self):<br>        <strong class="markup--strong markup--pre-strong">for</strong> sf <strong class="markup--strong markup--pre-strong">in</strong> self.sfs: sf.remove()</pre><pre name="1a9f" id="1a9f" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">UnetModel</strong>():<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self,model,name='unet'):<br>        self.model,self.name = model,name<br><br>    <strong class="markup--strong markup--pre-strong">def</strong> get_layer_groups(self, precompute):<br>        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))<br>        <strong class="markup--strong markup--pre-strong">return</strong> lgs + [children(self.model)[1:]]</pre><p name="0992" id="0992" class="graf graf--p graf-after--pre">Then we are going to take that ResNet34 backbone and turn it into a, I call it a, Unet34 [<a href="https://youtu.be/nG3tT31nPmQ?t=1h51m17s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h51m17s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:51:17</a>]. So what that’s going to do is it’s going to save that ResNet that we passed in and then we are going to use a forward hook just like before to save the results at the 2nd, 4th, 5th, and 6th blocks which as before is the layers before each stride 2 convolution. Then we are going to create a bunch of these things we are calling <code class="markup--code markup--p-code">UnetBlock</code>. We need to tell <code class="markup--code markup--p-code">UnetBlock</code> how many things are coming from the previous layer we are upsampling, how many are coming across, and then how many do we want to come out. The amount coming across is entirely defined by whatever the base network was — whatever the downward path was, we need that many layers. So this is a little bit awkward. Actually one of our master’s students here, Kerem, has actually created something called DynamicUnet that you’ll find in <a href="https://github.com/fastai/fastai/blob/d3ef60a96cddf5b503361ed4c95d68dda4a873fc/fastai/models/unet.py#L53" data-href="https://github.com/fastai/fastai/blob/d3ef60a96cddf5b503361ed4c95d68dda4a873fc/fastai/models/unet.py#L53" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">fastai.model.DynamicUnet</a> and it actually calculates this all for you and automatically creates the whole Unet from your base model. It’s got some minor quirks still that I want to fix. By the time the video is out, it’ll definitely be working and I will at least have a notebook showing how to use it and possibly an additional video. But for now you’ll just have to go through and do it yourself. You can easily see it just by, once you’ve got a ResNet, you can just type in its name and it’ll print out the layers. And you can see how many many activations there are in each block. Or you can have it printed out for you for each block automatically. Anyway, I just did this manually.</p><figure name="cfb4" id="cfb4" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_uJ4edTfPiSXfCXkFQ82Svg.png"></figure><p name="673e" id="673e" class="graf graf--p graf-after--figure">So the UnetBlock works like this [<a href="https://youtu.be/nG3tT31nPmQ?t=1h53m29s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h53m29s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:53:29</a>]:</p><ul class="postList"><li name="f390" id="f390" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">up_in</code>&nbsp;: This many are coming up from the previous layer</li><li name="9340" id="9340" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">x_in</code>&nbsp;: This many are coming across (hence <code class="markup--code markup--li-code">x</code>) from the downward path</li><li name="cb92" id="cb92" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">n_out</code>&nbsp;: The amount we want coming out</li></ul><p name="3d2e" id="3d2e" class="graf graf--p graf-after--li">Now what I do is&nbsp;, I then say, okay we’re going to create a certain amount of convolutions from the upward path and a certain amount from the cross path, and so I’m going to be concatenating them together so let’s divide the number we want out by 2. And so we are going to have our cross convolution take our cross path and create number out divided by 2 (<code class="markup--code markup--p-code">n_out//2</code>). And then the upward path is going to be a <code class="markup--code markup--p-code">ConvTranspose2d</code> because we want to increase/upsample. Again here, we’ve got the number out divided by 2 (<code class="markup--code markup--p-code">up_out</code>), then at the end, I just concatenate those together.</p><p name="7b32" id="7b32" class="graf graf--p graf-after--p">So I’ve got an upward sample, I’ve got a cross convolution, I can concatenate the two together. That’s all a UnetBlock is. So that’s actually a pretty easy module to create.</p><figure name="263d" id="263d" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_cXPJlacjby171FsaalyHcQ.png"></figure><p name="e27e" id="e27e" class="graf graf--p graf-after--figure">Then in my forward path, I need to pass to the forward of the UnetBlock the upward path and the cross path [<a href="https://youtu.be/nG3tT31nPmQ?t=1h54m40s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h54m40s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:54:40</a>]. The upward path is just whatever I am up to so far. But then the cross path is whatever the activations are that I stored on the way down. So as I come up, it’s the last set of saved features that I need first. And as I gradually keep going up farther and farther, eventually it’s the first set of features.</p><p name="7037" id="7037" class="graf graf--p graf-after--p">There are some more tricks we can do to make this a little bit better, but this is a good stuff. So the simple upsampling approach looked horrible and had a dice of&nbsp;.968. A Unet with everything else identical except we’ve now got these UnetBlocks has a dice of&nbsp;…</p><pre name="93b4" id="93b4" class="graf graf--pre graf-after--p">m_base = get_base()<br>m = to_gpu(Unet34(m_base))<br>models = UnetModel(m)</pre><pre name="baf5" id="baf5" class="graf graf--pre graf-after--pre">learn = ConvLearner(md, models)<br>learn.opt_fn=optim.Adam<br>learn.crit=nn.BCEWithLogitsLoss()<br>learn.metrics=[accuracy_thresh(0.5),dice]</pre><pre name="daf1" id="daf1" class="graf graf--pre graf-after--pre">learn.summary()</pre><pre name="8032" id="8032" class="graf graf--pre graf-after--pre">OrderedDict([('Conv2d-1',<br>              OrderedDict([('input_shape', [-1, 3, 128, 128]),<br>                           ('output_shape', [-1, 64, 64, 64]),<br>                           ('trainable', False),<br>                           ('nb_params', 9408)])),<br>             ('BatchNorm2d-2',<br>              OrderedDict([('input_shape', [-1, 64, 64, 64]),<br>                           ('output_shape', [-1, 64, 64, 64]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-3',<br>              OrderedDict([('input_shape', [-1, 64, 64, 64]),<br>                           ('output_shape', [-1, 64, 64, 64]),<br>                           ('nb_params', 0)])),<br>             ('MaxPool2d-4',<br>              OrderedDict([('input_shape', [-1, 64, 64, 64]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-5',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 36864)])),<br>             ('BatchNorm2d-6',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-7',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-8',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 36864)])),<br>             ('BatchNorm2d-9',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-10',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-11',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-12',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 36864)])),<br>             ('BatchNorm2d-13',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-14',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-15',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 36864)])),<br>             ('BatchNorm2d-16',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-17',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-18',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-19',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 36864)])),<br>             ('BatchNorm2d-20',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-21',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-22',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 36864)])),<br>             ('BatchNorm2d-23',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-24',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-25',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-26',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 73728)])),<br>             ('BatchNorm2d-27',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-28',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-29',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-30',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('Conv2d-31',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 8192)])),<br>             ('BatchNorm2d-32',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-33',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-34',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-35',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-36',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-37',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-38',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-39',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-40',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-41',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-42',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-43',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-44',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-45',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-46',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-47',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-48',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-49',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-50',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-51',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-52',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-53',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-54',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-55',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-56',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 294912)])),<br>             ('BatchNorm2d-57',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-58',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-59',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-60',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('Conv2d-61',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 32768)])),<br>             ('BatchNorm2d-62',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-63',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-64',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-65',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-66',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-67',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-68',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-69',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-70',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-71',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-72',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-73',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-74',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-75',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-76',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-77',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-78',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-79',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-80',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-81',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-82',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-83',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-84',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-85',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-86',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-87',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-88',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-89',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-90',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-91',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-92',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-93',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-94',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-95',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-96',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-97',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-98',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-99',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-100',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1179648)])),<br>             ('BatchNorm2d-101',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('ReLU-102',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-103',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 2359296)])),<br>             ('BatchNorm2d-104',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('Conv2d-105',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 131072)])),<br>             ('BatchNorm2d-106',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('ReLU-107',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-108',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-109',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 2359296)])),<br>             ('BatchNorm2d-110',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('ReLU-111',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-112',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 2359296)])),<br>             ('BatchNorm2d-113',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('ReLU-114',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-115',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-116',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 2359296)])),<br>             ('BatchNorm2d-117',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('ReLU-118',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-119',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 2359296)])),<br>             ('BatchNorm2d-120',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('ReLU-121',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-122',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('ConvTranspose2d-123',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 128, 8, 8]),<br>                           ('trainable', True),<br>                           ('nb_params', 262272)])),<br>             ('Conv2d-124',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 128, 8, 8]),<br>                           ('trainable', True),<br>                           ('nb_params', 32896)])),<br>             ('BatchNorm2d-125',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', True),<br>                           ('nb_params', 512)])),<br>             ('UnetBlock-126',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('ConvTranspose2d-127',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', True),<br>                           ('nb_params', 131200)])),<br>             ('Conv2d-128',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', True),<br>                           ('nb_params', 16512)])),<br>             ('BatchNorm2d-129',<br>              OrderedDict([('input_shape', [-1, 256, 16, 16]),<br>                           ('output_shape', [-1, 256, 16, 16]),<br>                           ('trainable', True),<br>                           ('nb_params', 512)])),<br>             ('UnetBlock-130',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('ConvTranspose2d-131',<br>              OrderedDict([('input_shape', [-1, 256, 16, 16]),<br>                           ('output_shape', [-1, 128, 32, 32]),<br>                           ('trainable', True),<br>                           ('nb_params', 131200)])),<br>             ('Conv2d-132',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 128, 32, 32]),<br>                           ('trainable', True),<br>                           ('nb_params', 8320)])),<br>             ('BatchNorm2d-133',<br>              OrderedDict([('input_shape', [-1, 256, 32, 32]),<br>                           ('output_shape', [-1, 256, 32, 32]),<br>                           ('trainable', True),<br>                           ('nb_params', 512)])),<br>             ('UnetBlock-134',<br>              OrderedDict([('input_shape', [-1, 256, 16, 16]),<br>                           ('output_shape', [-1, 256, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('ConvTranspose2d-135',<br>              OrderedDict([('input_shape', [-1, 256, 32, 32]),<br>                           ('output_shape', [-1, 128, 64, 64]),<br>                           ('trainable', True),<br>                           ('nb_params', 131200)])),<br>             ('Conv2d-136',<br>              OrderedDict([('input_shape', [-1, 64, 64, 64]),<br>                           ('output_shape', [-1, 128, 64, 64]),<br>                           ('trainable', True),<br>                           ('nb_params', 8320)])),<br>             ('BatchNorm2d-137',<br>              OrderedDict([('input_shape', [-1, 256, 64, 64]),<br>                           ('output_shape', [-1, 256, 64, 64]),<br>                           ('trainable', True),<br>                           ('nb_params', 512)])),<br>             ('UnetBlock-138',<br>              OrderedDict([('input_shape', [-1, 256, 32, 32]),<br>                           ('output_shape', [-1, 256, 64, 64]),<br>                           ('nb_params', 0)])),<br>             ('ConvTranspose2d-139',<br>              OrderedDict([('input_shape', [-1, 256, 64, 64]),<br>                           ('output_shape', [-1, 1, 128, 128]),<br>                           ('trainable', True),<br>                           ('nb_params', 1025)]))])</pre><pre name="35de" id="35de" class="graf graf--pre graf-after--pre">[o.features.size() <strong class="markup--strong markup--pre-strong">for</strong> o <strong class="markup--strong markup--pre-strong">in</strong> m.sfs]</pre><pre name="9db4" id="9db4" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[torch.Size([3, 64, 64, 64]),<br> torch.Size([3, 64, 32, 32]),<br> torch.Size([3, 128, 16, 16]),<br> torch.Size([3, 256, 8, 8])]</em></pre><pre name="26ea" id="26ea" class="graf graf--pre graf-after--pre">learn.freeze_to(1)</pre><pre name="ff8d" id="ff8d" class="graf graf--pre graf-after--pre">learn.lr_find()<br>learn.sched.plot()</pre><pre name="93a7" id="93a7" class="graf graf--pre graf-after--pre"> 0%|                                                                                           | 0/64 [00:00&lt;?, ?it/s]</pre><pre name="597f" id="597f" class="graf graf--pre graf-after--pre">92%|█████████████████████████████████████████████████████████████████▍     | 59/64 [00:22&lt;00:01,  2.68it/s, loss=2.45]</pre><figure name="ed74" id="ed74" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_kSXmrtfSNjvDnBoLEAiUaw.png"></figure><pre name="b1ac" id="b1ac" class="graf graf--pre graf-after--figure">lr=4e-2<br>wd=1e-7<br><br>lrs = np.array([lr/100,lr/10,lr])</pre><pre name="f56f" id="f56f" class="graf graf--pre graf-after--pre">learn.fit(lr,1,wds=wd,cycle_len=8,use_clr=(5,8))</pre><pre name="1e40" id="1e40" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">epoch      trn_loss   val_loss   &lt;lambda&gt;   dice           <br>    0      0.12936    0.03934    0.988571   0.971385  <br>    1      0.098401   0.039252   0.990438   0.974921        <br>    2      0.087789   0.02539    0.990961   0.978927        <br>    3      0.082625   0.027984   0.988483   0.975948        <br>    4      0.079509   0.025003   0.99171    0.981221        <br>    5      0.076984   0.022514   0.992462   0.981881        <br>    6      0.076822   0.023203   0.992484   0.982321        <br>    7      0.075488   0.021956   0.992327   0.982704</em></pre><pre name="a505" id="a505" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[0.021955982234979434, 0.9923273126284281, 0.9827044502137199]</em></pre><pre name="f074" id="f074" class="graf graf--pre graf-after--pre">learn.save('128urn-tmp')</pre><pre name="0b41" id="0b41" class="graf graf--pre graf-after--pre">learn.load('128urn-tmp')</pre><pre name="b057" id="b057" class="graf graf--pre graf-after--pre">learn.unfreeze()<br>learn.bn_freeze(<strong class="markup--strong markup--pre-strong">True</strong>)</pre><pre name="0ee9" id="0ee9" class="graf graf--pre graf-after--pre">learn.fit(lrs/4, 1, wds=wd, cycle_len=20,use_clr=(20,10))</pre><pre name="c6bd" id="c6bd" class="graf graf--pre graf-after--pre">0%|          | 0/64 [00:00&lt;?, ?it/s]<br>epoch      trn_loss   val_loss   &lt;lambda&gt;   dice            <br>    0      0.073786   0.023418   0.99297    0.98283   <br>    1      0.073561   0.020853   0.992142   0.982725        <br>    2      0.075227   0.023357   0.991076   0.980879        <br>    3      0.074245   0.02352    0.993108   0.983659        <br>    4      0.073434   0.021508   0.993024   0.983609        <br>    5      0.073092   0.020956   0.993188   0.983333        <br>    6      0.073617   0.019666   0.993035   0.984102        <br>    7      0.072786   0.019844   0.993196   0.98435         <br>    8      0.072256   0.018479   0.993282   0.984277        <br>    9      0.072052   0.019479   0.993164   0.984147        <br>    10     0.071361   0.019402   0.993344   0.984541        <br>    11     0.070969   0.018904   0.993139   0.984499        <br>    12     0.071588   0.018027   0.9935     0.984543        <br>    13     0.070709   0.018345   0.993491   0.98489         <br>    14     0.072238   0.019096   0.993594   0.984825        <br>    15     0.071407   0.018967   0.993446   0.984919        <br>    16     0.071047   0.01966    0.993366   0.984952        <br>    17     0.072024   0.018133   0.993505   0.98497         <br>    18     0.071517   0.018464   0.993602   0.985192        <br>    19     0.070109   0.018337   0.993614   0.9852</pre><pre name="aabb" id="aabb" class="graf graf--pre graf-after--pre">[0.018336569653853538, 0.9936137114252362, 0.9852004420189631]</pre><p name="df93" id="df93" class="graf graf--p graf-after--pre">.985! That’s like we halved the error with everything else exactly the same [<a href="https://youtu.be/nG3tT31nPmQ?t=1h55m42s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h55m42s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:55:42</a>]. And more the point, you can look at it.</p><pre name="f648" id="f648" class="graf graf--pre graf-after--p">learn.save('128urn-0')</pre><pre name="a362" id="a362" class="graf graf--pre graf-after--pre">learn.load('128urn-0')</pre><pre name="2295" id="2295" class="graf graf--pre graf-after--pre">x,y = next(iter(md.val_dl))<br>py = to_np(learn.model(V(x)))</pre><p name="c62d" id="c62d" class="graf graf--p graf-after--pre">This is actually looking somewhat car-like compared to our non-Unet equivalent which is just a blob. Because trying to do this through down and up paths — it’s just asking too much. Where else, when we actually provide the downward path pixels at every point, it can actually start to create something car-ish.</p><pre name="8a8b" id="8a8b" class="graf graf--pre graf-after--p">show_img(py[0]&gt;0);</pre><figure name="5bae" id="5bae" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_AuMRaTQP4gCUW0iHHvf2uQ.png"></figure><pre name="c36b" id="c36b" class="graf graf--pre graf-after--figure">show_img(y[0]);</pre><figure name="2dba" id="2dba" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_SHntdwiyRvupP9SQO5BD5g.png"></figure><p name="e9a3" id="e9a3" class="graf graf--p graf-after--figure">At the end of that, we’ll do m.close to remove those <code class="markup--code markup--p-code">sfs.features</code> taking up GPU memory.</p><pre name="426d" id="426d" class="graf graf--pre graf-after--p">m.close()</pre><h4 name="f39c" id="f39c" class="graf graf--h4 graf-after--pre">512x512 [<a href="https://youtu.be/nG3tT31nPmQ?t=1h56m26s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h56m26s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:56:26</a>]</h4><p name="09ca" id="09ca" class="graf graf--p graf-after--h4">Go to a smaller batch size, higher size</p><pre name="9e81" id="9e81" class="graf graf--pre graf-after--p">sz=512<br>bs=16</pre><pre name="6b68" id="6b68" class="graf graf--pre graf-after--pre">tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO, <br>                       tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)<br>datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), <br>                            (val_x,val_y), tfms, path=PATH)<br>md = ImageData(PATH, datasets, bs, num_workers=4, classes=<strong class="markup--strong markup--pre-strong">None</strong>)<br>denorm = md.trn_ds.denorm</pre><pre name="134a" id="134a" class="graf graf--pre graf-after--pre">m_base = get_base()<br>m = to_gpu(Unet34(m_base))<br>models = UnetModel(m)</pre><pre name="2824" id="2824" class="graf graf--pre graf-after--pre">learn = ConvLearner(md, models)<br>learn.opt_fn=optim.Adam<br>learn.crit=nn.BCEWithLogitsLoss()<br>learn.metrics=[accuracy_thresh(0.5),dice]</pre><pre name="3395" id="3395" class="graf graf--pre graf-after--pre">learn.freeze_to(1)</pre><pre name="653f" id="653f" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">learn.load('128urn-0')</strong></pre><pre name="397d" id="397d" class="graf graf--pre graf-after--pre">learn.fit(lr,1,wds=wd, cycle_len=5,use_clr=(5,5))</pre><pre name="6be3" id="6be3" class="graf graf--pre graf-after--pre">epoch      trn_loss   val_loss   &lt;lambda&gt;   dice              <br>    0      0.071421   0.02362    0.996459   0.991772  <br>    1      0.070373   0.014013   0.996558   0.992602          <br>    2      0.067895   0.011482   0.996705   0.992883          <br>    3      0.070653   0.014256   0.996695   0.992771          <br>    4      0.068621   0.013195   0.996993   0.993359</pre><pre name="1bbb" id="1bbb" class="graf graf--pre graf-after--pre">[0.013194938530288046, 0.996993034604996, 0.993358936574724]</pre><p name="eda9" id="eda9" class="graf graf--p graf-after--pre">You can see the dice coefficients really going up [<a href="https://youtu.be/nG3tT31nPmQ?t=1h56m30s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h56m30s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:56:30</a>]. So notice above, I’m loading in the 128x128 version of the network. We are doing this progressive resizing trick again, so that gets us&nbsp;.993.</p><pre name="e673" id="e673" class="graf graf--pre graf-after--p">learn.save('512urn-tmp')</pre><pre name="81f0" id="81f0" class="graf graf--pre graf-after--pre">learn.unfreeze()<br>learn.bn_freeze(<strong class="markup--strong markup--pre-strong">True</strong>)</pre><pre name="c937" id="c937" class="graf graf--pre graf-after--pre">learn.load('512urn-tmp')</pre><pre name="a246" id="a246" class="graf graf--pre graf-after--pre">learn.fit(lrs/4,1,wds=wd, cycle_len=8,use_clr=(20,8))</pre><pre name="ad71" id="ad71" class="graf graf--pre graf-after--pre">epoch      trn_loss   val_loss   &lt;lambda&gt;   dice              <br>    0      0.06605    0.013602   0.997      0.993014  <br>    1      0.066885   0.011252   0.997248   0.993563          <br>    2      0.065796   0.009802   0.997223   0.993817          <br>    3      0.065089   0.009668   0.997296   0.993744          <br>    4      0.064552   0.011683   0.997269   0.993835          <br>    5      0.065089   0.010553   0.997415   0.993827          <br>    6      0.064303   0.009472   0.997431   0.994046          <br>    7      0.062506   0.009623   0.997441   0.994118</pre><pre name="c98d" id="c98d" class="graf graf--pre graf-after--pre">[0.009623114736602894, 0.9974409020136273, 0.9941179137381296]</pre><p name="41d2" id="41d2" class="graf graf--p graf-after--pre">Then unfreeze to get to&nbsp;.994.</p><pre name="57bc" id="57bc" class="graf graf--pre graf-after--p">learn.save('512urn')</pre><pre name="eaeb" id="eaeb" class="graf graf--pre graf-after--pre">learn.load('512urn')</pre><pre name="2914" id="2914" class="graf graf--pre graf-after--pre">x,y = next(iter(md.val_dl))<br>py = to_np(learn.model(V(x)))</pre><p name="052f" id="052f" class="graf graf--p graf-after--pre">And you can see, it’s now looking pretty good.</p><pre name="dda0" id="dda0" class="graf graf--pre graf-after--p">show_img(py[0]&gt;0);</pre><figure name="2e85" id="2e85" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_lW-LsQorUM1UUwRDJiiMKg.png"></figure><pre name="41e9" id="41e9" class="graf graf--pre graf-after--figure">show_img(y[0]);</pre><figure name="4180" id="4180" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_EdCvr3nZIJf6mhwgQActnQ.png"></figure><pre name="f319" id="f319" class="graf graf--pre graf-after--figure">m.close()</pre><h4 name="f028" id="f028" class="graf graf--h4 graf-after--pre">1024x1024 [<a href="https://youtu.be/nG3tT31nPmQ?t=1h56m53s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h56m53s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:56:53</a>]</h4><p name="0df2" id="0df2" class="graf graf--p graf-after--h4">Go down to a batch size of 4, size of 1024.</p><pre name="8416" id="8416" class="graf graf--pre graf-after--p">sz=1024<br>bs=4</pre><pre name="0ece" id="0ece" class="graf graf--pre graf-after--pre">tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO, <br>                         tfm_y=TfmType.CLASS)<br>datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), <br>                            (val_x,val_y), tfms, path=PATH)<br>md = ImageData(PATH, datasets, bs, num_workers=16, classes=<strong class="markup--strong markup--pre-strong">None</strong>)<br>denorm = md.trn_ds.denorm</pre><pre name="5a4a" id="5a4a" class="graf graf--pre graf-after--pre">m_base = get_base()<br>m = to_gpu(Unet34(m_base))<br>models = UnetModel(m)</pre><pre name="22d8" id="22d8" class="graf graf--pre graf-after--pre">learn = ConvLearner(md, models)<br>learn.opt_fn=optim.Adam<br>learn.crit=nn.BCEWithLogitsLoss()<br>learn.metrics=[accuracy_thresh(0.5),dice]</pre><p name="e9fe" id="e9fe" class="graf graf--p graf-after--pre">Load in what we just saved with the 512.</p><pre name="01bf" id="01bf" class="graf graf--pre graf-after--p">learn.load('512urn')</pre><pre name="813b" id="813b" class="graf graf--pre graf-after--pre">learn.freeze_to(1)</pre><pre name="a020" id="a020" class="graf graf--pre graf-after--pre">learn.fit(lr,1, wds=wd, cycle_len=2,use_clr=(5,4))</pre><pre name="78fc" id="78fc" class="graf graf--pre graf-after--pre">epoch      trn_loss   val_loss   &lt;lambda&gt;   dice                 <br>    0      0.007656   0.008155   0.997247   0.99353   <br>    1      0.004706   0.00509    0.998039   0.995437</pre><pre name="c979" id="c979" class="graf graf--pre graf-after--pre">[0.005090427414942828, 0.9980387706605215, 0.995437301104031]</pre><p name="f808" id="f808" class="graf graf--p graf-after--pre">That gets us to&nbsp;.995.</p><pre name="2f50" id="2f50" class="graf graf--pre graf-after--p">learn.save('1024urn-tmp')</pre><pre name="04c2" id="04c2" class="graf graf--pre graf-after--pre">learn.load('1024urn-tmp')</pre><pre name="9025" id="9025" class="graf graf--pre graf-after--pre">learn.unfreeze()<br>learn.bn_freeze(<strong class="markup--strong markup--pre-strong">True</strong>)</pre><pre name="b82a" id="b82a" class="graf graf--pre graf-after--pre">lrs = np.array([lr/200,lr/30,lr])</pre><pre name="4237" id="4237" class="graf graf--pre graf-after--pre">learn.fit(lrs/10,1, wds=wd,cycle_len=4,use_clr=(20,8))</pre><pre name="1db5" id="1db5" class="graf graf--pre graf-after--pre">epoch      trn_loss   val_loss   &lt;lambda&gt;   dice                 <br>    0      0.005688   0.006135   0.997616   0.994616  <br>    1      0.004412   0.005223   0.997983   0.995349             <br>    2      0.004186   0.004975   0.99806    0.99554              <br>    3      0.004016   0.004899   0.99812    0.995627</pre><pre name="e86a" id="e86a" class="graf graf--pre graf-after--pre">[0.004898778487196458, 0.9981196409180051, 0.9956271404784823]</pre><pre name="ca01" id="ca01" class="graf graf--pre graf-after--pre">learn.fit(lrs/10,1, wds=wd,cycle_len=4,use_clr=(20,8))</pre><pre name="218c" id="218c" class="graf graf--pre graf-after--pre">epoch      trn_loss   val_loss   &lt;lambda&gt;   dice                 <br>    0      0.004169   0.004962   0.998049   0.995517  <br>    1      0.004022   0.004595   0.99823    0.995818             <br>    2      0.003772   0.004497   0.998215   0.995916             <br>    3      0.003618   0.004435   0.998291   0.995991</pre><pre name="ce73" id="ce73" class="graf graf--pre graf-after--pre">[0.004434524739663753, 0.9982911745707194, 0.9959913929776539]</pre><p name="0c5e" id="0c5e" class="graf graf--p graf-after--pre">Unfreeze takes us to… we’ll call that&nbsp;.996.</p><pre name="4fb8" id="4fb8" class="graf graf--pre graf-after--p">learn.sched.plot_loss()</pre><figure name="b088" id="b088" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_b7J9qrMQ0OxTQgj0QebeFw.png"></figure><pre name="9f1f" id="9f1f" class="graf graf--pre graf-after--figure">learn.save('1024urn')</pre><pre name="fc36" id="fc36" class="graf graf--pre graf-after--pre">learn.load('1024urn')</pre><pre name="a16e" id="a16e" class="graf graf--pre graf-after--pre">x,y = next(iter(md.val_dl))<br>py = to_np(learn.model(V(x)))</pre><p name="1907" id="1907" class="graf graf--p graf-after--pre">As you can see, that actually looks good [<a href="https://youtu.be/nG3tT31nPmQ?t=1h57m17s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h57m17s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:57:17</a>]. In accuracy terms, 99.82%. You can see this is looking like something you could just about use to cut out. I think, at this point, there’s a couple of minor tweaks we can do to get up to&nbsp;.997 but really the key thing then, I think, is just maybe to do a few bit of smoothing maybe or a little bit of post-processing. You can go and have a look at the Carvana winners’ blogs and see some of these tricks, but as I say, the difference between where we are at&nbsp;.996 and what the winners got of&nbsp;.997, it’s not heaps. So really that just the Unet on its own pretty much solves that problem.</p><pre name="5f52" id="5f52" class="graf graf--pre graf-after--p">show_img(py[0]&gt;0);</pre><figure name="4412" id="4412" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_A6ghUxP4m0OMKyUZWnv3xQ.png"></figure><pre name="0b0d" id="0b0d" class="graf graf--pre graf-after--figure">show_img(y[0]);</pre><figure name="04ec" id="04ec" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_1eNTc9dNtmuxTryHf1XGpA.png"></figure><h3 name="2ea9" id="2ea9" class="graf graf--h3 graf-after--figure">Back to Bounding Box [<a href="https://youtu.be/nG3tT31nPmQ?t=1h58m15s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h58m15s" class="markup--anchor markup--h3-anchor" rel="nofollow noopener" target="_blank">1:58:15</a>]</h3><p name="8276" id="8276" class="graf graf--p graf-after--h3">Okay, so that’s it. The last thing I wanted to mention is now to come all the way back to bounding boxes because you might remember, I said our bounding box model was still not doing very well on small objects. So hopefully you might be able to guess where I’m going to go with this which is that for the bounding box model, remember how we had at different grid cells we spat out outputs of the model. And it was those earlier ones with the small grid sizes that weren’t very good. How do we fix it? U-Net it! Let’s have an upward path with cross connections. So then we are just going to do a U-Net and then spit them out of that. Because now those finer grid cells have all of the information of that path, and that path, and that path, and that path for leverage. Now of course, this is deep learning so that means you can’t write a paper saying we just used U-Net for bounding boxes. You have to invent a new word so this is called feature pyramid networks or FPNs. And this was used in RetinaNet paper, it was created in an earlier paper specifically about FPNs. And if memory serves correctly, they did briefly cite the U-Net paper but they kind of made it sound like it was this vaguely slightly connected thing that maybe some people could consider slightly useful. But really, FPNs are U-Nets.</p><p name="7521" id="7521" class="graf graf--p graf-after--p">I don’t have an implementation of it to show you but it will be a fun thing, maybe for some of us to try and I know some of the students have been trying to get it working well on the forums. So yeah, interesting thing to try. So I think a couple of things to look at after this class as well as the other things I mentioned would be playing around with FPNs and also maybe trying Kerem’s DynamicUnet. They would both be interesting things to look at.</p><p name="bdf8" id="bdf8" class="graf graf--p graf-after--p graf--trailing">So you guys have all been through 14 lessons of me talking at you now. So I’m sorry about that. Thanks for putting up with me. I think you’re going to find it hard to find people who actually know them as much about training neural networks and practice as you do. It’ll be really easy for you to overestimate how capable all these other people are and underestimate how capable you are. So the main thing I’d say is, please practice, please. Just because you don’t have this constant thing getting you to come back here every Monday night now. It’s very easy to kind of lose that momentum. So find ways to keep it. Organize a study group, a book reading group, or get together with some friends and work on a project, or do something more than just deciding I want to keep working on X. Unless you are kind of person who’s super motivated and whenever you decide to do something, it happens. That’s not me. It’s like I know, for something to happen, I have to say “yes, David. In October, I will absolutely teach that course” and then it’s like okay I better actually write some material. That’s the only way I can get stuff to happen. So we’ve got a great community there on the forums. If people have ideas for ways to make it better, please tell me. If you think you can help with, if you want to create some new forum or moderated in some different way or whatever, just let me know. You can always PM me and there’s a lot of projects going on through GitHub as well — lots of stuff. So I hope to see you all back here at something else and thanks so much for joining me on this journey.</p><hr class="section-divider"><p name="dcdd" id="dcdd" class="graf graf--p graf--leading graf--trailing">Lessons: <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" class="markup--anchor markup--p-anchor" target="_blank">1</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" class="markup--anchor markup--p-anchor" target="_blank">2</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" class="markup--anchor markup--p-anchor" target="_blank">3</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" class="markup--anchor markup--p-anchor" target="_blank">4</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" class="markup--anchor markup--p-anchor" target="_blank">5</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" class="markup--anchor markup--p-anchor" target="_blank">6</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" class="markup--anchor markup--p-anchor" target="_blank">7</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" class="markup--anchor markup--p-anchor" target="_blank">8</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" class="markup--anchor markup--p-anchor" target="_blank">9</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" class="markup--anchor markup--p-anchor" target="_blank">10</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" class="markup--anchor markup--p-anchor" target="_blank">11</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" class="markup--anchor markup--p-anchor" target="_blank">12</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" class="markup--anchor markup--p-anchor" target="_blank">13</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" class="markup--anchor markup--p-anchor" target="_blank"><strong class="markup--strong markup--p-strong">14</strong></a></p></body></html>