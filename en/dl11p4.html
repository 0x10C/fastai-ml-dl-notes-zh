<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></head><body><pre name="9aae" id="9aae" class="graf graf--pre graf-after--p">learn.precompute=<strong class="markup--strong markup--pre-strong">True</strong></pre><pre name="0370" id="0370" class="graf graf--pre graf-after--pre">learn.fit(lr, 1, cycle_len=20, wds=wd, use_clr=(20,10))</pre><pre name="a105" id="a105" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">epoch      trn_loss   val_loss                                  <br>    0      0.104692   0.125685  <br>    1      0.112455   0.129307                                 <br>    2      0.110631   0.126568                                 <br>    3      0.108629   0.127338                                 <br>    4      0.110791   0.125033                                 <br>    5      0.108859   0.125186                                 <br>    6      0.106582   0.123875                                 <br>    7      0.103227   0.123945                                 <br>    8      0.10396    0.12304                                  <br>    9      0.105898   0.124894                                 <br>    10     0.10498    0.122582                                 <br>    11     0.104983   0.122906                                 <br>    12     0.102317   0.121171                                  <br>    13     0.10017    0.121816                                  <br>    14     0.099454   0.119647                                  <br>    15     0.100425   0.120914                                  <br>    16     0.097226   0.119724                                  <br>    17     0.094666   0.118746                                  <br>    18     0.094137   0.118744                                  <br>    19     0.090076   0.117908</em></pre><pre name="c43b" id="c43b" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[0.11790786389489033]</em></pre><pre name="4894" id="4894" class="graf graf--pre graf-after--pre">learn.bn_freeze(<strong class="markup--strong markup--pre-strong">True</strong>)</pre><pre name="fc1e" id="fc1e" class="graf graf--pre graf-after--pre">learn.fit(lr, 1, cycle_len=20, wds=wd, use_clr=(20,10))</pre><pre name="bac5" id="bac5" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">epoch      trn_loss   val_loss                                  <br>    0      0.104692   0.125685  <br>    1      0.112455   0.129307                                 <br>    2      0.110631   0.126568                                 <br>    3      0.108629   0.127338                                 <br>    4      0.110791   0.125033                                 <br>    5      0.108859   0.125186                                 <br>    6      0.106582   0.123875                                 <br>    7      0.103227   0.123945                                 <br>    8      0.10396    0.12304                                  <br>    9      0.105898   0.124894                                 <br>    10     0.10498    0.122582                                 <br>    11     0.104983   0.122906                                 <br>    12     0.102317   0.121171                                  <br>    13     0.10017    0.121816                                  <br>    14     0.099454   0.119647                                  <br>    15     0.100425   0.120914                                  <br>    16     0.097226   0.119724                                  <br>    17     0.094666   0.118746                                  <br>    18     0.094137   0.118744                                  <br>    19     0.090076   0.117908</em></pre><pre name="ddc2" id="ddc2" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[0.11790786389489033]</em></pre><pre name="70e1" id="70e1" class="graf graf--pre graf-after--pre">lrs = np.array([lr/1000,lr/100,lr])</pre><pre name="6cfb" id="6cfb" class="graf graf--pre graf-after--pre">learn.precompute=<strong class="markup--strong markup--pre-strong">False</strong><br>learn.freeze_to(1)</pre><pre name="404b" id="404b" class="graf graf--pre graf-after--pre">learn.save('pre0')</pre><pre name="2c47" id="2c47" class="graf graf--pre graf-after--pre">learn.load('pre0')</pre><h3 name="1ae7" id="1ae7" class="graf graf--h3 graf-after--pre">Image search</h3><h4 name="5a9e" id="5a9e" class="graf graf--h4 graf-after--h3">Search imagenet&nbsp;classes</h4><p name="7eea" id="7eea" class="graf graf--p graf-after--h4">At the end of all that, we can now say let’s grab the 1000 ImageNet classes, let’s predict on our whole validation set, and take a look at a few pictures [<a href="https://youtu.be/tY0n9OT5_nA?t=2h10m26s" data-href="https://youtu.be/tY0n9OT5_nA?t=2h10m26s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">2:10:26</a>].</p><pre name="5e0f" id="5e0f" class="graf graf--pre graf-after--p">syns, wvs = list(zip(*syn_wv_1k))<br>wvs = np.array(wvs)</pre><pre name="da52" id="da52" class="graf graf--pre graf-after--pre">%time pred_wv = learn.predict()</pre><pre name="9568" id="9568" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">CPU times: user 18.4 s, sys: 7.91 s, total: 26.3 s<br>Wall time: 7.17 s</em></pre><pre name="6f55" id="6f55" class="graf graf--pre graf-after--pre">start=300</pre><pre name="03a5" id="03a5" class="graf graf--pre graf-after--pre">denorm = md.val_ds.denorm</pre><pre name="7083" id="7083" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">def</strong> show_img(im, figsize=<strong class="markup--strong markup--pre-strong">None</strong>, ax=<strong class="markup--strong markup--pre-strong">None</strong>):<br>    <strong class="markup--strong markup--pre-strong">if</strong> <strong class="markup--strong markup--pre-strong">not</strong> ax: fig,ax = plt.subplots(figsize=figsize)<br>    ax.imshow(im)<br>    ax.axis('off')<br>    <strong class="markup--strong markup--pre-strong">return</strong> ax</pre><pre name="e2c3" id="e2c3" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">def</strong> show_imgs(ims, cols, figsize=<strong class="markup--strong markup--pre-strong">None</strong>):<br>    fig,axes = plt.subplots(len(ims)//cols, cols, figsize=figsize)<br>    <strong class="markup--strong markup--pre-strong">for</strong> i,ax <strong class="markup--strong markup--pre-strong">in</strong> enumerate(axes.flat): show_img(ims[i], ax=ax)<br>    plt.tight_layout()</pre><p name="bf46" id="bf46" class="graf graf--p graf-after--pre">Because validation set is ordered, tall the stuff of the same type are in the same place.</p><pre name="da5f" id="da5f" class="graf graf--pre graf-after--p">show_imgs(denorm(md.val_ds[start:start+25][0]), 5, (10,10))</pre><figure name="c31f" id="c31f" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_exiD0uDeL6xx5EOLdPS3BA.png"></figure><p name="d8a5" id="d8a5" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">Nearest neighbor search </strong>[<a href="https://youtu.be/tY0n9OT5_nA?t=2h10m56s" data-href="https://youtu.be/tY0n9OT5_nA?t=2h10m56s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">2:10:56</a>]: What we can now do is we can now use nearest neighbors search. So nearest neighbors search means here is one300 dimensional vector and here is a whole a lot of other 300 dimensional vectors, which things is it closest to? Normally that takes a very long time because you have to look through every 300 dimensional vector, calculate its distance, and find out how far away it is. But there is an amazing almost unknown library called <strong class="markup--strong markup--p-strong">NMSLib</strong> that does that incredibly fast. Some of you may have tried other nearest neighbor’s libraries, I guarantee this is faster than what you are using — I can tell you that because it’s been bench marked by people who do this stuff for a living. This is by far the fastest on every possible dimension. We want to create an index on angular distance, and we need to do it on all of our ImageNet word vectors. Adding a whole batch, create the index, and now we can query a bunch of vectors all at once, get the 10 nearest neighbors. The library uses multi-threading and is absolutely fantastic. You can install from pip (<code class="markup--code markup--p-code">pip install nmslib</code>) and it just works.</p><pre name="ef34" id="ef34" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">import</strong> <strong class="markup--strong markup--pre-strong">nmslib</strong></pre><pre name="9f2b" id="9f2b" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">def</strong> create_index(a):<br>    index = nmslib.init(space='angulardist')<br>    index.addDataPointBatch(a)<br>    index.createIndex()<br>    <strong class="markup--strong markup--pre-strong">return</strong> index</pre><pre name="64fd" id="64fd" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">def</strong> get_knns(index, vecs):<br>     <strong class="markup--strong markup--pre-strong">return</strong> zip(*index.knnQueryBatch(vecs, k=10, num_threads=4))</pre><pre name="07a0" id="07a0" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">def</strong> get_knn(index, vec): <strong class="markup--strong markup--pre-strong">return</strong> index.knnQuery(vec, k=10)</pre><pre name="a7f1" id="a7f1" class="graf graf--pre graf-after--pre">nn_wvs = create_index(wvs)</pre><p name="8aa9" id="8aa9" class="graf graf--p graf-after--pre">It tells you how far away they are and their indexes [<a href="https://youtu.be/tY0n9OT5_nA?t=2h12m13s" data-href="https://youtu.be/tY0n9OT5_nA?t=2h12m13s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">2:12:13</a>].</p><pre name="2b14" id="2b14" class="graf graf--pre graf-after--p">idxs,dists = get_knns(nn_wvs, pred_wv)</pre><p name="9794" id="9794" class="graf graf--p graf-after--pre">So now we can go through and print out the top 3 so it turns out that bird actually is a limpkin. Interestingly the fourth one does not say it’s a limpkin and Jeremy looked it up. He doesn’t know much about birds but everything else is brown with white spots, but the 4th one isn’t. So we don’t know if that is actually a limpkin or if it is mislabeled but sure as heck it doesn’t look like the other birds.</p><pre name="7b8d" id="7b8d" class="graf graf--pre graf-after--p">[[classids[syns[id]] <strong class="markup--strong markup--pre-strong">for</strong> id <strong class="markup--strong markup--pre-strong">in</strong> ids[:3]] <br>                         <strong class="markup--strong markup--pre-strong">for</strong> ids <strong class="markup--strong markup--pre-strong">in</strong> idxs[start:start+10]]</pre><pre name="8e93" id="8e93" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['spoonbill', 'bustard', 'oystercatcher'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill']]</em></pre><p name="9dce" id="9dce" class="graf graf--p graf-after--pre">This is not a particularly hard thing to do because there is only a thousand ImageNet classes and it is not doing anything new. But what if we now bring in the entirety of WordNet and we now say which of those 45 thousand things is it closest to?</p><h4 name="d4bc" id="d4bc" class="graf graf--h4 graf-after--p">Search all WordMet noun&nbsp;classes</h4><pre name="4ed5" id="4ed5" class="graf graf--pre graf-after--h4">all_syns, all_wvs = list(zip(*syn2wv.items()))<br>all_wvs = np.array(all_wvs)</pre><pre name="cb4d" id="cb4d" class="graf graf--pre graf-after--pre">nn_allwvs = create_index(all_wvs)</pre><pre name="2b27" id="2b27" class="graf graf--pre graf-after--pre">idxs,dists = get_knns(nn_allwvs, pred_wv)</pre><pre name="d157" id="d157" class="graf graf--pre graf-after--pre">[[classids[all_syns[id]] <strong class="markup--strong markup--pre-strong">for</strong> id <strong class="markup--strong markup--pre-strong">in</strong> ids[:3]] <br>                             <strong class="markup--strong markup--pre-strong">for</strong> ids <strong class="markup--strong markup--pre-strong">in</strong> idxs[start:start+10]]</pre><pre name="80aa" id="80aa" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['spoonbill', 'bustard', 'oystercatcher'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill'],<br> ['limpkin', 'oystercatcher', 'spoonbill']]</em></pre><p name="ba81" id="ba81" class="graf graf--p graf-after--pre">Exactly the same result. It is now searching all of the WordNet.</p><h4 name="f233" id="f233" class="graf graf--h4 graf-after--p">Text -&gt; image search [<a href="https://youtu.be/tY0n9OT5_nA?t=2h13m16s" data-href="https://youtu.be/tY0n9OT5_nA?t=2h13m16s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">2:13:16</a>]</h4><p name="a2b4" id="a2b4" class="graf graf--p graf-after--h4">Now let’s do something a bit different — which is to take all of our predictions (<code class="markup--code markup--p-code">pred_wv</code>) so basically take our whole validation set of images and create a KNN index of the image representations because remember, it is predicting things that are meant to be word vectors. Now let’s grab the fast text vector for “boat” and boat is not an ImageNet concept — yet we can now find all of the images in our predicted word vectors (i.e. our validation set) that are closest to the word boat and it works even though it is not something that was ever trained on.</p><pre name="72e3" id="72e3" class="graf graf--pre graf-after--p">nn_predwv = create_index(pred_wv)<br>en_vecd = pickle.load(open(TRANS_PATH/'wiki.en.pkl','rb'))<br>vec = en_vecd['boat']</pre><pre name="bb76" id="bb76" class="graf graf--pre graf-after--pre">idxs,dists = get_knn(nn_predwv, vec)<br>show_imgs([open_image(PATH/md.val_ds.fnames[i]) <strong class="markup--strong markup--pre-strong">for</strong> i <strong class="markup--strong markup--pre-strong">in</strong> idxs[:3]],<br>                      3, figsize=(9,3));</pre><figure name="5791" id="5791" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_BLLI7IWFO84BPwB-Y1uCKg.png"></figure><p name="f197" id="f197" class="graf graf--p graf-after--figure">What if we now take engine’s vector and boat’s vector and take their average and what if we now look in our nearest neighbors for that [<a href="https://youtu.be/tY0n9OT5_nA?t=2h14m4s" data-href="https://youtu.be/tY0n9OT5_nA?t=2h14m4s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">2:14:04</a>]?</p><pre name="f02f" id="f02f" class="graf graf--pre graf-after--p">vec = (en_vecd['engine'] + en_vecd['boat'])/2 </pre><pre name="0551" id="0551" class="graf graf--pre graf-after--pre">idxs,dists = get_knn(nn_predwv, vec)<br>show_imgs([open_image(PATH/md.val_ds.fnames[i]) <strong class="markup--strong markup--pre-strong">for</strong> i <strong class="markup--strong markup--pre-strong">in</strong> idxs[:3]],<br>                      3, figsize=(9,3));</pre><figure name="4ace" id="4ace" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_EkwjxE8m8xeX2lDRLIJTCw.png"></figure><p name="d7be" id="d7be" class="graf graf--p graf-after--figure">These are boats with engines. I mean, yes, the middle one is actually a boat with an engine — it just happens to have wings on as well. By the way, sail is not an ImageNet thing&nbsp;, neither is boat. Here is the average of two things that are not ImageNet things and yet with one exception, it’s found us two sailboats.</p><pre name="1f6a" id="1f6a" class="graf graf--pre graf-after--p">vec = (en_vecd['sail'] + en_vecd['boat'])/2</pre><pre name="deb4" id="deb4" class="graf graf--pre graf-after--pre">idxs,dists = get_knn(nn_predwv, vec)<br>show_imgs([open_image(PATH/md.val_ds.fnames[i]) <strong class="markup--strong markup--pre-strong">for</strong> i <strong class="markup--strong markup--pre-strong">in</strong> idxs[:3]],<br>                      3, figsize=(9,3));</pre><figure name="32ff" id="32ff" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_-7X7LGxPWi1qv8fF1hkCog.png"></figure><h4 name="a464" id="a464" class="graf graf--h4 graf-after--figure">Image-&gt;image [<a href="https://youtu.be/tY0n9OT5_nA?t=2h14m35s" data-href="https://youtu.be/tY0n9OT5_nA?t=2h14m35s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">2:14:35</a>]</h4><p name="419f" id="419f" class="graf graf--p graf-after--h4">Okay, let’s do something else crazy. Let’s open up an image in the validation set. Let’s call <code class="markup--code markup--p-code">predict_array</code> on that image to get its word vector like thing, and let’s do a nearest neighbor search on all the other images.</p><pre name="78d8" id="78d8" class="graf graf--pre graf-after--p">fname = 'valid/n01440764/ILSVRC2012_val_00007197.JPEG'<br>img = open_image(PATH/fname)<br>show_img(img);</pre><figure name="caf8" id="caf8" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_FVCX6O367r2oJXVhR1r-Sg.png"></figure><pre name="5582" id="5582" class="graf graf--pre graf-after--figure">t_img = md.val_ds.transform(img)<br>pred = learn.predict_array(t_img[<strong class="markup--strong markup--pre-strong">None</strong>])</pre><pre name="bbcb" id="bbcb" class="graf graf--pre graf-after--pre">idxs,dists = get_knn(nn_predwv, pred)<br>show_imgs([open_image(PATH/md.val_ds.fnames[i]) <strong class="markup--strong markup--pre-strong">for</strong> i <strong class="markup--strong markup--pre-strong">in</strong> idxs[1:4]],<br>                      3, figsize=(9,3));</pre><figure name="a044" id="a044" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_hQ8r1gcwNfh7KlZGjS-lcQ.png"></figure><p name="8e97" id="8e97" class="graf graf--p graf-after--figure">And here are all the other images of whatever that is. So you can see, this is crazy — we’ve trained a thing on all of ImageNet in an hour, using a custom head that required basically like two lines fo code, and these things run in 300 milliseconds to do these searches.</p><p name="787d" id="787d" class="graf graf--p graf-after--p">Jeremy taught this basic idea last year as well, but it was in Keras, and it was pages and pages of code, and everything took a long time and complicated. And back then, Jeremy said he can’t begin to think all of the stuff you could do with this. He doesn’t think anybody has really thought deeply about this yet, but he thinks it’s fascinating. So go back and read the DeVICE paper because Andrea had a whole bunch of other thoughts and now that it is so easy to do, hopefully people will dig into this now. Jeremy thinks it’s crazy and amazing.</p><p name="ffb1" id="ffb1" class="graf graf--p graf-after--p graf--trailing">Alright, see you next week!</p><hr class="section-divider"><p name="1c54" id="1c54" class="graf graf--p graf--leading graf--trailing">Lessons: <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" class="markup--anchor markup--p-anchor" target="_blank">1</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" class="markup--anchor markup--p-anchor" target="_blank">2</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" class="markup--anchor markup--p-anchor" target="_blank">3</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" class="markup--anchor markup--p-anchor" target="_blank">4</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" class="markup--anchor markup--p-anchor" target="_blank">5</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" class="markup--anchor markup--p-anchor" target="_blank">6</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" class="markup--anchor markup--p-anchor" target="_blank">7</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" class="markup--anchor markup--p-anchor" target="_blank">8</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" class="markup--anchor markup--p-anchor" target="_blank">9</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" class="markup--anchor markup--p-anchor" target="_blank">10</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" class="markup--anchor markup--p-anchor" target="_blank"><strong class="markup--strong markup--p-strong">11</strong></a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" class="markup--anchor markup--p-anchor" target="_blank">12</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" class="markup--anchor markup--p-anchor" target="_blank">13</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" class="markup--anchor markup--p-anchor" target="_blank">14</a></p></body></html>