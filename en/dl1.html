
<!-- saved from url=(0063)file:///C:/Users/asus/Desktop/fastai-ml-dl-notes-zh/en/dl1.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></head><body><hr class="section-divider"><h1 name="6f59" id="6f59" class="graf graf--h3 graf--leading graf--title">Deep Learning 2: Part 1 Lesson&nbsp;1</h1><p name="1907" id="1907" class="graf graf--p graf-after--h3"><em class="markup--em markup--p-em">My personal notes from </em><a href="http://www.fast.ai/" data-href="http://www.fast.ai/" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank"><em class="markup--em markup--p-em">fast.ai course</em></a><em class="markup--em markup--p-em">. These notes will continue to be updated and improved as I continue to review the course to “really” understand it. Much appreciation to </em><a href="https://twitter.com/jeremyphoward" data-href="https://twitter.com/jeremyphoward" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank"><em class="markup--em markup--p-em">Jeremy</em></a><em class="markup--em markup--p-em"> and </em><a href="https://twitter.com/math_rachel" data-href="https://twitter.com/math_rachel" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank"><em class="markup--em markup--p-em">Rachel</em></a><em class="markup--em markup--p-em"> who gave me this opportunity to learn.</em></p><p name="3e8b" id="3e8b" class="graf graf--p graf-after--p graf--trailing">Lessons: <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" class="markup--anchor markup--p-anchor" target="_blank"><strong class="markup--strong markup--p-strong">1</strong></a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" class="markup--anchor markup--p-anchor" target="_blank">2</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" class="markup--anchor markup--p-anchor" target="_blank">3</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" class="markup--anchor markup--p-anchor" target="_blank">4</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" class="markup--anchor markup--p-anchor" target="_blank">5</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" class="markup--anchor markup--p-anchor" target="_blank">6</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" class="markup--anchor markup--p-anchor" target="_blank">7</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" class="markup--anchor markup--p-anchor" target="_blank">8</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" class="markup--anchor markup--p-anchor" target="_blank">9</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" class="markup--anchor markup--p-anchor" target="_blank">10</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" class="markup--anchor markup--p-anchor" target="_blank">11</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" class="markup--anchor markup--p-anchor" target="_blank">12</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" class="markup--anchor markup--p-anchor" target="_blank">13</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" class="markup--anchor markup--p-anchor" target="_blank">14</a></p><hr class="section-divider"><h3 name="9da9" id="9da9" class="graf graf--h3 graf--leading"><a href="http://forums.fast.ai/t/wiki-lesson-1/9398/1" data-href="http://forums.fast.ai/t/wiki-lesson-1/9398/1" class="markup--anchor markup--h3-anchor" rel="nofollow noopener" target="_blank">Lesson 1</a></h3><h4 name="fb00" id="fb00" class="graf graf--h4 graf-after--h3">Getting started&nbsp;[<a href="https://youtu.be/IPBSB1HLNLo" data-href="https://youtu.be/IPBSB1HLNLo" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">0:00</a>]:</h4><ul class="postList"><li name="3af3" id="3af3" class="graf graf--li graf-after--h4">In order to train a neural network, you will most certainly need Graphics Processing Unit (GPU) — specifically NVIDIA GPU because it is the only one that supports CUDA (the language and framework that nearly all deep learning libraries and practitioners use).</li><li name="b76f" id="b76f" class="graf graf--li graf-after--li">There are several ways to rent GPU: Crestle [<a href="https://youtu.be/IPBSB1HLNLo?t=4m6s" data-href="https://youtu.be/IPBSB1HLNLo?t=4m6s" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">04:06</a>], Paperspace [<a href="https://youtu.be/IPBSB1HLNLo?t=6m10s" data-href="https://youtu.be/IPBSB1HLNLo?t=6m10s" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">06:10</a>]</li></ul><h4 name="e0c0" id="e0c0" class="graf graf--h4 graf-after--li"><a href="https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb" data-href="https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">Introduction to Jupyter Notebook and Dogs vs. Cats</a>&nbsp;[<a href="https://youtu.be/IPBSB1HLNLo?t=12m39s" data-href="https://youtu.be/IPBSB1HLNLo?t=12m39s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">12:39</a>]</h4><ul class="postList"><li name="323d" id="323d" class="graf graf--li graf-after--h4">You can run a cell by selecting it and hitting <code class="markup--code markup--li-code">shift+enter</code> (you can hold down <code class="markup--code markup--li-code">shift</code> and hit <code class="markup--code markup--li-code">enter</code> multiple times to keep going down the cells), or you can click on Run button at the top. A cell can contain code, text, picture, video, etc.</li><li name="fbe6" id="fbe6" class="graf graf--li graf-after--li">Fast.ai requires Python 3</li></ul><pre name="2699" id="2699" class="graf graf--pre graf-after--li">%reload_ext autoreload<br>%autoreload 2<br>%matplotlib inline</pre><pre name="c4df" id="c4df" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em"># This file contains all the main external libs we'll use</em><br><strong class="markup--strong markup--pre-strong">from</strong> <strong class="markup--strong markup--pre-strong">fastai.imports</strong> <strong class="markup--strong markup--pre-strong">import</strong> *</pre><pre name="fcca" id="fcca" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">from</strong> <strong class="markup--strong markup--pre-strong">fastai.transforms</strong> <strong class="markup--strong markup--pre-strong">import</strong> *<br><strong class="markup--strong markup--pre-strong">from</strong> <strong class="markup--strong markup--pre-strong">fastai.conv_learner</strong> <strong class="markup--strong markup--pre-strong">import</strong> *<br><strong class="markup--strong markup--pre-strong">from</strong> <strong class="markup--strong markup--pre-strong">fastai.model</strong> <strong class="markup--strong markup--pre-strong">import</strong> *<br><strong class="markup--strong markup--pre-strong">from</strong> <strong class="markup--strong markup--pre-strong">fastai.dataset</strong> <strong class="markup--strong markup--pre-strong">import</strong> *<br><strong class="markup--strong markup--pre-strong">from</strong> <strong class="markup--strong markup--pre-strong">fastai.sgdr</strong> <strong class="markup--strong markup--pre-strong">import</strong> *<br><strong class="markup--strong markup--pre-strong">from</strong> <strong class="markup--strong markup--pre-strong">fastai.plots</strong> <strong class="markup--strong markup--pre-strong">import</strong> *</pre><pre name="37b3" id="37b3" class="graf graf--pre graf-after--pre">PATH = "data/dogscats/"<br>sz=224</pre><p name="f96b" id="f96b" class="graf graf--p graf-after--pre"><strong class="markup--strong markup--p-strong">First look at pictures [</strong><a href="https://youtu.be/IPBSB1HLNLo?t=15m40s" data-href="https://youtu.be/IPBSB1HLNLo?t=15m40s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank"><strong class="markup--strong markup--p-strong">15:39</strong></a><strong class="markup--strong markup--p-strong">]</strong></p><pre name="8911" id="8911" class="graf graf--pre graf-after--p">!ls {PATH}</pre><pre name="5607" id="5607" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">models	sample	test1  tmp  train  valid</em></pre><ul class="postList"><li name="f02f" id="f02f" class="graf graf--li graf-after--pre"><code class="markup--code markup--li-code">!</code> tells to use bash (shell) instead of python</li><li name="e28c" id="e28c" class="graf graf--li graf-after--li">If you are not familiar with training set and validation set, check out Practical Machine Learning class (or read <a href="http://www.fast.ai/2017/11/13/validation-sets/" data-href="http://www.fast.ai/2017/11/13/validation-sets/" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Rachel’s blog</a>)</li></ul><pre name="9fb2" id="9fb2" class="graf graf--pre graf-after--li">!ls {PATH}valid</pre><pre name="0e16" id="0e16" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">cats  dogs</em></pre><pre name="42ba" id="42ba" class="graf graf--pre graf-after--pre">files = !ls {PATH}valid/cats | head<br>files</pre><pre name="f0c4" id="f0c4" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">['cat.10016.jpg',<br> 'cat.1001.jpg',<br> 'cat.10026.jpg',<br> 'cat.10048.jpg',<br> 'cat.10050.jpg',<br> 'cat.10064.jpg',<br> 'cat.10071.jpg',<br> 'cat.10091.jpg',<br> 'cat.10103.jpg',<br> 'cat.10104.jpg']</em></pre><ul class="postList"><li name="f414" id="f414" class="graf graf--li graf-after--pre">This folder structure is the most common approach for how image classification dataset is shared and provided. Each folder tells you the label (e.g. <code class="markup--code markup--li-code">dogs</code> or <code class="markup--code markup--li-code">cats</code>).</li></ul><pre name="0299" id="0299" class="graf graf--pre graf-after--li">img = plt.imread(f'<strong class="markup--strong markup--pre-strong">{PATH}</strong>valid/cats/<strong class="markup--strong markup--pre-strong">{files[0]}</strong>')<br>plt.imshow(img);</pre><figure name="12e9" id="12e9" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_Uqy-JLzpyZedFNdpm15N2A.png"></figure><ul class="postList"><li name="ec35" id="ec35" class="graf graf--li graf-after--figure"><code class="markup--code markup--li-code">f’{PATH}valid/cats/{files[0]}’</code> — This is a Python 3.6. format string which is a convenient to format a string.</li></ul><pre name="6b8b" id="6b8b" class="graf graf--pre graf-after--li">img.shape</pre><pre name="fd63" id="fd63" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">(198, 179, 3)</em></pre><pre name="5b3d" id="5b3d" class="graf graf--pre graf-after--pre">img[:4,:4]</pre><pre name="097a" id="097a" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">array([[[ 29,  20,  23],<br>        [ 31,  22,  25],<br>        [ 34,  25,  28],<br>        [ 37,  28,  31]],</em></pre><pre name="7c3f" id="7c3f" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[[ 60,  51,  54],<br>        [ 58,  49,  52],<br>        [ 56,  47,  50],<br>        [ 55,  46,  49]],</em></pre><pre name="9f31" id="9f31" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[[ 93,  84,  87],<br>        [ 89,  80,  83],<br>        [ 85,  76,  79],<br>        [ 81,  72,  75]],</em></pre><pre name="da80" id="da80" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[[104,  95,  98],<br>        [103,  94,  97],<br>        [102,  93,  96],<br>        [102,  93,  96]]], dtype=uint8)</em></pre><ul class="postList"><li name="dc93" id="dc93" class="graf graf--li graf-after--pre"><code class="markup--code markup--li-code">img</code> is a 3 dimensional array (a.k.a. rank 3 tensor)</li><li name="1702" id="1702" class="graf graf--li graf-after--li">The three items (e.g. <code class="markup--code markup--li-code">[29, 20, 23]</code>) represents Red Green Blue pixel values between 0 and 255</li><li name="7fda" id="7fda" class="graf graf--li graf-after--li">The idea is to take these numbers and use them to predict whether those numbers represent a cat or a dog based on looking at lots of pictures of cats and dogs.</li><li name="95d7" id="95d7" class="graf graf--li graf-after--li">This dataset comes from <a href="https://www.kaggle.com/c/dogs-vs-cats" data-href="https://www.kaggle.com/c/dogs-vs-cats" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Kaggle competition</a>, and when it was released (back in 2013) the state-of-the-art was 80% accurate.</li></ul><p name="7ebe" id="7ebe" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Let’s train a model [</strong><a href="https://youtu.be/IPBSB1HLNLo?t=20m21s" data-href="https://youtu.be/IPBSB1HLNLo?t=20m21s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank"><strong class="markup--strong markup--p-strong">20:21</strong></a><strong class="markup--strong markup--p-strong">]</strong></p><p name="4ab2" id="4ab2" class="graf graf--p graf-after--p">Here are the three lines of code necessary to train a model:</p><pre name="ab62" id="ab62" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">data</strong> = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(resnet34, sz))<br><strong class="markup--strong markup--pre-strong">learn</strong> = ConvLearner.pretrained(resnet34, data, precompute=<strong class="markup--strong markup--pre-strong">True</strong>)<br><strong class="markup--strong markup--pre-strong">learn.fit</strong>(0.01, 3)</pre><pre name="05b9" id="05b9" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[ 0.       0.04955  0.02605  0.98975]                         <br>[ 1.       0.03977  0.02916  0.99219]                         <br>[ 2.       0.03372  0.02929  0.98975]</em></pre><ul class="postList"><li name="af09" id="af09" class="graf graf--li graf-after--pre">This will do 3 <strong class="markup--strong markup--li-strong">epochs</strong> which means it is going to look at the entire set of images three times.</li><li name="d972" id="d972" class="graf graf--li graf-after--li">The last of three numbers in the output is the accuracy on the validation set.</li><li name="1476" id="1476" class="graf graf--li graf-after--li">The first two are the value of loss function (in this case the cross-entropy loss) for the training set and the validation set.</li><li name="c201" id="c201" class="graf graf--li graf-after--li">The start (e.g. <code class="markup--code markup--li-code">0.</code>, <code class="markup--code markup--li-code">1.</code>) is the epoch number.</li><li name="0e78" id="0e78" class="graf graf--li graf-after--li">We achieved ~99% (which would have won the Kaggle competition back in 2013) in 17 seconds with 3 lines of code! [<a href="https://youtu.be/IPBSB1HLNLo?t=21m49s" data-href="https://youtu.be/IPBSB1HLNLo?t=21m49s" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">21:49</a>]</li><li name="d16a" id="d16a" class="graf graf--li graf-after--li">A lot of people assume that deep learning takes a huge amount of time, lots of resources, and lots of data — that, in general, is not true!</li></ul><h4 name="16d3" id="16d3" class="graf graf--h4 graf-after--li">Fast.ai Library&nbsp;[<a href="https://youtu.be/IPBSB1HLNLo?t=22m24s" data-href="https://youtu.be/IPBSB1HLNLo?t=22m24s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">22:24</a>]</h4><ul class="postList"><li name="5925" id="5925" class="graf graf--li graf-after--h4">The library takes all of the best practices and approaches they can find — each time a paper comes out that looks interesting, they test it out and if it works well for a variety of datasets and they can figure out how to tune it, it gets implement it in the library.</li><li name="5d0f" id="5d0f" class="graf graf--li graf-after--li">Fast.ai curates all these best practices and packages up for you, and most of the time, figures out the best way to handle things automatically.</li><li name="1106" id="1106" class="graf graf--li graf-after--li">Fast.ai sits on top of a library called PyTorch which is a really flexible deep learning, machine learning, and GPU computation library written by Facebook.</li><li name="0216" id="0216" class="graf graf--li graf-after--li">Most people are more familiar with TensorFlow than PyTorch, but most of the top researchers Jeremy knows nowadays have switched across to PyTorch.</li><li name="15b8" id="15b8" class="graf graf--li graf-after--li">Fast.ai is flexible that you can use all these curated best practices as much or as little as you want. It is easy to hook in at any point and write your own data augmentation, loss function, network architecture, etc, and we will learn all that in this course.</li></ul><h4 name="3da2" id="3da2" class="graf graf--h4 graf-after--li">Analyzing results&nbsp;[<a href="https://youtu.be/IPBSB1HLNLo?t=24m12s" data-href="https://youtu.be/IPBSB1HLNLo?t=24m12s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">24:21</a>]</h4><p name="c436" id="c436" class="graf graf--p graf-after--h4">This is what the validation dataset label (think of it as the correct answers) looks like:</p><pre name="bcb9" id="bcb9" class="graf graf--pre graf-after--p">data.val_y</pre><pre name="205d" id="205d" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">array([0, 0, 0, ..., 1, 1, 1])</em></pre><p name="f216" id="f216" class="graf graf--p graf-after--pre">What do these 0’s and 1’s represents?</p><pre name="bc14" id="bc14" class="graf graf--pre graf-after--p">data.classes</pre><pre name="84e9" id="84e9" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">['cats', 'dogs']</em></pre><ul class="postList"><li name="a47b" id="a47b" class="graf graf--li graf-after--pre"><code class="markup--code markup--li-code">data</code> contains the validation and training data</li><li name="1a2b" id="1a2b" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">learn</code> contains the model</li></ul><p name="2cd0" id="2cd0" class="graf graf--p graf-after--li">Let’s make predictions for the validation set (predictions are in log scale):</p><pre name="be55" id="be55" class="graf graf--pre graf-after--p">log_preds = learn.predict()<br>log_preds.shape</pre><pre name="f27a" id="f27a" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">(2000, 2)</em></pre><pre name="b7f8" id="b7f8" class="graf graf--pre graf-after--pre">log_preds[:10]</pre><pre name="dadd" id="dadd" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">array([[ -0.00002, -11.07446],<br>       [ -0.00138,  -6.58385],<br>       [ -0.00083,  -7.09025],<br>       [ -0.00029,  -8.13645],<br>       [ -0.00035,  -7.9663 ],<br>       [ -0.00029,  -8.15125],<br>       [ -0.00002, -10.82139],<br>       [ -0.00003, -10.33846],<br>       [ -0.00323,  -5.73731],<br>       [ -0.0001 ,  -9.21326]], dtype=float32)</em></pre><ul class="postList"><li name="b8f1" id="b8f1" class="graf graf--li graf-after--pre">The output represents a prediction for cats, and prediction for dogs</li></ul><pre name="33e7" id="33e7" class="graf graf--pre graf-after--li">preds = np.argmax(log_preds, axis=1)  <em class="markup--em markup--pre-em"># from log probabilities to 0 or 1</em><br>probs = np.exp(log_preds[:,1])        <em class="markup--em markup--pre-em"># pr(dog)</em></pre><ul class="postList"><li name="ca3c" id="ca3c" class="graf graf--li graf-after--pre">In PyTorch and Fast.ai, most models return the log of the predictions rather than the probabilities themselves (we will learn why later in the course). For now, just know that to get probabilities, you have to do <code class="markup--code markup--li-code">np.exp()</code></li></ul><figure name="d3f3" id="d3f3" class="graf graf--figure graf-after--li"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_7upaprK7pvlI1x4SnIl9aQ.png"></figure><ul class="postList"><li name="226a" id="226a" class="graf graf--li graf-after--figure">Make sure you familiarize yourself with numpy (<code class="markup--code markup--li-code">np</code>)</li></ul><pre name="c979" id="c979" class="graf graf--pre graf-after--li"><em class="markup--em markup--pre-em"># 1. A few correct labels at random</em> plot_val_with_title(rand_by_correct(<strong class="markup--strong markup--pre-strong">True</strong>), "Correctly classified")</pre><ul class="postList"><li name="fa01" id="fa01" class="graf graf--li graf-after--pre">The number above the image is the probability of being a dog</li></ul><pre name="4481" id="4481" class="graf graf--pre graf-after--li"><em class="markup--em markup--pre-em"># 2. A few incorrect labels at random</em><br>plot_val_with_title(rand_by_correct(<strong class="markup--strong markup--pre-strong">False</strong>), "Incorrectly classified")</pre><figure name="4639" id="4639" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_ZLhFRuLXqQmFV2uAok84DA.png"></figure><pre name="6627" id="6627" class="graf graf--pre graf-after--figure">plot_val_with_title(most_by_correct(0, <strong class="markup--strong markup--pre-strong">True</strong>), "Most correct cats")</pre><figure name="2c00" id="2c00" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_RxYBmvqixwG4BYNPQGAZ4w.png"></figure><pre name="bc13" id="bc13" class="graf graf--pre graf-after--figure">plot_val_with_title(most_by_correct(1, <strong class="markup--strong markup--pre-strong">True</strong>), "Most correct dogs")</pre><figure name="0bb2" id="0bb2" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_kwUuA3gN-xbNBIUjDBHePg.png"></figure><p name="bedf" id="bedf" class="graf graf--p graf-after--figure">More interestingly, here are what the model thought it was definitely a dog but turns out to be a cat, or vice versa:</p><pre name="70fe" id="70fe" class="graf graf--pre graf-after--p">plot_val_with_title(most_by_correct(0, <strong class="markup--strong markup--pre-strong">False</strong>), "Most incorrect cats")</pre><figure name="446e" id="446e" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_gvPAqSdB9IRFmhU4DCk-mg.png"></figure><pre name="5550" id="5550" class="graf graf--pre graf-after--figure">plot_val_with_title(most_by_correct(1, <strong class="markup--strong markup--pre-strong">False</strong>), "Most incorrect dogs")</pre><figure name="404c" id="404c" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_jXaTLkWMrvpC8Yz0QfR6LA.png"></figure><pre name="f4b0" id="f4b0" class="graf graf--pre graf-after--figure">most_uncertain = np.argsort(np.abs(probs -0.5))[:4]<br>plot_val_with_title(most_uncertain, "Most uncertain predictions")</pre><figure name="d671" id="d671" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_wZDDn_XFH-z7libyMUlsBg.png"></figure><ul class="postList"><li name="258a" id="258a" class="graf graf--li graf-after--figure">Why is it important to look at these images? The first thing Jeremy does after he builds a model is to find a way to visualize what it has built. Because if he wants to make the model better, then he needs to take advantage of the things that is doing well and fix the things that is doing badly.</li><li name="27e7" id="27e7" class="graf graf--li graf-after--li">In this case, we have learned something about the dataset itself which is that there are some images that are in here that probably should not be. But it is also clear that this model has room to improve (e.g. data augmentation — which we will learn later).</li><li name="214a" id="214a" class="graf graf--li graf-after--li">Now you are ready to build your own image classifier (for regular photos — maybe not CT scan)! For example, <a href="https://towardsdatascience.com/fun-with-small-image-data-sets-8c83d95d0159" data-href="https://towardsdatascience.com/fun-with-small-image-data-sets-8c83d95d0159" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">here</a> is what one of the students did.</li><li name="097d" id="097d" class="graf graf--li graf-after--li">Check out<a href="http://forums.fast.ai/t/understanding-softmax-probabilities-output-on-a-multi-class-classification-problem/8194" data-href="http://forums.fast.ai/t/understanding-softmax-probabilities-output-on-a-multi-class-classification-problem/8194" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank"> this forum post </a>for different way of visualizing the results (e.g. when there are more than 2 categories, etc)</li></ul><h4 name="4edd" id="4edd" class="graf graf--h4 graf-after--li">Top-down vs Bottom-up [<a href="https://youtu.be/IPBSB1HLNLo?t=30m52s" data-href="https://youtu.be/IPBSB1HLNLo?t=30m52s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">30:52</a>]</h4><p name="a7a9" id="a7a9" class="graf graf--p graf-after--h4">Bottom-up: learn each building block you need, and eventually put them together</p><ul class="postList"><li name="ca31" id="ca31" class="graf graf--li graf-after--p">Hard to maintain motivation</li><li name="6ec8" id="6ec8" class="graf graf--li graf-after--li">Hard to know the “big picture”</li><li name="5cc3" id="5cc3" class="graf graf--li graf-after--li">Hard to know which pieces you’ll actually need</li></ul><p name="ddda" id="ddda" class="graf graf--p graf-after--li">fast.ai: Get students using a neural net right away, getting results ASAP</p><ul class="postList"><li name="9619" id="9619" class="graf graf--li graf-after--p">Gradually peel back the layers, modify, look under the hood</li></ul><h4 name="0e39" id="0e39" class="graf graf--h4 graf-after--li">Course Structure [<a href="https://youtu.be/IPBSB1HLNLo?t=33m53s" data-href="https://youtu.be/IPBSB1HLNLo?t=33m53s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">33:53</a>]</h4><figure name="ffa5" id="ffa5" class="graf graf--figure graf-after--h4"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_xTuKc0FAP9yKZ6fpcymKbA.png"></figure><ol class="postList"><li name="b75a" id="b75a" class="graf graf--li graf-after--figure">Image classifier with deep learning (with fewest lines of code)</li><li name="4692" id="4692" class="graf graf--li graf-after--li">Multi-label classification and different kinds of images (e.g. satellite images)</li><li name="f413" id="f413" class="graf graf--li graf-after--li">Structured data (e.g. sales forecasting) — structured data is what comes from database or spreadsheet</li><li name="0dbd" id="0dbd" class="graf graf--li graf-after--li">Language: NLP classifier (e.g. movie review classification)</li><li name="fdf3" id="fdf3" class="graf graf--li graf-after--li">Collaborative filtering (e.g. recommendation engine)</li><li name="43de" id="43de" class="graf graf--li graf-after--li">Generative language model: How to write your own Nietzsche philosophy from scratch character by character</li><li name="1092" id="1092" class="graf graf--li graf-after--li">Back to computer vision — not just recognize a cat photo, but find where the cat is in the photo (heat map) and also learn how to write our own architecture from scratch (ResNet)</li></ol><h4 name="bac1" id="bac1" class="graf graf--h4 graf-after--li">Image Classifier Examples:</h4><p name="00da" id="00da" class="graf graf--p graf-after--h4">Image classification algorithm is useful for lots and lots of things.</p><ul class="postList"><li name="120a" id="120a" class="graf graf--li graf-after--p">For example, AlphaGo [<a href="https://youtu.be/IPBSB1HLNLo?t=42m20s" data-href="https://youtu.be/IPBSB1HLNLo?t=42m20s" class="markup--anchor markup--li-anchor" rel="noopener nofollow" target="_blank">42:20</a>] looked at thousands and thousands of go boards and each one had a label saying whether the go board ended up being the winning or the losing player’s. So it learnt an image classification that was able to look at a go board and figure out whether it was a good or bad — which is the most important step in playing go well: to know which move is better.</li><li name="b111" id="b111" class="graf graf--li graf-after--li">Another example is an earlier student created <a href="https://www.splunk.com/blog/2017/04/18/deep-learning-with-splunk-and-tensorflow-for-security-catching-the-fraudster-in-neural-networks-with-behavioral-biometrics.html" data-href="https://www.splunk.com/blog/2017/04/18/deep-learning-with-splunk-and-tensorflow-for-security-catching-the-fraudster-in-neural-networks-with-behavioral-biometrics.html" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">an image classifier of mouse movement images </a>and detected fraudulent transactions.</li></ul><h4 name="b575" id="b575" class="graf graf--h4 graf-after--li">Deep Learning ≠Machine Learning&nbsp;[<a href="https://youtu.be/IPBSB1HLNLo?t=44m26s" data-href="https://youtu.be/IPBSB1HLNLo?t=44m26s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">44:26</a>]</h4><ul class="postList"><li name="71e1" id="71e1" class="graf graf--li graf-after--h4">Deep learning is a kind of machine learning</li><li name="798f" id="798f" class="graf graf--li graf-after--li">Machine learning was invented by Arthur Samuel. In the late 50s, he got an IBM mainframe to play checkers better than he could by inventing machine learning. He made the mainframe to play against itself lots of times and figure out which kind of things led to victories, and used that to, in a way, write its own program. In 1962, Arthur Samuel said one day, the vast majority of computer software would be written using this machine learning approach rather than written by hand.</li><li name="2ff8" id="2ff8" class="graf graf--li graf-after--li">C-Path (Computational Pathologist)[<a href="https://youtu.be/IPBSB1HLNLo?t=45m42s" data-href="https://youtu.be/IPBSB1HLNLo?t=45m42s" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">45:42</a>] is an example of traditional machine learning approach. He took pathology slides of breast cancer biopsies, consulted many pathologists on ideas about what kinds of patterns or features might be associated with long-term survival. Then they wrote specialist algorithms to calculate these features, run through logistic regression, and predicted the survival rate. It outperformed pathologists, but it took domain experts and computer experts many years of work to build.</li></ul><h4 name="3368" id="3368" class="graf graf--h4 graf-after--li">A better way&nbsp;[<a href="https://youtu.be/IPBSB1HLNLo?t=47m35s" data-href="https://youtu.be/IPBSB1HLNLo?t=47m35s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">47:35</a>]</h4><figure name="7d7b" id="7d7b" class="graf graf--figure graf-after--h4"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_R4qix1l4TjKOrLkrA4t6EA.png"></figure><ul class="postList"><li name="044c" id="044c" class="graf graf--li graf-after--figure">A class of algorithm that have these three properties is Deep Learning.</li></ul><h4 name="994c" id="994c" class="graf graf--h4 graf-after--li">Infinitely flexible function: Neural Network&nbsp;[<a href="https://youtu.be/IPBSB1HLNLo?t=48m43s" data-href="https://youtu.be/IPBSB1HLNLo?t=48m43s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">48:43</a>]</h4><p name="1ff8" id="1ff8" class="graf graf--p graf-after--h4">Underlying function that deep learning uses is called the neural network:</p><figure name="70ec" id="70ec" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_0YOpyzGWkrS4VW3ntJRQ5Q.png"></figure><ul class="postList"><li name="1b98" id="1b98" class="graf graf--li graf-after--figure">All you need to know for now is that it consists of a number of simple linear layers interspersed with a number of simple non-linear layers. When you intersperse these layers, you get something called the universal approximation theorem. What universal approximation theorem says is that this kind of function can solve any given problem to arbitrarily close accuracy as long as you add enough parameters.</li></ul><h4 name="11f5" id="11f5" class="graf graf--h4 graf-after--li">All purpose parameter fitting: Gradient Descent&nbsp;[<a href="https://youtu.be/IPBSB1HLNLo?t=49m39s" data-href="https://youtu.be/IPBSB1HLNLo?t=49m39s" class="markup--anchor markup--h4-anchor" rel="noopener nofollow" target="_blank">49:39</a>]</h4><figure name="fde5" id="fde5" class="graf graf--figure graf-after--h4"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_ezus486-s4OMT2YrXq81Dg.png"></figure><h4 name="1ad8" id="1ad8" class="graf graf--h4 graf-after--figure">Fast and scalable: GPU&nbsp;[<a href="https://youtu.be/IPBSB1HLNLo?t=51m5s" data-href="https://youtu.be/IPBSB1HLNLo?t=51m5s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">51:05</a>]</h4><figure name="7e40" id="7e40" class="graf graf--figure graf-after--h4"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_qPZYWZebPi6Sx_usSPWHUg.png"></figure><p name="faed" id="faed" class="graf graf--p graf-after--figure">The neural network example shown above has one hidden layer. Something what we learned in the past few years is that these kind of neural network was not fast or scalable unless we added multiple hidden layers — hence called “Deep” learning.</p><h4 name="d29f" id="d29f" class="graf graf--h4 graf-after--p">Putting all together&nbsp;[<a href="https://youtu.be/IPBSB1HLNLo?t=53m40s" data-href="https://youtu.be/IPBSB1HLNLo?t=53m40s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">53:40</a>]</h4><figure name="949d" id="949d" class="graf graf--figure graf-after--h4"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_btdxcSWzAoJMPuo0qgVXKw.png"></figure><p name="3c23" id="3c23" class="graf graf--p graf-after--figure">Here are some of the examples:</p><ul class="postList"><li name="3cb8" id="3cb8" class="graf graf--li graf-after--p"><a href="https://research.googleblog.com/2015/11/computer-respond-to-this-email.html" data-href="https://research.googleblog.com/2015/11/computer-respond-to-this-email.html" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">https://research.googleblog.com/2015/11/computer-respond-to-this-email.html</a></li><li name="5c47" id="5c47" class="graf graf--li graf-after--li"><a href="https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/" data-href="https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/</a></li><li name="446f" id="446f" class="graf graf--li graf-after--li"><a href="https://www.skype.com/en/features/skype-translator/" data-href="https://www.skype.com/en/features/skype-translator/" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">https://www.skype.com/en/features/skype-translator/</a></li><li name="cc5e" id="cc5e" class="graf graf--li graf-after--li"><a href="https://arxiv.org/abs/1603.01768" data-href="https://arxiv.org/abs/1603.01768" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">https://arxiv.org/abs/1603.01768</a></li></ul><figure name="d274" id="d274" class="graf graf--figure graf-after--li"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_BFG_B7UpS3AvJxE6lH0lug.gif"></figure><h4 name="9d5b" id="9d5b" class="graf graf--h4 graf-after--figure">Diagnosing lung cancer&nbsp;[<a href="https://youtu.be/IPBSB1HLNLo?t=56m55s" data-href="https://youtu.be/IPBSB1HLNLo?t=56m55s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">56:55</a>]</h4><figure name="d6e3" id="d6e3" class="graf graf--figure graf-after--h4"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1__E0tiKelpZ3_7u0rOo6T5A.png"></figure><p name="9bf7" id="9bf7" class="graf graf--p graf-after--figure">Other current applications:</p><figure name="1632" id="1632" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_LtaJU-2GsBanHnxavDysDA.png"></figure><h3 name="4f4e" id="4f4e" class="graf graf--h3 graf-after--figure">Convolutional Neural Network&nbsp;[<a href="https://youtu.be/IPBSB1HLNLo?t=59m13s" data-href="https://youtu.be/IPBSB1HLNLo?t=59m13s" class="markup--anchor markup--h3-anchor" rel="nofollow noopener" target="_blank">59:13</a>]</h3><h4 name="40e8" id="40e8" class="graf graf--h4 graf-after--h3">Linear Layer</h4><p name="ac5b" id="ac5b" class="graf graf--p graf-after--h4"><a href="http://setosa.io/ev/image-kernels/" data-href="http://setosa.io/ev/image-kernels/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">http://setosa.io/ev/image-kernels/</a></p><figure name="08bf" id="08bf" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_saLeHFHg9zMRmmCAR-qqzA.png"></figure><h4 name="4e14" id="4e14" class="graf graf--h4 graf-after--figure">Nonlinear Layer [<a href="https://youtu.be/IPBSB1HLNLo?t=1h2m12s" data-href="https://youtu.be/IPBSB1HLNLo?t=1h2m12s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">01:02:12</a>]</h4><a href="http://neuralnetworksanddeeplearning.com/chap4.html" data-href="http://neuralnetworksanddeeplearning.com/chap4.html" class="markup--anchor markup--mixtapeEmbed-anchor" title="http://neuralnetworksanddeeplearning.com/chap4.html" rel="nofollow"><strong class="markup--strong markup--mixtapeEmbed-strong">Neural networks and deep learning</strong><br><em class="markup--em markup--mixtapeEmbed-em">In this chapter I give a simple and mostly visual explanation of the universality theorem. We'll go step by step…</em>neuralnetworksanddeeplearning.com</a><a href="http://neuralnetworksanddeeplearning.com/chap4.html" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="9ce4cd00b910d2805911a640bd3a05ed" data-thumbnail-img-id="0*f47bnyqylDnQqIg0." style="background-image: url(https://cdn-images-1.medium.com/fit/c/200/200/0*f47bnyqylDnQqIg0.);"></a><figure name="dab7" id="dab7" class="graf graf--figure graf--layoutOutsetRow is-partialWidth graf-after--mixtapeEmbed" style="width: 62.949%;" data-scroll="native"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_hdh2d_jl5YohqGU265ce5A.png"></figure><figure name="4f35" id="4f35" class="graf graf--figure graf--layoutOutsetRowContinue is-partialWidth graf-after--figure" style="width: 37.051%;" data-scroll="native"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_QindKA4Dt7Ol3CbICMSxWw.png"><figcaption class="imageCaption" style="width: 269.898%; left: -169.898%;">Sigmoid and&nbsp;ReLU</figcaption></figure><ul class="postList"><li name="1e1e" id="1e1e" class="graf graf--li graf-after--figure"><span class="markup--quote markup--li-quote is-other" name="anon_2102015ed018" data-creator-ids="anon">A combination of linear layer followed by an element-wise nonlinear function allows us to create arbitrarily complex shapes — this is the essence of the universal approximation theorem.</span></li></ul><h4 name="80a9" id="80a9" class="graf graf--h4 graf-after--li">How to set these parameters to solve problems [<a href="https://youtu.be/IPBSB1HLNLo?t=1h4m25s" data-href="https://youtu.be/IPBSB1HLNLo?t=1h4m25s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">01:04:25</a>]</h4><ul class="postList"><li name="632d" id="632d" class="graf graf--li graf-after--h4">Stochastic Gradient Descent — we take small steps down the hill. The step size is called <strong class="markup--strong markup--li-strong">learning rate</strong></li></ul><figure name="60c9" id="60c9" class="graf graf--figure graf-after--li"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_BOJUtuAtlS9wUUyj0JJCHw.gif"></figure><figure name="dca0" id="dca0" class="graf graf--figure graf-after--figure"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_YQWdnHVTRPGjr0-VGuSxyA.jpeg"></figure><ul class="postList"><li name="25de" id="25de" class="graf graf--li graf-after--figure">If learning rate is too large, it will diverge instead of converge</li><li name="8408" id="8408" class="graf graf--li graf-after--li">If learning rate is too small, it will take forever</li></ul><h4 name="212c" id="212c" class="graf graf--h4 graf-after--li">Visualizing and Understanding Convolutional Networks [<a href="https://youtu.be/IPBSB1HLNLo?t=1h8m27s" data-href="https://youtu.be/IPBSB1HLNLo?t=1h8m27s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">01:08:27</a>]</h4><figure name="d240" id="d240" class="graf graf--figure graf-after--h4"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_RPakI9UqMTYmGIm4ELhh6w.png"></figure><p name="308c" id="308c" class="graf graf--p graf-after--figure">We started with something incredibly simple but if we use it as a big enough scale, thanks to the universal approximation theorem and the use of multiple hidden layers in deep learning, we actually get the very very rich capabilities. This is actually what we used when we used when we trained our dog vs cat recognizer.</p><h4 name="8b0a" id="8b0a" class="graf graf--h4 graf-after--p">Dog vs. Cat Revisited — Choosing a learning rate [<a href="https://youtu.be/IPBSB1HLNLo?t=1h11m41s" data-href="https://youtu.be/IPBSB1HLNLo?t=1h11m41s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">01:11:41</a>]</h4><pre name="c398" id="c398" class="graf graf--pre graf-after--h4">learn.fit(0.01, 3)</pre><ul class="postList"><li name="9ba1" id="9ba1" class="graf graf--li graf-after--pre">The first number <code class="markup--code markup--li-code">0.01</code> is the learning rate.</li><li name="ec77" id="ec77" class="graf graf--li graf-after--li">The <em class="markup--em markup--li-em">learning rate</em> determines how quickly or how slowly you want to update the <em class="markup--em markup--li-em">weights</em> (or <em class="markup--em markup--li-em">parameters</em>). Learning rate is one of the most difficult parameters to set, because it significantly affect model performance.</li><li name="04f2" id="04f2" class="graf graf--li graf-after--li">The method <code class="markup--code markup--li-code">learn.lr_find()</code> helps you find an optimal learning rate. It uses the technique developed in the 2015 paper <a href="http://arxiv.org/abs/1506.01186" data-href="http://arxiv.org/abs/1506.01186" class="markup--anchor markup--li-anchor" rel="noopener nofollow" target="_blank">Cyclical Learning Rates for Training Neural Networks</a>, where we simply keep increasing the learning rate from a very small value, until the loss stops decreasing. We can plot the learning rate across batches to see what this looks like.</li></ul><pre name="600f" id="600f" class="graf graf--pre graf-after--li">learn = ConvLearner.pretrained(arch, data, precompute=<strong class="markup--strong markup--pre-strong">True</strong>)<br>learn.lr_find()</pre><p name="590e" id="590e" class="graf graf--p graf-after--pre">Our <code class="markup--code markup--p-code">learn</code> object contains an attribute <code class="markup--code markup--p-code">sched</code> that contains our learning rate scheduler, and has some convenient plotting functionality including this one:</p><pre name="785c" id="785c" class="graf graf--pre graf-after--p">learn.sched.plot_lr()</pre><figure name="2a4f" id="2a4f" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_iGjSbGhX60ZZ3bHbqaIURQ.png"></figure><ul class="postList"><li name="67cb" id="67cb" class="graf graf--li graf-after--figure">Jeremy is currently experimenting with increasing the learning rate exponentially vs. linearly.</li></ul><p name="0228" id="0228" class="graf graf--p graf-after--li">We can see the plot of loss versus learning rate to see where our loss stops decreasing:</p><pre name="3574" id="3574" class="graf graf--pre graf-after--p">learn.sched.plot()</pre><figure name="735b" id="735b" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_CWF7v1ihFka2QG4RebgqjQ.png"></figure><ul class="postList"><li name="e73a" id="e73a" class="graf graf--li graf-after--figure">We then pick the learning rate where the loss is still clearly improving — in this case <code class="markup--code markup--li-code">1e-2</code> (0.01)</li></ul><h4 name="f3ed" id="f3ed" class="graf graf--h4 graf-after--li">Choosing number of epochs [<a href="https://youtu.be/IPBSB1HLNLo?t=1h18m49s" data-href="https://youtu.be/IPBSB1HLNLo?t=1h18m49s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:18:49</a>]</h4><pre name="1ffc" id="1ffc" class="graf graf--pre graf-after--h4"><em class="markup--em markup--pre-em">[ 0.       0.04955  0.02605  0.98975]                         <br>[ 1.       0.03977  0.02916  0.99219]                         <br>[ 2.       0.03372  0.02929  0.98975]</em></pre><ul class="postList"><li name="5b27" id="5b27" class="graf graf--li graf-after--pre">As many as you would like, but accuracy might start getting worse if you run it for too long. It is something called “overfitting” and we will learn more about it later.</li><li name="2f26" id="2f26" class="graf graf--li graf-after--li">Another consideration is the time available to you.</li></ul><h4 name="e165" id="e165" class="graf graf--h4 graf-after--li">Tips and Tricks [<a href="https://youtu.be/IPBSB1HLNLo?t=1h21m40s" data-href="https://youtu.be/IPBSB1HLNLo?t=1h21m40s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:21:40</a>]</h4><p name="63df" id="63df" class="graf graf--p graf-after--h4"><strong class="markup--strong markup--p-strong">1.</strong><code class="markup--code markup--p-code">Tab</code> — it will do an auto complete when you cannot remember the function name</p><figure name="3832" id="3832" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_g5JpxoRhb-rIPeaXlrII1w.png"></figure><p name="ef47" id="ef47" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">2.</strong> <code class="markup--code markup--p-code">Shift + Tab</code> — it will show you the arguments of a function</p><figure name="091f" id="091f" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_u5P7II8U2C-6tYpQoTyIVA.png"></figure><p name="767d" id="767d" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">3.</strong> <code class="markup--code markup--p-code">Shift + Tab + Tab</code> — it will bring up a documentation (i.e. docstring)</p><figure name="a569" id="a569" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_bCD9vgqELl-M4qQY2WU-Zw.png"></figure><p name="491f" id="491f" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">4.</strong> <code class="markup--code markup--p-code">Shift + Tab + Tab + Tab</code> — it will open a separate window with the same information.</p><figure name="8106" id="8106" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_632kupN-LwycuzR7wLBwKA.png"></figure><p name="9f2f" id="9f2f" class="graf graf--p graf-after--figure">Typing&nbsp;<code class="markup--code markup--p-code">?</code> followed by a function name in a cell and running it will do the same as <code class="markup--code markup--p-code">shift + tab (3 times)</code></p><figure name="9980" id="9980" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_fCXsVFZq_0Pmsa8-g_5nUg.png"></figure><p name="1d6b" id="1d6b" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">5.</strong> Typing two question mark will display the source code</p><figure name="48b8" id="48b8" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_rmoEReBWYIfc-Kgz-QOgWQ.png"></figure><p name="1367" id="1367" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">6. </strong>Typing <code class="markup--code markup--p-code">H</code> in Jupyter Notebook will open up a window with keyboard shortcuts. Try learning 4 or 5 shortcuts a day</p><figure name="666d" id="666d" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_z0rM6FP5gJZExHbmsVr5Xg.png"></figure><p name="1563" id="1563" class="graf graf--p graf-after--figure"><strong class="markup--strong markup--p-strong">7. </strong>Stop Paperspace, Crestle, AWS — otherwise you’ll be charged $$</p><p name="53f3" id="53f3" class="graf graf--p graf-after--p graf--trailing"><strong class="markup--strong markup--p-strong">8. </strong>Please remember about the <a href="http://forums.fast.ai/" data-href="http://forums.fast.ai/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">forum</a> and <a href="http://course.fast.ai/" data-href="http://course.fast.ai/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">http://course.fast.ai/</a> (for each lesson) for up-to-date information.</p><hr class="section-divider"><p name="96b4" id="96b4" class="graf graf--p graf--leading graf--trailing">Lessons: <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" class="markup--anchor markup--p-anchor" target="_blank"><strong class="markup--strong markup--p-strong">1</strong></a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" class="markup--anchor markup--p-anchor" target="_blank">2</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" class="markup--anchor markup--p-anchor" target="_blank">3</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" class="markup--anchor markup--p-anchor" target="_blank">4</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" class="markup--anchor markup--p-anchor" target="_blank">5</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" class="markup--anchor markup--p-anchor" target="_blank">6</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" class="markup--anchor markup--p-anchor" target="_blank">7</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" class="markup--anchor markup--p-anchor" target="_blank">8</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" class="markup--anchor markup--p-anchor" target="_blank">9</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" class="markup--anchor markup--p-anchor" target="_blank">10</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" class="markup--anchor markup--p-anchor" target="_blank">11</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" class="markup--anchor markup--p-anchor" target="_blank">12</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" class="markup--anchor markup--p-anchor" target="_blank">13</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" class="markup--anchor markup--p-anchor" target="_blank">14</a></p></body></html>