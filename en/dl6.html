
<!-- saved from url=(0063)file:///C:/Users/asus/Desktop/fastai-ml-dl-notes-zh/en/dl6.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></head><body><hr class="section-divider"><h1 name="6615" id="6615" class="graf graf--h3 graf--leading graf--title">Deep Learning 2: Part 1 Lesson&nbsp;6</h1><p name="cff8" id="cff8" class="graf graf--p graf-after--h3"><em class="markup--em markup--p-em">My personal notes from </em><a href="http://www.fast.ai/" data-href="http://www.fast.ai/" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank"><em class="markup--em markup--p-em">fast.ai course</em></a><em class="markup--em markup--p-em">. These notes will continue to be updated and improved as I continue to review the course to “really” understand it. Much appreciation to </em><a href="https://twitter.com/jeremyphoward" data-href="https://twitter.com/jeremyphoward" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank"><em class="markup--em markup--p-em">Jeremy</em></a><em class="markup--em markup--p-em"> and </em><a href="https://twitter.com/math_rachel" data-href="https://twitter.com/math_rachel" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank"><em class="markup--em markup--p-em">Rachel</em></a><em class="markup--em markup--p-em"> who gave me this opportunity to learn.</em></p><p name="c832" id="c832" class="graf graf--p graf-after--p graf--trailing">Lessons: <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" class="markup--anchor markup--p-anchor" target="_blank">1</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" class="markup--anchor markup--p-anchor" target="_blank">2</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" class="markup--anchor markup--p-anchor" target="_blank">3</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" class="markup--anchor markup--p-anchor" target="_blank">4</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" class="markup--anchor markup--p-anchor" target="_blank">5</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" class="markup--anchor markup--p-anchor" target="_blank"><strong class="markup--strong markup--p-strong">6</strong></a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" class="markup--anchor markup--p-anchor" target="_blank">7</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" class="markup--anchor markup--p-anchor" target="_blank">8</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" class="markup--anchor markup--p-anchor" target="_blank">9</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" class="markup--anchor markup--p-anchor" target="_blank">10</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" class="markup--anchor markup--p-anchor" target="_blank">11</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" class="markup--anchor markup--p-anchor" target="_blank">12</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" class="markup--anchor markup--p-anchor" target="_blank">13</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" class="markup--anchor markup--p-anchor" target="_blank">14</a></p><hr class="section-divider"><h3 name="4323" id="4323" class="graf graf--h3 graf--leading"><a href="http://forums.fast.ai/t/wiki-lesson-6/9404" data-href="http://forums.fast.ai/t/wiki-lesson-6/9404" class="markup--anchor markup--h3-anchor" rel="nofollow noopener" target="_blank">Lesson 6</a></h3><a href="http://ruder.io/deep-learning-optimization-2017/index.html" data-href="http://ruder.io/deep-learning-optimization-2017/index.html" class="markup--anchor markup--mixtapeEmbed-anchor" title="http://ruder.io/deep-learning-optimization-2017/index.html" rel="nofollow"><strong class="markup--strong markup--mixtapeEmbed-strong">Optimization for Deep Learning Highlights in 2017</strong><br><em class="markup--em markup--mixtapeEmbed-em">Table of contents: Deep Learning ultimately is about finding a minimum that generalizes well -- with bonus points for…</em>ruder.io</a><a href="http://ruder.io/deep-learning-optimization-2017/index.html" class="js-mixtapeImage mixtapeImage mixtapeImage--empty u-ignoreBlock" data-media-id="cc3a6514c19d7500dcdba37b25670a54"></a><p name="0588" id="0588" class="graf graf--p graf-after--mixtapeEmbed">Review from last week [<a href="https://youtu.be/sHcLkfRrgoQ?t=2m15s" data-href="https://youtu.be/sHcLkfRrgoQ?t=2m15s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">2:15</a>]</p><p name="4ae9" id="4ae9" class="graf graf--p graf-after--p">We took a deep dive to collaborative filtering last week, and we ended up re-creating <code class="markup--code markup--p-code">EmbeddingDotBias</code> class (<code class="markup--code markup--p-code">column_data.py</code>) in fast.ai library. Let’s visualize what the embeddings look like [<a href="https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb" data-href="https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">notebook</a>].</p><p name="090b" id="090b" class="graf graf--p graf-after--p">Inside of a learner <code class="markup--code markup--p-code">learn</code>, you can get a PyTorch model itself by calling <code class="markup--code markup--p-code">learn.model</code>&nbsp;. <code class="markup--code markup--p-code">@property</code> looks like a regular function, but requires no parenthesis when you call it.</p><pre name="1d03" id="1d03" class="graf graf--pre graf-after--p">@property<br>def model(self): return self.models.model</pre><p name="1376" id="1376" class="graf graf--p graf-after--pre"><code class="markup--code markup--p-code">learn.models</code> is an instance of <code class="markup--code markup--p-code">CollabFilterModel</code> which is a thin wrapper of PyTorch model that allows us to use “layer groups” which is not a concept available in PyTorch and fast.ai uses it to apply different learning rates to different sets of layers (layer group).</p><p name="513d" id="513d" class="graf graf--p graf-after--p">PyTorch model prints out the layers nicely including layer name which is what we called them in the code.</p><pre name="061b" id="061b" class="graf graf--pre graf-after--p">m=learn.model; m</pre><pre name="b5a5" id="b5a5" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">EmbeddingDotBias (<br>  (u): Embedding(671, 50)<br>  (i): Embedding(9066, 50)<br>  (ub): Embedding(671, 1)<br>  (ib): Embedding(9066, 1)<br>)</em></pre><figure name="b18a" id="b18a" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_4MrbqWktWz3oroYWn5Xh6w.png"></figure><p name="fdb1" id="fdb1" class="graf graf--p graf-after--figure"><code class="markup--code markup--p-code">m.ib</code> refers to an embedding layer for an item bias — movie bias, in our case. What is nice about PyTorch models and layers is that we can call them as if they are functions. So if you want to get a prediction, you call <code class="markup--code markup--p-code">m(...)</code> and pass in variables.</p><p name="4ca8" id="4ca8" class="graf graf--p graf-after--p">Layers require variables not tensors because it needs to keep track of the derivatives — that is the reason for <code class="markup--code markup--p-code">V(...)</code> to convert tensor to variable. PyTorch 0.4 will get rid of variables and we will be able to use tensors directly.</p><pre name="aee2" id="aee2" class="graf graf--pre graf-after--p">movie_bias = to_np(m.ib(V(topMovieIdx)))</pre><p name="659d" id="659d" class="graf graf--p graf-after--pre">The <code class="markup--code markup--p-code">to_np</code> function will take a variable or a tensor (regardless of being on the CPU or GPU) and returns a numpy array. Jeremy’s approach [<a href="https://youtu.be/sHcLkfRrgoQ?t=12m3s" data-href="https://youtu.be/sHcLkfRrgoQ?t=12m3s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">12:03</a>] is to use numpy for everything except when he explicitly needs something to run on the GPU or he needs its derivatives — in which case he uses PyTorch. Numpy has been around longer than PyTorch and works well with other libraries such as OpenCV, Pandas, etc.</p><p name="7be3" id="7be3" class="graf graf--p graf-after--p">A question regarding CPU vs. GPU in production. The suggested approach is to do inference on CPU as it is more scalable and you do not need to put things in batches. You can move a model onto the CPU by typing <code class="markup--code markup--p-code">m.cpu()</code>, similarly a variable by typing<code class="markup--code markup--p-code">V(topMovieIndex).cpu()</code> (from CPU to GPU would be <code class="markup--code markup--p-code">m.cuda()</code>).If your server does not have GPU, it will run inference on CPU automatically. For loading a saved model that was trained on GPU, take a look at this line of code in <code class="markup--code markup--p-code">torch_imports.py</code>:</p><pre name="13b0" id="13b0" class="graf graf--pre graf-after--p">def load_model(m, p): m.load_state_dict(torch.load(p, map_location=lambda storage, loc: storage))</pre><p name="8bf8" id="8bf8" class="graf graf--p graf-after--pre">Now that we have movie bias for top 3000 movies, and let’s take a look at ratings:</p><pre name="ef4b" id="ef4b" class="graf graf--pre graf-after--p">movie_ratings = [(b[0], movie_names[i]) <strong class="markup--strong markup--pre-strong">for</strong> i,b <strong class="markup--strong markup--pre-strong">in</strong> zip(topMovies,movie_bias)]</pre><p name="c376" id="c376" class="graf graf--p graf-after--pre"><code class="markup--code markup--p-code">zip</code> will allow you to iterate through multiple lists at the same time.</p><h4 name="b8a8" id="b8a8" class="graf graf--h4 graf-after--p">Worst movies</h4><p name="1523" id="1523" class="graf graf--p graf-after--h4">About sorting key — Python has <code class="markup--code markup--p-code">itemgetter</code> function but plain <code class="markup--code markup--p-code">lambda</code> is just one more character.</p><pre name="ceff" id="ceff" class="graf graf--pre graf-after--p">sorted(movie_ratings, key=<strong class="markup--strong markup--pre-strong">lambda</strong> o: o[0])[:15]</pre><pre name="0055" id="0055" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[(-0.96070349, 'Battlefield Earth (2000)'),<br> (-0.76858485, 'Speed 2: Cruise Control (1997)'),<br> (-0.73675376, 'Wild Wild West (1999)'),<br> (-0.73655486, 'Anaconda (1997)'),<br> ...]</em></pre><pre name="b236" id="b236" class="graf graf--pre graf-after--pre">sorted(movie_ratings, key=<strong class="markup--strong markup--pre-strong">itemgetter</strong>(0))[:15]</pre><h4 name="365a" id="365a" class="graf graf--h4 graf-after--pre">Best movies</h4><pre name="75cf" id="75cf" class="graf graf--pre graf-after--h4">sorted(movie_ratings, key=<strong class="markup--strong markup--pre-strong">lambda</strong> o: o[0], reverse=<strong class="markup--strong markup--pre-strong">True</strong>)[:15]</pre><pre name="1588" id="1588" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[(1.3070084, 'Shawshank Redemption, The (1994)'),<br> (1.1196285, 'Godfather, The (1972)'),<br> (1.0844109, 'Usual Suspects, The (1995)'),<br> (0.96578616, "Schindler's List (1993)"),<br> ...]</em></pre><h4 name="866b" id="866b" class="graf graf--h4 graf-after--pre">Embedding interpretation [<a href="https://youtu.be/sHcLkfRrgoQ?t=18m42s" data-href="https://youtu.be/sHcLkfRrgoQ?t=18m42s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">18:42</a>]</h4><p name="d192" id="d192" class="graf graf--p graf-after--h4">Each movie has 50 embeddings and it is hard to visualize 50 dimensional space, so we will turn it into a three dimensional space. We can compress dimensions using several techniques: Principal Component Analysis (<a href="https://plot.ly/ipython-notebooks/principal-component-analysis/" data-href="https://plot.ly/ipython-notebooks/principal-component-analysis/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">PCA</a>) (Rachel’s Computational Linear Algebra class covers this in detail — which is almost identical to Singular Value Decomposition (SVD))</p><pre name="a706" id="a706" class="graf graf--pre graf-after--p">movie_emb = to_np(m.i(V(topMovieIdx)))<br>movie_emb.shape</pre><pre name="cd75" id="cd75" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">(3000, 50)</em></pre><pre name="716e" id="716e" class="graf graf--pre graf-after--pre">from sklearn.decomposition import PCA<br>pca = PCA(n_components=3)<br>movie_pca = pca.fit(movie_emb.T).components_<br>movie_pca.shape</pre><pre name="e493" id="e493" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">(3, 3000)</em></pre><p name="be5d" id="be5d" class="graf graf--p graf-after--pre">We will take a look at the first dimension “easy watching vs. serious” (we do not know what it represents but can certainly speculate by looking at them):</p><pre name="86aa" id="86aa" class="graf graf--pre graf-after--p">fac0 = movie_pca[0] <br>movie_comp = [(f, movie_names[i]) <strong class="markup--strong markup--pre-strong">for</strong> f,i <strong class="markup--strong markup--pre-strong">in</strong> zip(fac0, topMovies)]<br>sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]</pre><pre name="7081" id="7081" class="graf graf--pre graf-after--pre">sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]</pre><pre name="b8fb" id="b8fb" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[(0.06748189, 'Independence Day (a.k.a. ID4) (1996)'),<br> (0.061572548, 'Police Academy 4: Citizens on Patrol (1987)'),<br> (0.061050549, 'Waterworld (1995)'),<br> (0.057877172, 'Rocky V (1990)'),<br> ...<br>]</em></pre><pre name="143e" id="143e" class="graf graf--pre graf-after--pre">sorted(movie_comp, key=itemgetter(0))[:10]</pre><pre name="d537" id="d537" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[(-0.078433245, 'Godfather: Part II, The (1974)'),<br> (-0.072180331, 'Fargo (1996)'),<br> (-0.071351372, 'Pulp Fiction (1994)'),<br> (-0.068537779, 'Goodfellas (1990)'),<br> ...<br>]</em></pre><p name="600e" id="600e" class="graf graf--p graf-after--pre">The second dimension “dialog driven vs. CGI”</p><pre name="59ab" id="59ab" class="graf graf--pre graf-after--p">fac1 = movie_pca[1]<br>movie_comp = [(f, movie_names[i]) for f,i in zip(fac1, topMovies)]<br>sorted(movie_comp, key=itemgetter(0), reverse=True)[:10]</pre><pre name="d94c" id="d94c" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[(0.058975246, 'Bonfire of the Vanities (1990)'),<br> (0.055992026, '2001: A Space Odyssey (1968)'),<br> (0.054682467, 'Tank Girl (1995)'),<br> (0.054429606, 'Purple Rose of Cairo, The (1985)'),<br> ...]</em></pre><pre name="db89" id="db89" class="graf graf--pre graf-after--pre">sorted(movie_comp, key=itemgetter(0))[:10]</pre><pre name="616e" id="616e" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[(-0.1064609, 'Lord of the Rings: The Return of the King, The (2003)'),<br> (-0.090635143, 'Aladdin (1992)'),<br> (-0.089208141, 'Star Wars: Episode V - The Empire Strikes Back (1980)'),<br> (-0.088854566, 'Star Wars: Episode IV - A New Hope (1977)'),<br> ...]</em></pre><p name="f64e" id="f64e" class="graf graf--p graf-after--pre">Plot</p><pre name="2341" id="2341" class="graf graf--pre graf-after--p">idxs = np.random.choice(len(topMovies), 50, replace=False)<br>X = fac0[idxs]<br>Y = fac1[idxs]<br>plt.figure(figsize=(15,15))<br>plt.scatter(X, Y)<br>for i, x, y in zip(topMovies[idxs], X, Y):<br>    plt.text(x,y,movie_names[i], color=np.random.rand(3)*0.7, fontsize=11)<br>plt.show()</pre><figure name="56d6" id="56d6" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_rH0bFyR8qSj6MuV0Rn-waA.png"></figure><p name="6cb7" id="6cb7" class="graf graf--p graf-after--figure">What actually happens when you say <code class="markup--code markup--p-code">learn.fit</code>&nbsp;?</p><h4 name="8c6c" id="8c6c" class="graf graf--h4 graf-after--p"><a href="https://arxiv.org/pdf/1604.06737.pdf" data-href="https://arxiv.org/pdf/1604.06737.pdf" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">Entity Embeddings of Categorical Variables</a> [<a href="https://youtu.be/sHcLkfRrgoQ?t=24m42s" data-href="https://youtu.be/sHcLkfRrgoQ?t=24m42s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">24:42</a>]</h4><p name="8054" id="8054" class="graf graf--p graf-after--h4">The second paper to talk about categorical embeddings. FIG. 1. caption should sound familiar as they talk about how entity embedding layers are equivalent to one-hot encoding followed by a matrix multiplication.</p><figure name="04a2" id="04a2" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_BgBtlqi7Ja6aQ8wGvWQbgQ.png"></figure><p name="1278" id="1278" class="graf graf--p graf-after--figure">The interesting thing they did was, they took the entity embeddings trained by a neural network, replaced each categorical variable with the learned entity embeddings, then fed that into Gradient Boosting Machine (GBM), Random Forest (RF), and KNN — which reduced the error to something almost as good as neural network (NN). This is a great way to give the power of neural net within your organization without forcing others to learn deep learning because they can continue to use what they currently use and use the embeddings as input. GBM and RF train much faster than NN.</p><figure name="05b7" id="05b7" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_XYcNx7NmTyblDXa5diFMbg.png"></figure><p name="ca13" id="ca13" class="graf graf--p graf-after--figure">They also plotted the embeddings of states in Germany which interestingly (“whackingly enough” as Jeremy would call it) resembled an actual map.</p><p name="ab36" id="ab36" class="graf graf--p graf-after--p">They also plotted the distances of stores in physical space and embedding space — which showed a beautiful and clear correlation.</p><p name="7cd4" id="7cd4" class="graf graf--p graf-after--p">There also seems to be correlation between days of the week, or months of the year. Visualizing embeddings can be interesting as it shows you what you expected see or what you didn’t.</p><h4 name="b718" id="b718" class="graf graf--h4 graf-after--p">A question about Skip-Gram to generate embeddings [<a href="https://youtu.be/sHcLkfRrgoQ?t=31m31s" data-href="https://youtu.be/sHcLkfRrgoQ?t=31m31s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">31:31</a>]</h4><p name="09e4" id="09e4" class="graf graf--p graf-after--h4">Skip-Gram is specific to NLP. A good way to turn an unlabeled problem into a labeled problem is to “invent” labels. Word2Vec’s approach was to take a sentence of 11 words, delete the middle word, and replace it with a random word. Then they gave a label 1 to the original sentence; 0 to the fake one, and built a machine learning model to find the fake sentences. As a result, they now have embeddings they can use for other purposes. If you do this as a single matrix multiplier (shallow model) rather than deep neural net, you can train this very quickly — the disadvantage is that it is a less predictive model, but the advantages are that you can train on a very large dataset and more importantly, the resulting embeddings have <em class="markup--em markup--p-em">linear characteristics</em> which allow us to add, subtract, or draw nicely. In NLP, we should move past Word2Vec and Glove (i.e. linear based methods) because these embeddings are less predictive. The state of the art language model uses deep RNN.</p><h4 name="5c15" id="5c15" class="graf graf--h4 graf-after--p">To learn any kind of feature space, you either need labeled data or you need to invent a fake task&nbsp;[<a href="https://youtu.be/sHcLkfRrgoQ?t=35m45s" data-href="https://youtu.be/sHcLkfRrgoQ?t=35m45s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">35:45</a>]</h4><ul class="postList"><li name="c94a" id="c94a" class="graf graf--li graf-after--h4">Is one fake task better than another? Not well studied yet.</li><li name="1e6b" id="1e6b" class="graf graf--li graf-after--li">Intuitively, we want a task which helps a machine to learn the kinds of relationships that you care about.</li><li name="8580" id="8580" class="graf graf--li graf-after--li">In computer vision, a type of fake task people use is to apply unreal and unreasonable data augmentations.</li><li name="b4d1" id="b4d1" class="graf graf--li graf-after--li">If you can’t come up with great fake tasks, just use crappy one — it is often surprising how little you need.</li><li name="36e9" id="36e9" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Autoencoder</strong> [<a href="https://youtu.be/sHcLkfRrgoQ?t=38m10s" data-href="https://youtu.be/sHcLkfRrgoQ?t=38m10s" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">38:10</a>] — it recently won an <a href="https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629" data-href="https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">insurance claim competition</a>. Take a single policy, run it through neural net, and have it reconstruct itself (make sure that intermediate layers have less activations than the input variable). Basically, it is a task whose input = output which works surprisingly well as a fake task.</li></ul><p name="fd0c" id="fd0c" class="graf graf--p graf-after--li">In computer vision, you can train on cats and dogs and use it for CT scans. Maybe it might work for language/NLP! (future research)</p><h4 name="d815" id="d815" class="graf graf--h4 graf-after--p"><a href="https://github.com/fastai/fastai/blob/master/courses/dl1/lesson3-rossman.ipynb" data-href="https://github.com/fastai/fastai/blob/master/courses/dl1/lesson3-rossman.ipynb" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">Rossmann</a> [<a href="https://youtu.be/sHcLkfRrgoQ?t=41m4s" data-href="https://youtu.be/sHcLkfRrgoQ?t=41m4s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">41:04</a>]</h4><ul class="postList"><li name="9fa1" id="9fa1" class="graf graf--li graf-after--h4">A way to use test set properly was added to the notebook.</li><li name="8556" id="8556" class="graf graf--li graf-after--li">For more detailed explanations, see Machine Learning course.</li><li name="d99b" id="d99b" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">apply_cats(joined_test, joined)</code> is used to make sure that the test set and the training set have the same categorical codes.</li><li name="d0b0" id="d0b0" class="graf graf--li graf-after--li">Keep track of <code class="markup--code markup--li-code">mapper</code> which contains the mean and standard deviation of each continuous column, and apply the same <code class="markup--code markup--li-code">mapper</code> to the test set.</li><li name="80f4" id="80f4" class="graf graf--li graf-after--li">Do not rely on Kaggle public board — rely on your own thoughtfully created validation set.</li></ul><h4 name="5f3e" id="5f3e" class="graf graf--h4 graf-after--li">Going over a good <a href="https://www.kaggle.com/thie1e/exploratory-analysis-rossmann" data-href="https://www.kaggle.com/thie1e/exploratory-analysis-rossmann" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">Kernel</a> for&nbsp;Rossmann</h4><ul class="postList"><li name="2ebb" id="2ebb" class="graf graf--li graf-after--h4">Sunday effect on sales</li></ul><p name="c31b" id="c31b" class="graf graf--p graf-after--li">There is a jump on sales before and after the store closing. 3rd place winner deleted closed store rows before they started any analysis.</p><blockquote name="2717" id="2717" class="graf graf--pullquote graf-after--p"><span class="markup--quote markup--pullquote-quote is-other" name="anon_608d0015410f" data-creator-ids="anon"><strong class="markup--strong markup--pullquote-strong">Don’t touch your data unless you, first of all, analyze to see what you are doing is okay — no assumptions.</strong></span></blockquote><h4 name="d33e" id="d33e" class="graf graf--h4 graf-after--pullquote">Vim tricks&nbsp;[<a href="https://youtu.be/sHcLkfRrgoQ?t=49m12s" data-href="https://youtu.be/sHcLkfRrgoQ?t=49m12s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">49:12</a>]</h4><ul class="postList"><li name="805b" id="805b" class="graf graf--li graf-after--h4"><code class="markup--code markup--li-code">:tag ColumnarModelData</code> will take you to the class definition</li><li name="0f83" id="0f83" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">ctrl + ]</code> will take you to a definition of what’s under the cursor</li><li name="c025" id="c025" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">ctrl + t</code> to go back</li><li name="8c78" id="8c78" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">*</code> to find the usage of what’s under the cursor</li><li name="845d" id="845d" class="graf graf--li graf-after--li">You can switch between tabs with&nbsp;<code class="markup--code markup--li-code">:tabn</code> and&nbsp;<code class="markup--code markup--li-code">:tabp</code>, With&nbsp;<code class="markup--code markup--li-code">:tabe &lt;filepath&gt;</code> you can add a new tab; and with a regular&nbsp;<code class="markup--code markup--li-code">:q</code> or&nbsp;<code class="markup--code markup--li-code">:wq</code> you close a tab. If you map&nbsp;<code class="markup--code markup--li-code">:tabn</code> and&nbsp;<code class="markup--code markup--li-code">:tabp</code> to your F7/F8 keys you can easily switch between files.</li></ul><h4 name="bfc6" id="bfc6" class="graf graf--h4 graf-after--li">Inside of ColumnarModelData [<a href="https://youtu.be/sHcLkfRrgoQ?t=51m1s" data-href="https://youtu.be/sHcLkfRrgoQ?t=51m1s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">51:01</a>]</h4><p name="6ec9" id="6ec9" class="graf graf--p graf-after--h4">Slowly but surely, what used to be just “magic” start to look familiar. As you can see, <code class="markup--code markup--p-code">get_learner</code> returns <code class="markup--code markup--p-code">Learner</code> which is fast.ai concept that wraps data and PyTorch model:</p><figure name="3a1b" id="3a1b" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_Fda8NgH2L9m3d_UIdNsKCQ.png"></figure><p name="f8ba" id="f8ba" class="graf graf--p graf-after--figure">Inside of <code class="markup--code markup--p-code">MixedInputModel</code> you see how it is creating <code class="markup--code markup--p-code">Embedding</code> which we now know more about. <code class="markup--code markup--p-code">nn.ModuleList</code> is used to register a list of layers. We will talk about <code class="markup--code markup--p-code">BatchNorm</code> next week, but rest, we have seen before.</p><figure name="4dda" id="4dda" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_7E46VmEHXatQWNY2s7D9-g.png"></figure><p name="39fd" id="39fd" class="graf graf--p graf-after--figure">Similarly, we now understand what’s going on in the <code class="markup--code markup--p-code">forward</code> function.</p><ul class="postList"><li name="0806" id="0806" class="graf graf--li graf-after--p">call embedding layer with<em class="markup--em markup--li-em"> i</em>th categorical variable and concatenate them all together</li><li name="b920" id="b920" class="graf graf--li graf-after--li">put that through dropout</li><li name="7f12" id="7f12" class="graf graf--li graf-after--li">go through each one of our linear layers, call it, apply relu and dropout</li><li name="e8de" id="e8de" class="graf graf--li graf-after--li">then final linear layer has a size of 1</li><li name="1df4" id="1df4" class="graf graf--li graf-after--li">if <code class="markup--code markup--li-code">y_range</code> is passed in, apply sigmoid and fit the output within a range (which we learned last week)</li></ul><figure name="2266" id="2266" class="graf graf--figure graf-after--li"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_Ry2bDxD36x8zV9KfH_IL9Q.png"></figure><h4 name="471c" id="471c" class="graf graf--h4 graf-after--figure"><a href="https://github.com/fastai/fastai/blob/master/courses/dl1/lesson6-sgd.ipynb" data-href="https://github.com/fastai/fastai/blob/master/courses/dl1/lesson6-sgd.ipynb" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">Stochastic Gradient Descent — SGD</a>&nbsp;[<a href="https://youtu.be/sHcLkfRrgoQ?t=59m56s" data-href="https://youtu.be/sHcLkfRrgoQ?t=59m56s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">59:56</a>]</h4><p name="607b" id="607b" class="graf graf--p graf-after--h4">To make sure we are totally comfortable with SGD, we will use it to learn <code class="markup--code markup--p-code"><em class="markup--em markup--p-em">y = ax + b</em></code>&nbsp;. If we can solve something with 2 parameters, we can use the same technique to solve 100 million parameters.</p><pre name="2182" id="2182" class="graf graf--pre graf-after--p"><em class="markup--em markup--pre-em"># Here we generate some fake data</em><br><strong class="markup--strong markup--pre-strong">def</strong> lin(a,b,x): <strong class="markup--strong markup--pre-strong">return</strong> a*x+b<br><br><strong class="markup--strong markup--pre-strong">def</strong> gen_fake_data(n, a, b):<br>    x = s = np.random.uniform(0,1,n) <br>    y = lin(a,b,x) + 0.1 * np.random.normal(0,3,n)<br>    <strong class="markup--strong markup--pre-strong">return</strong> x, y<br><br>x, y = gen_fake_data(50, 3., 8.)<br><br>plt.scatter(x,y, s=8); plt.xlabel("x"); plt.ylabel("y");</pre><figure name="bcd4" id="bcd4" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_28U8r1xSD7ODB9BZnGHNZg.png"></figure><p name="31b0" id="31b0" class="graf graf--p graf-after--figure">To get started, we need a loss function. This is a regression problem since the output is continuous output, and the most common loss function is the mean squared error (MSE).</p><blockquote name="c847" id="c847" class="graf graf--blockquote graf-after--p">Regression — the target output is a real number or a whole vector of real numbers</blockquote><blockquote name="b253" id="b253" class="graf graf--blockquote graf-after--blockquote">Classification — the target output is a class label</blockquote><pre name="0f6f" id="0f6f" class="graf graf--pre graf-after--blockquote"><strong class="markup--strong markup--pre-strong">def</strong> <strong class="markup--strong markup--pre-strong">mse</strong>(y_hat, y): <strong class="markup--strong markup--pre-strong">return</strong> ((y_hat - y) ** 2).mean()</pre><pre name="4cb3" id="4cb3" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">def</strong> <strong class="markup--strong markup--pre-strong">mse_loss</strong>(a, b, x, y): <strong class="markup--strong markup--pre-strong">return</strong> mse(lin(a,b,x), y)</pre><ul class="postList"><li name="f0f5" id="f0f5" class="graf graf--li graf-after--pre"><code class="markup--code markup--li-code">y_hat</code> — predictions</li></ul><p name="317a" id="317a" class="graf graf--p graf-after--li">We will make 10,000 more fake data and turn them into PyTorch variables because Jeremy doesn’t like taking derivatives and PyTorch can do that for him:</p><pre name="e0bc" id="e0bc" class="graf graf--pre graf-after--p">x, y = gen_fake_data(10000, 3., 8.) <br>x,y = V(x),V(y)</pre><p name="b6eb" id="b6eb" class="graf graf--p graf-after--pre">Then create random weight for <code class="markup--code markup--p-code">a</code> and <code class="markup--code markup--p-code">b</code>&nbsp;, they are the variables we want to learn, so set <code class="markup--code markup--p-code">requires_grad=True</code>&nbsp;.</p><pre name="f7a2" id="f7a2" class="graf graf--pre graf-after--p">a = V(np.random.randn(1), requires_grad=<strong class="markup--strong markup--pre-strong">True</strong>) <br>b = V(np.random.randn(1), requires_grad=<strong class="markup--strong markup--pre-strong">True</strong>)</pre><p name="ebad" id="ebad" class="graf graf--p graf-after--pre">Then set the learning rate and do 10,000 epoch of full gradient descent (not SGD as each epoch will look at all of the data):</p><pre name="b184" id="b184" class="graf graf--pre graf-after--p">learning_rate = 1e-3<br><strong class="markup--strong markup--pre-strong">for</strong> t <strong class="markup--strong markup--pre-strong">in</strong> range(10000):<br>    <em class="markup--em markup--pre-em"># Forward pass: compute predicted y using operations on Variables</em><br>    loss = mse_loss(a,b,x,y)<br>    <strong class="markup--strong markup--pre-strong">if</strong> t % 1000 == 0: print(loss.data[0])<br>    <br>    <em class="markup--em markup--pre-em"># Computes the gradient of loss with respect to all Variables with requires_grad=True.</em><br>    <em class="markup--em markup--pre-em"># After this call a.grad and b.grad will be Variables holding the gradient</em><br>    <em class="markup--em markup--pre-em"># of the loss with respect to a and b respectively</em><br>    loss.backward()<br>    <br>    <em class="markup--em markup--pre-em"># Update a and b using gradient descent; a.data and b.data are Tensors,</em><br>    <em class="markup--em markup--pre-em"># a.grad and b.grad are Variables and a.grad.data and b.grad.data are Tensors</em><br>    a.data -= learning_rate * a.grad.data<br>    b.data -= learning_rate * b.grad.data<br>    <br>    <em class="markup--em markup--pre-em"># Zero the gradients</em><br>    a.grad.data.zero_()<br>    b.grad.data.zero_()</pre><figure name="e5f7" id="e5f7" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_LRtxJiNrnAX1o6mEnaiUpA.png"></figure><ul class="postList"><li name="9ed2" id="9ed2" class="graf graf--li graf-after--figure">calculate the loss (remember, <code class="markup--code markup--li-code">a</code> and <code class="markup--code markup--li-code">b</code> are set to random initially)</li><li name="2c3a" id="2c3a" class="graf graf--li graf-after--li">from time to time (every 1000 epochs), print out the loss</li><li name="2b9c" id="2b9c" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">loss.backward()</code> will calculate gradients for all variables with <code class="markup--code markup--li-code">requires_grad=True</code> and fill in&nbsp;<code class="markup--code markup--li-code">.grad</code> property</li><li name="9df0" id="9df0" class="graf graf--li graf-after--li">update <code class="markup--code markup--li-code">a</code> to whatever it was minus LR * <code class="markup--code markup--li-code">grad</code> (&nbsp;<code class="markup--code markup--li-code">.data</code> accesses a tensor inside of a variable)</li><li name="a10a" id="a10a" class="graf graf--li graf-after--li">when there are multiple loss functions or many output layers contributing to the gradient, PyTorch will add them together. So you need to tell when to set gradients back to zero (<code class="markup--code markup--li-code">zero_()</code> in the <code class="markup--code markup--li-code">_</code> means that the variable is changed in-place).</li><li name="f53c" id="f53c" class="graf graf--li graf-after--li">The last 4 lines of code is what is wrapped in <code class="markup--code markup--li-code">optim.SGD.step</code> function</li></ul><h4 name="c851" id="c851" class="graf graf--h4 graf-after--li">Let’s do this with just Numpy (without PyTorch) [<a href="https://youtu.be/sHcLkfRrgoQ?t=1h7m1s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h7m1s" class="markup--anchor markup--h4-anchor" rel="noopener nofollow" target="_blank">1:07:01</a>]</h4><p name="0e84" id="0e84" class="graf graf--p graf-after--h4">We actually have to do calculus, but everything else should look similar:</p><pre name="b1d5" id="b1d5" class="graf graf--pre graf-after--p">x, y = gen_fake_data(50, 3., 8.)</pre><pre name="417d" id="417d" class="graf graf--pre graf-after--pre">a_guess,b_guess = -1., 1.<br>mse_loss(y, a_guess, b_guess, x)</pre><pre name="e50d" id="e50d" class="graf graf--pre graf-after--pre">lr=0.01 <br><strong class="markup--strong markup--pre-strong">def</strong> <strong class="markup--strong markup--pre-strong">upd</strong>():<br>     <strong class="markup--strong markup--pre-strong">global</strong> a_guess, b_guess<br>     y_pred = lin(a_guess, b_guess, x)<br>     dydb = 2 * (y_pred - y)<br>     dyda = x*dydb<br>     a_guess -= lr*dyda.mean()<br>     b_guess -= lr*dydb.mean()</pre><p name="93fb" id="93fb" class="graf graf--p graf-after--pre">Just for fun, you can use <code class="markup--code markup--p-code">matplotlib.animation.FuncAnimation</code> to animate:</p><figure name="6fae" id="6fae" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_yGWe-bn7PoDqx0pZc2fjtg.png"></figure><p name="378b" id="378b" class="graf graf--p graf-after--figure">Tip: Fast.ai AMI did not come with <code class="markup--code markup--p-code">ffmpeg</code>&nbsp;. So if you see <code class="markup--code markup--p-code">KeyError: 'ffmpeg'</code></p><ul class="postList"><li name="7f8c" id="7f8c" class="graf graf--li graf-after--p">Run <code class="markup--code markup--li-code">print(animation.writers.list())</code> and print out a list of available MovieWriters</li><li name="4361" id="4361" class="graf graf--li graf-after--li">If <code class="markup--code markup--li-code">ffmpeg</code> is among it. Otherwise <a href="https://github.com/adaptlearning/adapt_authoring/wiki/Installing-FFmpeg" data-href="https://github.com/adaptlearning/adapt_authoring/wiki/Installing-FFmpeg" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">install it</a>.</li></ul><h3 name="e2c1" id="e2c1" class="graf graf--h3 graf-after--li"><a href="https://github.com/fastai/fastai/blob/master/courses/dl1/lesson6-rnn.ipynb" data-href="https://github.com/fastai/fastai/blob/master/courses/dl1/lesson6-rnn.ipynb" class="markup--anchor markup--h3-anchor" rel="noopener nofollow" target="_blank">Recurrent Neural Network — RNN</a> [<a href="https://youtu.be/sHcLkfRrgoQ?t=1h9m16s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h9m16s" class="markup--anchor markup--h3-anchor" rel="noopener nofollow" target="_blank">1:09:16</a>]</h3><p name="d811" id="d811" class="graf graf--p graf-after--h3">Let’s learn how to write philosophy like Nietzsche. This is similar to a language model we learned in lesson 4, but this time, we will do it one character at a time. RNN is no different from what we have already learned.</p><figure name="decb" id="decb" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_wIccxf1fG4jtSZhLHTtw-A.png"></figure><h4 name="1099" id="1099" class="graf graf--h4 graf-after--figure">Some examples:</h4><ul class="postList"><li name="c80e" id="c80e" class="graf graf--li graf-after--h4"><a href="https://blog.swiftkey.com/neural-networks-a-meaningful-leap-for-mobile-typing/" data-href="https://blog.swiftkey.com/neural-networks-a-meaningful-leap-for-mobile-typing/" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">SwiftKey</a></li><li name="68a8" id="68a8" class="graf graf--li graf-after--li"><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" data-href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">Andrej Karpathy LaTex generator</a></li></ul><h4 name="b08a" id="b08a" class="graf graf--h4 graf-after--li">Basic NN with single hidden&nbsp;layer</h4><p name="a849" id="a849" class="graf graf--p graf-after--h4">All shapes are activations (an activation is a number that has been calculated by a relu, matrix product, etc.). An arrow is a layer operation (possibly more than one). Check out Machine Learning course lesson 9–11 for creating this from scratch.</p><figure name="7565" id="7565" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_vPfe01ALNgbxw8DP_4RFVw.png"></figure><h4 name="5fd9" id="5fd9" class="graf graf--h4 graf-after--figure">Image CNN with single dense hidden&nbsp;layer</h4><p name="b58c" id="b58c" class="graf graf--p graf-after--h4">We will cover how to flatten a layer next week more, but the main method is called “adaptive max pooling” — where we average across the height and the width and turn it into a vector.</p><figure name="5c2b" id="5c2b" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_VEEVatttQmlWeI98vTO0iA.png"><figcaption class="imageCaption"><code class="markup--code markup--figure-code">batch_size</code> dimension and activation function (e.g. relu, softmax) are not shown&nbsp;here</figcaption></figure><h4 name="f48d" id="f48d" class="graf graf--h4 graf-after--figure">Predicting char 3 using chars 1 &amp; 2 [<a href="https://youtu.be/sHcLkfRrgoQ?t=1h18m4s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h18m4s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:18:04</a>]</h4><p name="cc44" id="cc44" class="graf graf--p graf-after--h4">We are going to implement this one for NLP.</p><ul class="postList"><li name="69d8" id="69d8" class="graf graf--li graf-after--p">Input can be one-hot-encoded character (length of vector = # of unique characters) or a single integer and pretend it is one-hot-encoded by using an embedding layer.</li><li name="b825" id="b825" class="graf graf--li graf-after--li">The difference from the CNN one is that then char 2 inputs gets added.</li></ul><figure name="161d" id="161d" class="graf graf--figure graf-after--li"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_gc1z1R1d5zHkYc75iqSWtw.png"><figcaption class="imageCaption">layer operations not shown; remember arrows represent layer operations</figcaption></figure><p name="9905" id="9905" class="graf graf--p graf-after--figure">Let’s implement this without torchtext or fast.ai library so we can see.</p><ul class="postList"><li name="3289" id="3289" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">set</code> will return all unique characters.</li></ul><pre name="1243" id="1243" class="graf graf--pre graf-after--li">text = open(f'{PATH}nietzsche.txt').read()<br>print(text[:400])</pre><pre name="291e" id="291e" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">'PREFACE\n\n\nSUPPOSING that Truth is a woman--what then? Is there not ground\nfor suspecting that all philosophers, in so far as they have been\ndogmatists, have failed to understand women--that the terrible\nseriousness and clumsy importunity with which they have usually paid\ntheir addresses to Truth, have been unskilled and unseemly methods for\nwinning a woman? Certainly she has never allowed herself '</em></pre><pre name="d4ce" id="d4ce" class="graf graf--pre graf-after--pre">chars = sorted(list(set(text))) <br>vocab_size = len(chars)+1 <br>print('total chars:', vocab_size)</pre><pre name="b788" id="b788" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">total chars: 85</em></pre><ul class="postList"><li name="b883" id="b883" class="graf graf--li graf-after--pre">Always good to put a null or an empty character for padding.</li></ul><pre name="efe8" id="efe8" class="graf graf--pre graf-after--li">chars.insert(0, "\0")</pre><p name="e9b9" id="e9b9" class="graf graf--p graf-after--pre">Mapping of every character to a unique ID, and a unique ID to a character</p><pre name="f7da" id="f7da" class="graf graf--pre graf-after--p">char_indices = dict((c, i) for i, c in enumerate(chars))<br>indices_char = dict((i, c) for i, c in enumerate(chars))</pre><p name="5d56" id="5d56" class="graf graf--p graf-after--pre">Now we can represent the text with its ID’s:</p><pre name="be1d" id="be1d" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">idx</strong> = [char_indices[c] for c in text]<br>idx[:10]</pre><pre name="ded8" id="ded8" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]</em></pre><h4 name="a7e1" id="a7e1" class="graf graf--h4 graf-after--pre">Question: Character based model vs. word based model [<a href="https://youtu.be/sHcLkfRrgoQ?t=1h22m30s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h22m30s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:22:30</a>]</h4><ul class="postList"><li name="eb1e" id="eb1e" class="graf graf--li graf-after--h4">Generally, you want to combine character level model and word level model (e.g. for translation).</li><li name="22bf" id="22bf" class="graf graf--li graf-after--li">Character level model is useful when a vocabulary contains unusual words — which word level model will just treat as “unknown”. When you see a word you have not seen before, you can use a character level model.</li><li name="dda0" id="dda0" class="graf graf--li graf-after--li">There is also something in between that is called Byte Pair Encoding (BPE) which looks at n-gram of characters.</li></ul><h4 name="2098" id="2098" class="graf graf--h4 graf-after--li">Create inputs [<a href="https://youtu.be/sHcLkfRrgoQ?t=1h23m48s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h23m48s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:23:48</a>]</h4><pre name="76f6" id="76f6" class="graf graf--pre graf-after--h4">cs = 3 <br>c1_dat = [idx[i]   for i in range(0, len(idx)-cs, cs)]<br>c2_dat = [idx[i+1] for i in range(0, len(idx)-cs, cs)]<br>c3_dat = [idx[i+2] for i in range(0, len(idx)-cs, cs)]<br>c4_dat = [idx[i+3] for i in range(0, len(idx)-cs, cs)]</pre><p name="4bb4" id="4bb4" class="graf graf--p graf-after--pre">Note that <code class="markup--code markup--p-code">c1_dat[n+1] == c4_dat[n]</code> since we are skipping by 3 (the third argument of <code class="markup--code markup--p-code">range</code>)</p><pre name="cb1d" id="cb1d" class="graf graf--pre graf-after--p">x1 = np.stack(c1_dat) <br>x2 = np.stack(c2_dat) <br>x3 = np.stack(c3_dat) <br>y = np.stack(c4_dat)</pre><p name="271e" id="271e" class="graf graf--p graf-after--pre"><code class="markup--code markup--p-code">x</code>’s are our inputs, <code class="markup--code markup--p-code">y</code> is our target value.</p><h4 name="3d85" id="3d85" class="graf graf--h4 graf-after--p">Build a model [<a href="https://youtu.be/sHcLkfRrgoQ?t=1h26m8s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h26m8s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:26:08</a>]</h4><pre name="1a24" id="1a24" class="graf graf--pre graf-after--h4">n_hidden = 256 <br>n_fac = 42</pre><ul class="postList"><li name="d68b" id="d68b" class="graf graf--li graf-after--pre"><code class="markup--code markup--li-code">n_hiddein</code> — “# activations” in the diagram.</li><li name="f2d6" id="f2d6" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">n_fac</code> — the size of the embedding matrix.</li></ul><p name="2e34" id="2e34" class="graf graf--p graf-after--li">Here is the updated version of the previous diagram. Notice that now arrows are colored. All the arrows with the same color will use the same weight matrix. The idea here is that a character would not have different meaning (semantically or conceptually) depending on whether it is the first, the second, or the third item in a sequence, so treat them the same.</p><figure name="63fa" id="63fa" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_9XXQ3J7G3rD92tFkusi4bA.png"></figure><pre name="83aa" id="83aa" class="graf graf--pre graf-after--figure"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">Char3Model</strong>(nn.Module):<br>     <strong class="markup--strong markup--pre-strong">def</strong> <strong class="markup--strong markup--pre-strong">__init__</strong>(self, vocab_size, n_fac):<br>         super().__init__()<br>         <em class="markup--em markup--pre-em"><br></em>         self.e = nn.Embedding(vocab_size, n_fac)<br>         <em class="markup--em markup--pre-em"><br></em>         self.l_in = nn.Linear(n_fac, n_hidden)<br>          <em class="markup--em markup--pre-em"><br></em>         self.l_hidden = nn.Linear(n_hidden, n_hidden)<br>         <em class="markup--em markup--pre-em"><br></em>         self.l_out = nn.Linear(n_hidden, vocab_size)              </pre><pre name="bdfa" id="bdfa" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">def</strong> <strong class="markup--strong markup--pre-strong">forward</strong>(self, c1, c2, c3):<br>         in1 = F.relu(self.l_in(self.e(c1)))<br>         in2 = F.relu(self.l_in(self.e(c2)))<br>         in3 = F.relu(self.l_in(self.e(c3)))<br><br>         h = V(torch.zeros(in1.size()).cuda())<br>         h = F.tanh(self.l_hidden(h+in1))<br>         h = F.tanh(self.l_hidden(h+in2))<br>         h = F.tanh(self.l_hidden(h+in3))<br>         <br>         <strong class="markup--strong markup--pre-strong">return</strong> F.log_softmax(self.l_out(h))</pre><figure name="4821" id="4821" class="graf graf--figure graf--layoutOutsetCenter graf-after--pre" data-scroll="native"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_gBZslK323CITflsnXp-DSA.png"><figcaption class="imageCaption"><a href="https://youtu.be/sHcLkfRrgoQ?t=1h27m57s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h27m57s" class="markup--anchor markup--figure-anchor" rel="nofollow noopener" target="_blank">Video [1:27:57]</a></figcaption></figure><ul class="postList"><li name="5f6d" id="5f6d" class="graf graf--li graf-after--figure">[<a href="https://youtu.be/sHcLkfRrgoQ?t=1h29m58s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h29m58s" class="markup--anchor markup--li-anchor" rel="nofollow noopener" target="_blank">1:29:58</a>] It is important that this <code class="markup--code markup--li-code">l_hidden</code> uses a square weight matrix whose size matches the output of <code class="markup--code markup--li-code">l_in</code>. Then <code class="markup--code markup--li-code">h</code> and <code class="markup--code markup--li-code">in2</code> will be the same shape allowing us to sum them together as you see in <code class="markup--code markup--li-code">self.l_hidden(h+in2)</code></li><li name="1e85" id="1e85" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">V(torch.zeros(in1.size()).cuda())</code> is only there to make the three lines identical to make it easier to put in a for loop later.</li></ul><pre name="6144" id="6144" class="graf graf--pre graf-after--li">md = ColumnarModelData.from_arrays('.', [-1], np.stack(<strong class="markup--strong markup--pre-strong">[x1,x2,x3]</strong>, axis=1), y, bs=512)</pre><p name="7a82" id="7a82" class="graf graf--p graf-after--pre">We will reuse <code class="markup--code markup--p-code">ColumnarModelData</code>[<a href="https://youtu.be/sHcLkfRrgoQ?t=1h32m20s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h32m20s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:32:20</a>]. If we stack <code class="markup--code markup--p-code">x1</code>&nbsp;, <code class="markup--code markup--p-code">x2</code>, and <code class="markup--code markup--p-code">x3</code>, we will get <code class="markup--code markup--p-code">c1</code>, <code class="markup--code markup--p-code">c2</code>, <code class="markup--code markup--p-code">c3</code> in the <code class="markup--code markup--p-code">forward</code> method. <code class="markup--code markup--p-code">ColumnarModelData.from_arrays</code> will come in handy when you want to train a model in raw-er approach, what you put in <code class="markup--code markup--p-code">[x1, x2, x3]</code>&nbsp;, you will get back in <code class="markup--code markup--p-code u-paddingRight0 u-marginRight0"><strong class="markup--strong markup--p-strong">def</strong> <strong class="markup--strong markup--p-strong">forward</strong>(self, c1, c2, c3)</code></p><pre name="3456" id="3456" class="graf graf--pre graf-after--p">m = Char3Model(vocab_size, n_fac).cuda()</pre><ul class="postList"><li name="66f5" id="66f5" class="graf graf--li graf-after--pre">We create a standard PyTorch model (not <code class="markup--code markup--li-code">Learner</code>)</li><li name="062d" id="062d" class="graf graf--li graf-after--li">Because it is a standard PyTorch model, don’t forget&nbsp;<code class="markup--code markup--li-code">.cuda</code></li></ul><pre name="53f2" id="53f2" class="graf graf--pre graf-after--li">it = iter(md.trn_dl)<br>*xs,yt = next(it)<br>t = m(*V(xs)</pre><ul class="postList"><li name="ed52" id="ed52" class="graf graf--li graf-after--pre"><code class="markup--code markup--li-code">iter</code> to grab an iterator</li><li name="0234" id="0234" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">next</code> returns a mini-batch</li><li name="8344" id="8344" class="graf graf--li graf--startsWithDoubleQuote graf-after--li">“Variabize” the <code class="markup--code markup--li-code">xs</code> tensor, and put it through the model — which will give us 512x85 tensor containing prediction (batch size * unique character)</li></ul><pre name="796e" id="796e" class="graf graf--pre graf-after--li">opt = optim.Adam(m.parameters(), 1e-2)</pre><ul class="postList"><li name="402e" id="402e" class="graf graf--li graf-after--pre">Create a standard PyTorch optimizer — for which you need to pass in a list of things to optimize, which is returned by <code class="markup--code markup--li-code">m.parameters()</code></li></ul><pre name="baaf" id="baaf" class="graf graf--pre graf-after--li">fit(m, md, 1, opt, F.nll_loss)<br>set_lrs(opt, 0.001)<br>fit(m, md, 1, opt, F.nll_loss)</pre><ul class="postList"><li name="c759" id="c759" class="graf graf--li graf-after--pre">We do not find a learning rate finder and SGDR because we are not using <code class="markup--code markup--li-code">Learner</code>, so we would need to manually do learning rate annealing (set LR a little bit lower)</li></ul><h4 name="0896" id="0896" class="graf graf--h4 graf-after--li">Testing a model [<a href="https://youtu.be/sHcLkfRrgoQ?t=1h35m58s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h35m58s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:35:58</a>]</h4><pre name="6c21" id="6c21" class="graf graf--pre graf-after--h4"><strong class="markup--strong markup--pre-strong">def</strong> <strong class="markup--strong markup--pre-strong">get_next</strong>(inp):<br>     idxs = T(np.array([char_indices[c] <strong class="markup--strong markup--pre-strong">for</strong> c <strong class="markup--strong markup--pre-strong">in</strong> inp]))<br>     p = m(*VV(idxs))<br>     i = np.argmax(to_np(p))<br>     <strong class="markup--strong markup--pre-strong">return</strong> chars[i]</pre><p name="2a94" id="2a94" class="graf graf--p graf-after--pre">This function takes three characters and return what the model predict as the fourth. Note: <code class="markup--code markup--p-code">np.argmax</code> returns index of the maximum values.</p><pre name="3b71" id="3b71" class="graf graf--pre graf-after--p">get_next('y. ')<br><em class="markup--em markup--pre-em">'T'</em></pre><pre name="377e" id="377e" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">get_next('ppl')<br>'e'</em></pre><pre name="85bb" id="85bb" class="graf graf--pre graf-after--pre">get_next(' th')<br><em class="markup--em markup--pre-em">'e'</em></pre><pre name="8cef" id="8cef" class="graf graf--pre graf-after--pre">get_next('and')<br>' '</pre><h4 name="741d" id="741d" class="graf graf--h4 graf-after--pre">Let’s create our first RNN [<a href="https://youtu.be/sHcLkfRrgoQ?t=1h37m45s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h37m45s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:37:45</a>]</h4><p name="64c6" id="64c6" class="graf graf--p graf-after--h4">We can simplify the previous diagram as below:</p><figure name="55d5" id="55d5" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_xF-ab5Hn_3FGZRZtEGwFtw.png"><figcaption class="imageCaption">Predicting char n using chars 1 to&nbsp;n-1</figcaption></figure><p name="cce4" id="cce4" class="graf graf--p graf-after--figure">Let’s implement this. This time, we will use the first 8 characters to predict the 9th. Here is how we create inputs and output just like the last time:</p><pre name="3dbb" id="3dbb" class="graf graf--pre graf-after--p">cs = 8</pre><pre name="b9f6" id="b9f6" class="graf graf--pre graf-after--pre">c_in_dat = [[idx[i+j] <strong class="markup--strong markup--pre-strong">for</strong> i <strong class="markup--strong markup--pre-strong">in</strong> range(cs)] <strong class="markup--strong markup--pre-strong">for</strong> j <strong class="markup--strong markup--pre-strong">in</strong> range(len(idx)-cs)]</pre><pre name="2966" id="2966" class="graf graf--pre graf-after--pre">c_out_dat = [idx[j+cs] <strong class="markup--strong markup--pre-strong">for</strong> j <strong class="markup--strong markup--pre-strong">in</strong> range(len(idx)-cs)]</pre><pre name="17cb" id="17cb" class="graf graf--pre graf-after--pre">xs = np.stack(c_in_dat, axis=0)</pre><pre name="7a6a" id="7a6a" class="graf graf--pre graf-after--pre">y = np.stack(c_out_dat)</pre><pre name="7591" id="7591" class="graf graf--pre graf-after--pre">xs[:cs,:cs]<br><em class="markup--em markup--pre-em">array([[40, 42, 29, 30, 25, 27, 29,  1],<br>       [42, 29, 30, 25, 27, 29,  1,  1],<br>       [29, 30, 25, 27, 29,  1,  1,  1],<br>       [30, 25, 27, 29,  1,  1,  1, 43],<br>       [25, 27, 29,  1,  1,  1, 43, 45],<br>       [27, 29,  1,  1,  1, 43, 45, 40],<br>       [29,  1,  1,  1, 43, 45, 40, 40],<br>       [ 1,  1,  1, 43, 45, 40, 40, 39]])</em></pre><pre name="a484" id="a484" class="graf graf--pre graf-after--pre">y[:cs]<br><em class="markup--em markup--pre-em">array([ 1,  1, 43, 45, 40, 40, 39, 43])</em></pre><p name="c42f" id="c42f" class="graf graf--p graf-after--pre">Notice that they are overlaps (i.e. 0–7 to predict 8, 1–8 to predict 9).</p><pre name="6bc7" id="6bc7" class="graf graf--pre graf-after--p">val_idx = get_cv_idxs(len(idx)-cs-1)<br>md = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)</pre><h4 name="dcde" id="dcde" class="graf graf--h4 graf-after--pre">Create the model [<a href="https://youtu.be/sHcLkfRrgoQ?t=1h43m3s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h43m3s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:43:03</a>]</h4><pre name="0c0e" id="0c0e" class="graf graf--pre graf-after--h4"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">CharLoopModel</strong>(nn.Module):<br>    <em class="markup--em markup--pre-em"># This is an RNN!</em><br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, vocab_size, n_fac):<br>        super().__init__()<br>        self.e = nn.Embedding(vocab_size, n_fac)<br>        self.l_in = nn.Linear(n_fac, n_hidden)<br>        self.l_hidden = nn.Linear(n_hidden, n_hidden)<br>        self.l_out = nn.Linear(n_hidden, vocab_size)<br>        <br>    <strong class="markup--strong markup--pre-strong">def</strong> forward(self, *cs):<br>        bs = cs[0].size(0)<br>        h = V(torch.zeros(bs, n_hidden).cuda())<br>        <strong class="markup--strong markup--pre-strong">for</strong> c <strong class="markup--strong markup--pre-strong">in</strong> cs:<br>            inp = F.relu(self.l_in(self.e(c)))<br>            h = F.tanh(self.l_hidden(h+inp))<br>        <br>        <strong class="markup--strong markup--pre-strong">return</strong> F.log_softmax(self.l_out(h), dim=-1)</pre><p name="fe37" id="fe37" class="graf graf--p graf-after--pre">Most of the code is the same as before. You will notice that there is one <code class="markup--code markup--p-code">for</code> loop in <code class="markup--code markup--p-code">forward</code> function.</p><blockquote name="21e0" id="21e0" class="graf graf--blockquote graf-after--p">Hyperbolic Tangent (Tanh) [<a href="https://youtu.be/sHcLkfRrgoQ?t=1h43m43s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h43m43s" class="markup--anchor markup--blockquote-anchor" rel="nofollow noopener" target="_blank">1:43:43</a>]</blockquote><blockquote name="b6f3" id="b6f3" class="graf graf--blockquote graf-after--blockquote">It is a sigmoid that is offset. It is common to use hyperbolic tanh in the hidden state to hidden state transition because it stops it from flying off too high or too low. For other purposes, relu is more common.</blockquote><figure name="047e" id="047e" class="graf graf--figure graf-after--blockquote"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_EFvLR4S8KFKN9xTvTVMcng.png"></figure><p name="097c" id="097c" class="graf graf--p graf-after--figure">This now is a quite deep network as it uses 8 characters instead of 2. And as networks get deeper, they become harder to train.</p><pre name="7f41" id="7f41" class="graf graf--pre graf-after--p">m = CharLoopModel(vocab_size, n_fac).cuda() <br>opt = optim.Adam(m.parameters(), 1e-2)<br>fit(m, md, 1, opt, F.nll_loss)<br>set_lrs(opt, 0.001)<br>fit(m, md, 1, opt, F.nll_loss)</pre><h4 name="aa4c" id="aa4c" class="graf graf--h4 graf-after--pre">Adding vs. Contatenating</h4><p name="4193" id="4193" class="graf graf--p graf-after--h4">We now will try something else for <code class="markup--code markup--p-code u-paddingRight0 u-marginRight0">self.l_hidden(<strong class="markup--strong markup--p-strong">h+inp</strong>)</code>[<a href="https://youtu.be/sHcLkfRrgoQ?t=1h46m4s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h46m4s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:46:04</a>]. The reason is that the input state and the hidden state are qualitatively different. Input is the encoding of a character, and h is an encoding of series of characters. So adding them together, we might lose information. Let’s concatenate them instead. Don’t forget to change the input to match the shape (<code class="markup--code markup--p-code">n_fac+n_hidden</code> instead of <code class="markup--code markup--p-code">n_fac</code>).</p><pre name="e7d6" id="e7d6" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">CharLoopConcatModel</strong>(nn.Module):<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, vocab_size, n_fac):<br>        super().__init__()<br>        self.e = nn.Embedding(vocab_size, n_fac)<br>        self.l_in = nn.Linear(<strong class="markup--strong markup--pre-strong">n_fac+n_hidden</strong>, n_hidden)<br>        self.l_hidden = nn.Linear(n_hidden, n_hidden)<br>        self.l_out = nn.Linear(n_hidden, vocab_size)<br>        <br>    <strong class="markup--strong markup--pre-strong">def</strong> forward(self, *cs):<br>        bs = cs[0].size(0)<br>        h = V(torch.zeros(bs, n_hidden).cuda())<br>        <strong class="markup--strong markup--pre-strong">for</strong> c <strong class="markup--strong markup--pre-strong">in</strong> cs:<br>            inp = <strong class="markup--strong markup--pre-strong">torch.cat</strong>((h, self.e(c)), 1)<br>            inp = F.relu(self.l_in(inp))<br>            h = F.tanh(self.l_hidden(inp))<br>        <br>        <strong class="markup--strong markup--pre-strong">return</strong> F.log_softmax(self.l_out(h), dim=-1)</pre><p name="5e48" id="5e48" class="graf graf--p graf-after--pre">This gives some improvement.</p><h4 name="9fb9" id="9fb9" class="graf graf--h4 graf-after--p">RNN with PyTorch [<a href="https://youtu.be/sHcLkfRrgoQ?t=1h48m47s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h48m47s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:48:47</a>]</h4><p name="5685" id="5685" class="graf graf--p graf-after--h4">PyTorch will write the <code class="markup--code markup--p-code">for</code> loop automatically for us and also the linear input layer.</p><pre name="cb4b" id="cb4b" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">CharRnn</strong>(nn.Module):<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, vocab_size, n_fac):<br>        super().__init__()<br>        self.e = nn.Embedding(vocab_size, n_fac)<br>        <strong class="markup--strong markup--pre-strong">self.rnn = nn.RNN(n_fac, n_hidden)</strong><br>        self.l_out = nn.Linear(n_hidden, vocab_size)<br>        <br>    <strong class="markup--strong markup--pre-strong">def</strong> forward(self, *cs):<br>        bs = cs[0].size(0)<br>        h = V(torch.zeros(1, bs, n_hidden))<br>        inp = self.e(torch.stack(cs))<br>        <strong class="markup--strong markup--pre-strong">outp,h = self.rnn(inp, h)</strong><br>        <br>        <strong class="markup--strong markup--pre-strong">return</strong> F.log_softmax(self.l_out(<strong class="markup--strong markup--pre-strong">outp[-1]</strong>), dim=-1)</pre><ul class="postList"><li name="9561" id="9561" class="graf graf--li graf-after--pre">For reasons that will become apparent later on, <code class="markup--code markup--li-code">self.rnn</code> will return not only the output but also the hidden state.</li><li name="dd5d" id="dd5d" class="graf graf--li graf-after--li">The minor difference in PyTorch is that <code class="markup--code markup--li-code">self.rnn</code> will append a new hidden state to a tensor instead of replacing (in other words, it will give back all ellipses in the diagram)&nbsp;. We only want the final one so we do <code class="markup--code markup--li-code">outp[-1]</code></li></ul><pre name="bd08" id="bd08" class="graf graf--pre graf-after--li">m = CharRnn(vocab_size, n_fac).cuda() <br>opt = optim.Adam(m.parameters(), 1e-3)</pre><pre name="78e9" id="78e9" class="graf graf--pre graf-after--pre">ht = V(torch.zeros(1, 512,n_hidden)) <br>outp, hn = m.rnn(t, ht) <br>outp.size(), hn.size()<br><br><em class="markup--em markup--pre-em">(torch.Size([8, 512, 256]), torch.Size([1, 512, 256]))</em></pre><p name="d859" id="d859" class="graf graf--p graf-after--pre">In PyTorch version, a hidden state is rank 3 tensor <code class="markup--code markup--p-code">h = V(torch.zeros(1, bs, n_hidden)) </code>(in our version, it was rank 2 tensor) [<a href="https://youtu.be/sHcLkfRrgoQ?t=1h51m58s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h51m58s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:51:58</a>]. We will learn more about this later, but it turns out you can have a second RNN that goes backwards. The idea is that it is going to be better at finding relationships that go backwards — it is called “bi-directional RNN”. Also you can have an RNN feeds to an RNN which is called “multi layer RNN”. For these RNN’s, you will need the additional axis in the tensor to keep track of additional layers of hidden state. For now, we will just have 1 there, and get back 1.</p><h4 name="006b" id="006b" class="graf graf--h4 graf-after--p">Test the&nbsp;model</h4><pre name="905c" id="905c" class="graf graf--pre graf-after--h4"><strong class="markup--strong markup--pre-strong">def</strong> get_next(inp):<br>    idxs = T(np.array([char_indices[c] <strong class="markup--strong markup--pre-strong">for</strong> c <strong class="markup--strong markup--pre-strong">in</strong> inp]))<br>    p = m(*VV(idxs))<br>    i = np.argmax(to_np(p))<br>    <strong class="markup--strong markup--pre-strong">return</strong> chars[i]</pre><pre name="d3a4" id="d3a4" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">def</strong> get_next_n(inp, n):<br>    res = inp<br>    <strong class="markup--strong markup--pre-strong">for</strong> i <strong class="markup--strong markup--pre-strong">in</strong> range(n):<br>        c = get_next(inp)<br>        res += c<br>        inp = inp[1:]+c<br>    <strong class="markup--strong markup--pre-strong">return</strong> res</pre><pre name="c3c4" id="c3c4" class="graf graf--pre graf-after--pre">get_next_n('for thos', 40)<em class="markup--em markup--pre-em"><br>'for those the same the same the same the same th'</em></pre><p name="7923" id="7923" class="graf graf--p graf-after--pre">This time, we loop <code class="markup--code markup--p-code">n</code> times calling <code class="markup--code markup--p-code">get_next</code> each time, and each time we will replace our input by removing the first character and adding the character we just predicted.</p><p name="2902" id="2902" class="graf graf--p graf-after--p">For an interesting homework, try writing your own <code class="markup--code markup--p-code">nn.RNN</code> “<code class="markup--code markup--p-code">JeremysRNN</code>” without looking at PyTorch source code.</p><h4 name="6516" id="6516" class="graf graf--h4 graf-after--p">Multi-output [<a href="https://youtu.be/sHcLkfRrgoQ?t=1h55m31s" data-href="https://youtu.be/sHcLkfRrgoQ?t=1h55m31s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:55:31</a>]</h4><p name="7fab" id="7fab" class="graf graf--p graf-after--h4">From the last diagram, we can simplify even further by treating char 1 the same as char 2 to n-1. You notice the triangle (the output) also moved inside of the loop, in other words, we create a prediction after each character.</p><figure name="9bbb" id="9bbb" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_0-XkFkCIatPvenvKPfe2_g.png"><figcaption class="imageCaption">Predicting chars 2 to n using chars 1 to&nbsp;n-1</figcaption></figure><p name="a292" id="a292" class="graf graf--p graf-after--figure">One of the reasons we may want to do this is the redundancies we had seen before:</p><pre name="4a2c" id="4a2c" class="graf graf--pre graf-after--p">array([[40, 42, 29, 30, 25, 27, 29,  1],<br>       [42, 29, 30, 25, 27, 29,  1,  1],<br>       [29, 30, 25, 27, 29,  1,  1,  1],<br>       [30, 25, 27, 29,  1,  1,  1, 43],<br>       [25, 27, 29,  1,  1,  1, 43, 45],<br>       [27, 29,  1,  1,  1, 43, 45, 40],<br>       [29,  1,  1,  1, 43, 45, 40, 40],<br>       [ 1,  1,  1, 43, 45, 40, 40, 39]])</pre><p name="57de" id="57de" class="graf graf--p graf-after--pre">We can make it more efficient by taking <strong class="markup--strong markup--p-strong">non-overlapping</strong> sets of character this time. Because we are doing multi-output, for an input char 0 to 7, the output would be the predictions for char 1 to 8.</p><pre name="3ae2" id="3ae2" class="graf graf--pre graf-after--p">xs[:cs,:cs]</pre><pre name="c821" id="c821" class="graf graf--pre graf-after--pre">array([[40, 42, 29, 30, 25, 27, 29,  1],<br>       [ 1,  1, 43, 45, 40, 40, 39, 43],<br>       [33, 38, 31,  2, 73, 61, 54, 73],<br>       [ 2, 44, 71, 74, 73, 61,  2, 62],<br>       [72,  2, 54,  2, 76, 68, 66, 54],<br>       [67,  9,  9, 76, 61, 54, 73,  2],<br>       [73, 61, 58, 67, 24,  2, 33, 72],<br>       [ 2, 73, 61, 58, 71, 58,  2, 67]])</pre><pre name="41d6" id="41d6" class="graf graf--pre graf-after--pre">ys[:cs,:cs]<br>array([[42, 29, 30, 25, 27, 29,  1,  1],<br>       [ 1, 43, 45, 40, 40, 39, 43, 33],<br>       [38, 31,  2, 73, 61, 54, 73,  2],<br>       [44, 71, 74, 73, 61,  2, 62, 72],<br>       [ 2, 54,  2, 76, 68, 66, 54, 67],<br>       [ 9,  9, 76, 61, 54, 73,  2, 73],<br>       [61, 58, 67, 24,  2, 33, 72,  2],<br>       [73, 61, 58, 71, 58,  2, 67, 68]])</pre><p name="4836" id="4836" class="graf graf--p graf-after--pre">This will not make our model any more accurate, but we can train it more efficiently.</p><pre name="d54d" id="d54d" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">CharSeqRnn</strong>(nn.Module):<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, vocab_size, n_fac):<br>        super().__init__()<br>        self.e = nn.Embedding(vocab_size, n_fac)<br>        self.rnn = nn.RNN(n_fac, n_hidden)<br>        self.l_out = nn.Linear(n_hidden, vocab_size)<br>        <br>    <strong class="markup--strong markup--pre-strong">def</strong> forward(self, *cs):<br>        bs = cs[0].size(0)<br>        h = V(torch.zeros(1, bs, n_hidden))<br>        inp = self.e(torch.stack(cs))<br>        outp,h = self.rnn(inp, h)<br>        <strong class="markup--strong markup--pre-strong">return</strong> F.log_softmax(self.l_out(<strong class="markup--strong markup--pre-strong">outp</strong>), dim=-1)</pre><p name="ecf5" id="ecf5" class="graf graf--p graf-after--pre">Notice that we are no longer doing <code class="markup--code markup--p-code">outp[-1]</code> since we want to keep all of them. But everything else is identical. One complexity[<a href="https://youtu.be/sHcLkfRrgoQ?t=2h37s" data-href="https://youtu.be/sHcLkfRrgoQ?t=2h37s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">2:00:37</a>] is that we want to use the negative log-likelihood loss function as before, but it expects two rank 2 tensors (two mini-batches of vectors). But here, we have rank 3 tensor:</p><ul class="postList"><li name="f1bb" id="f1bb" class="graf graf--li graf-after--p">8 characters (time steps)</li><li name="e7f9" id="e7f9" class="graf graf--li graf-after--li">84 probabilities</li><li name="df6c" id="df6c" class="graf graf--li graf-after--li">for 512 minibatch</li></ul><h4 name="70de" id="70de" class="graf graf--h4 graf-after--li">Let’s write a custom loss function [<a href="https://youtu.be/sHcLkfRrgoQ?t=2h2m10s" data-href="https://youtu.be/sHcLkfRrgoQ?t=2h2m10s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">2:02:10</a>]:</h4><pre name="53f6" id="53f6" class="graf graf--pre graf-after--h4"><strong class="markup--strong markup--pre-strong">def</strong> nll_loss_seq(inp, targ):<br>    sl,bs,nh = inp.size()<br>    targ = targ.transpose(0,1).contiguous().view(-1)<br>    <strong class="markup--strong markup--pre-strong">return</strong> F.nll_loss(inp.view(-1,nh), targ)</pre><ul class="postList"><li name="c40a" id="c40a" class="graf graf--li graf-after--pre"><code class="markup--code markup--li-code">F.nll_loss</code> is the PyTorch loss function.</li><li name="8313" id="8313" class="graf graf--li graf-after--li">Flatten our inputs and targets.</li><li name="eabb" id="eabb" class="graf graf--li graf-after--li">Transpose the first two axes because PyTorch expects 1. sequence length (how many time steps), 2. batch size, 3. hidden state itself. <code class="markup--code markup--li-code">yt.size()</code> is 512 by 8, whereas <code class="markup--code markup--li-code">sl, bs</code> is 8 by 512.</li><li name="600f" id="600f" class="graf graf--li graf-after--li">PyTorch does not generally actually shuffle the memory order when you do things like ‘transpose’, but instead it keeps some internal metadata to treat it as if it is transposed. When you transpose a matrix, PyTorch just updates the metadata&nbsp;. If you ever see an error that says “this tensor is not continuous”&nbsp;, add&nbsp;<code class="markup--code markup--li-code">.contiguous()</code> after it and error goes away.</li><li name="717d" id="717d" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">.view</code> is same as <code class="markup--code markup--li-code">np.reshape</code>. <code class="markup--code markup--li-code">-1</code> indicates as long as it needs to be.</li></ul><pre name="243b" id="243b" class="graf graf--pre graf-after--li">fit(m, md, 4, opt, null_loss_seq)</pre><p name="7be2" id="7be2" class="graf graf--p graf-after--pre">Remember that <code class="markup--code markup--p-code">fit(...)</code> is the lowest level fast.ai abstraction that implements the training loop. So all the arguments are standard PyTorch things except for <code class="markup--code markup--p-code">md</code> which is our model data object which wraps up the test set, the training set, and the validation set.</p><p name="e935" id="e935" class="graf graf--p graf-after--p">Question [<a href="https://youtu.be/sHcLkfRrgoQ?t=2h6m4s" data-href="https://youtu.be/sHcLkfRrgoQ?t=2h6m4s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">2:06:04</a>]: Now that we put a triangle inside of the loop, do we need a bigger sequence size?</p><ul class="postList"><li name="d6fa" id="d6fa" class="graf graf--li graf-after--p">If we have a short sequence like 8, the first character has nothing to go on. It starts with an empty hidden state of zeros.</li><li name="38d6" id="38d6" class="graf graf--li graf-after--li">We will learn how to avoid that problem next week.</li><li name="b155" id="b155" class="graf graf--li graf-after--li">The basic idea is “why should we reset the hidden state to zeros every time?” (see code below). If we can line up these mini-batches somehow so that the next mini-batch joins up correctly representingthe next letter in Nietsche’s works, then we can move <code class="markup--code markup--li-code">h = V(torch.zeros(1, bs, n_hidden))</code> to the constructor.</li></ul><pre name="f215" id="f215" class="graf graf--pre graf-after--li"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">CharSeqRnn</strong>(nn.Module):<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, vocab_size, n_fac):<br>        super().__init__()<br>        self.e = nn.Embedding(vocab_size, n_fac)<br>        self.rnn = nn.RNN(n_fac, n_hidden)<br>        self.l_out = nn.Linear(n_hidden, vocab_size)<br>        <br>    <strong class="markup--strong markup--pre-strong">def</strong> forward(self, *cs):<br>        bs = cs[0].size(0)<br>        <strong class="markup--strong markup--pre-strong">h = V(torch.zeros(1, bs, n_hidden))</strong><br>        inp = self.e(torch.stack(cs))<br>        outp,h = self.rnn(inp, h)<br>        <strong class="markup--strong markup--pre-strong">return</strong> F.log_softmax(self.l_out(outp), dim=-1)</pre><h4 name="65a4" id="65a4" class="graf graf--h4 graf-after--pre">Gradient Explosion [<a href="https://youtu.be/sHcLkfRrgoQ?t=2h8m21s" data-href="https://youtu.be/sHcLkfRrgoQ?t=2h8m21s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">2:08:21</a>]</h4><p name="367d" id="367d" class="graf graf--p graf-after--h4"><code class="markup--code markup--p-code">self.rnn(inp, h)</code> is a loop applying the same matrix multiply again and again. If that matrix multiply tends to increase the activations each time, we are effectively doing that to the power of 8 — we call this a gradient explosion. We want to make sure the initial <code class="markup--code markup--p-code">l_hidden</code> will not cause our activations on average to increase or decrease.</p><p name="f790" id="f790" class="graf graf--p graf-after--p">A nice matrix that does exactly that is called identity matrix:</p><figure name="57cc" id="57cc" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_MH5NhqJBth84L9ufaxJCig.jpeg"></figure><p name="9825" id="9825" class="graf graf--p graf-after--figure">We can overwrite the randomly initialized hidden-hidden weight with an identity matrix:</p><pre name="8187" id="8187" class="graf graf--pre graf-after--p">m.rnn.weight_hh_l0.data.copy_(torch.eye(n_hidden))</pre><p name="c0b9" id="c0b9" class="graf graf--p graf-after--pre graf--trailing">This was introduced by Geoffrey Hinton et. al. in 2015 (<a href="https://arxiv.org/abs/1504.00941" data-href="https://arxiv.org/abs/1504.00941" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">A Simple Way to Initialize Recurrent Networks of Rectified Linear Units</a>) — after RNN has been around for decades. It works very well, and you can use higher learning rate since it is well behaved.</p><hr class="section-divider"><p name="554a" id="554a" class="graf graf--p graf--leading graf--trailing">Lessons: <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" class="markup--anchor markup--p-anchor" target="_blank">1</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" class="markup--anchor markup--p-anchor" target="_blank">2</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" class="markup--anchor markup--p-anchor" target="_blank">3</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" class="markup--anchor markup--p-anchor" target="_blank">4</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" class="markup--anchor markup--p-anchor" target="_blank">5</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" class="markup--anchor markup--p-anchor" target="_blank"><strong class="markup--strong markup--p-strong">6</strong></a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" class="markup--anchor markup--p-anchor" target="_blank">7</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" class="markup--anchor markup--p-anchor" target="_blank">8</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" class="markup--anchor markup--p-anchor" target="_blank">9</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" class="markup--anchor markup--p-anchor" target="_blank">10</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" class="markup--anchor markup--p-anchor" target="_blank">11</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" class="markup--anchor markup--p-anchor" target="_blank">12</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" class="markup--anchor markup--p-anchor" target="_blank">13</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" class="markup--anchor markup--p-anchor" target="_blank">14</a></p></body></html>