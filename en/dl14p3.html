<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></head><body><pre name="71c6" id="71c6" class="graf graf--pre graf-after--pre">learn.lr_find()<br>learn.sched.plot()</pre><pre name="774d" id="774d" class="graf graf--pre graf-after--pre">94%|█████████▍| 30/32 [00:05&lt;00:00,  5.48it/s, loss=10.6]</pre><figure name="04ea" id="04ea" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_0RoKSchCdIyFHGVjb7PXHA.png"></figure><pre name="dba8" id="dba8" class="graf graf--pre graf-after--figure">lr=4e-2</pre><pre name="3d50" id="3d50" class="graf graf--pre graf-after--pre">learn.fit(lr,1,cycle_len=5,use_clr=(20,5))</pre><pre name="e8fb" id="e8fb" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">epoch      trn_loss   val_loss   &lt;lambda&gt;                  <br>    0      0.124078   0.133566   0.945951  <br>    1      0.111241   0.112318   0.954912                  <br>    2      0.099743   0.09817    0.957507                   <br>    3      0.090651   0.092375   0.958117                   <br>    4      0.084031   0.086026   0.963243</em></pre><pre name="b542" id="b542" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[0.086025625, 0.96324310824275017]</em></pre><p name="1fbe" id="1fbe" class="graf graf--p graf-after--pre">After a few epochs, we’ve got 96 percent accurate. Is that good [<a href="https://youtu.be/nG3tT31nPmQ?t=1h40m56s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h40m56s" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">1:40:56</a>]? Is 96% accurate good? And hopefully the answer to that question is it depends. What’s it for? The answer is Carvana wanted this because they wanted to be able to take their car image and cut them out and paste them on exotic Monte Carlo backgrounds or whatever (that’s Monte Carlo the place and not the simulation). To do that, you you need a really good mask. You don’t want to leave the rearview mirrors behind, have one wheel missing, or include a little bit of background or something. That would look stupid. So you would need something very good. So only having 96% of the pixels correct doesn’t sound great. But we won’t really know until we look at it. So let’s look at it.</p><pre name="e43b" id="e43b" class="graf graf--pre graf-after--p">learn.save('tmp')</pre><pre name="8a62" id="8a62" class="graf graf--pre graf-after--pre">learn.load('tmp')</pre><pre name="9fd7" id="9fd7" class="graf graf--pre graf-after--pre">py,ay = learn.predict_with_targs()</pre><pre name="bae3" id="bae3" class="graf graf--pre graf-after--pre">ay.shape</pre><pre name="ec1b" id="ec1b" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">(1008, 128, 128)</em></pre><p name="cd51" id="cd51" class="graf graf--p graf-after--pre">So there is the correct version that we want to cut out [<a href="https://youtu.be/nG3tT31nPmQ?t=1h41m54s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h41m54s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:41:54</a>]</p><pre name="0abd" id="0abd" class="graf graf--pre graf-after--p">show_img(ay[0]);</pre><figure name="1711" id="1711" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_ZuW4s04Ubneh3fFjQuQ3rQ.png"></figure><p name="6fbf" id="6fbf" class="graf graf--p graf-after--figure">That’s the 96% accurate version. So when you look at it you realize “oh yeah, getting 96% of the pixel accurate is actually easy because all the outside bit is not car, and all the inside bit is a car, and really interesting bit is the edge. So we need to do better.</p><pre name="5078" id="5078" class="graf graf--pre graf-after--p">show_img(py[0]&gt;0);</pre><figure name="3117" id="3117" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_cp-SvDXQPGdN6k-8JL2CMw.png"></figure><p name="11f5" id="11f5" class="graf graf--p graf-after--figure">Let’s unfreeze because all we’ve done so far is train the custom head. Let’s do more.</p><pre name="3d63" id="3d63" class="graf graf--pre graf-after--p">learn.unfreeze()</pre><pre name="d43c" id="d43c" class="graf graf--pre graf-after--pre">learn.bn_freeze(<strong class="markup--strong markup--pre-strong">True</strong>)</pre><pre name="3e0b" id="3e0b" class="graf graf--pre graf-after--pre">lrs = np.array([lr/100,lr/10,lr])/4</pre><pre name="4cf0" id="4cf0" class="graf graf--pre graf-after--pre">learn.fit(lrs,1,cycle_len=20,use_clr=(20,10))</pre><pre name="09a7" id="09a7" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">epoch      trn_loss   val_loss   &lt;lambda&gt;                   <br>    0      0.06577    0.053292   0.972977  <br>    1      0.049475   0.043025   0.982559                   <br>    2      0.039146   0.035927   0.98337                    <br>    3      0.03405    0.031903   0.986982                   <br>    4      0.029788   0.029065   0.987944                   <br>    5      0.027374   0.027752   0.988029                   <br>    6      0.026041   0.026718   0.988226                   <br>    7      0.024302   0.025927   0.989512                   <br>    8      0.022921   0.026102   0.988276                   <br>    9      0.021944   0.024714   0.989537                   <br>    10     0.021135   0.0241     0.990628                   <br>    11     0.020494   0.023367   0.990652                   <br>    12     0.01988    0.022961   0.990989                   <br>    13     0.019241   0.022498   0.991014                   <br>    14     0.018697   0.022492   0.990571                   <br>    15     0.01812    0.021771   0.99105                    <br>    16     0.017597   0.02183    0.991365                   <br>    17     0.017192   0.021434   0.991364                   <br>    18     0.016768   0.021383   0.991643                   <br>    19     0.016418   0.021114   0.99173</em></pre><pre name="7898" id="7898" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[0.021113895, 0.99172959849238396]</em></pre><p name="62e3" id="62e3" class="graf graf--p graf-after--pre">After a bit more, we’ve got 99.1%. Is that good? I don’t know. Let’s take a look.</p><pre name="c1cd" id="c1cd" class="graf graf--pre graf-after--p">learn.save('0')</pre><pre name="a8c0" id="a8c0" class="graf graf--pre graf-after--pre">x,y = next(iter(md.val_dl))<br>py = to_np(learn.model(V(x)))</pre><p name="49a7" id="49a7" class="graf graf--p graf-after--pre">Actually no. It’s totally missed the rearview vision mirror on the left and missed a lot of it on the right. And it’s clearly got an edge wrong on the bottom. And these things are totally going to matter when we try to cut it out, so it’s still not good enough.</p><pre name="a270" id="a270" class="graf graf--pre graf-after--p">ax = show_img(denorm(x)[0])<br>show_img(py[0]&gt;0, ax=ax, alpha=0.5);</pre><figure name="db2a" id="db2a" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_b4NbyzWojBS_6peHalw3tQ.png"></figure><pre name="5221" id="5221" class="graf graf--pre graf-after--figure">ax = show_img(denorm(x)[0])<br>show_img(y[0], ax=ax, alpha=0.5);</pre><figure name="b23b" id="b23b" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_nh7F97XxSE1ZOcleTfoPeA.png"></figure><h4 name="3fed" id="3fed" class="graf graf--h4 graf-after--figure">512x512 [<a href="https://youtu.be/nG3tT31nPmQ?t=1h42m50s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h42m50s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:42:50</a>]</h4><p name="c002" id="c002" class="graf graf--p graf-after--h4">Let’s try upscaling. And the nice thing is that when we upscale to 512 by 512, (make sure you decrease the batch size because you’ll run out of memory), it’s quite a lot more information there for it to go on so our accuracy increases to 99.4% and things keep getting better.</p><pre name="406f" id="406f" class="graf graf--pre graf-after--p">TRAIN_DN = 'train'<br>MASKS_DN = 'train_masks_png'<br>sz = 512<br>bs = 16</pre><pre name="bae2" id="bae2" class="graf graf--pre graf-after--pre">x_names = np.array([Path(TRAIN_DN)/o <strong class="markup--strong markup--pre-strong">for</strong> o <strong class="markup--strong markup--pre-strong">in</strong> masks_csv['img']])<br>y_names = np.array([Path(MASKS_DN)/f'<strong class="markup--strong markup--pre-strong">{o[:-4]}</strong>_mask.png' <br>                      <strong class="markup--strong markup--pre-strong">for</strong> o <strong class="markup--strong markup--pre-strong">in</strong> masks_csv['img']])</pre><pre name="821b" id="821b" class="graf graf--pre graf-after--pre">((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names, <br>                                      y_names)<br>len(val_x),len(trn_x)</pre><pre name="7772" id="7772" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">(1008, 4080)</em></pre><pre name="25db" id="25db" class="graf graf--pre graf-after--pre">tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO,<br>                         tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)<br>datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y),<br>                      (val_x,val_y), tfms, path=PATH)<br>md = ImageData(PATH, datasets, bs, num_workers=8, classes=<strong class="markup--strong markup--pre-strong">None</strong>)</pre><pre name="859d" id="859d" class="graf graf--pre graf-after--pre">denorm = md.trn_ds.denorm<br>x,y = next(iter(md.aug_dl))<br>x = denorm(x)</pre><p name="9176" id="9176" class="graf graf--p graf-after--pre">Here is the true ones.</p><pre name="6fee" id="6fee" class="graf graf--pre graf-after--p">fig, axes = plt.subplots(4, 4, figsize=(10, 10))<br><strong class="markup--strong markup--pre-strong">for</strong> i,ax <strong class="markup--strong markup--pre-strong">in</strong> enumerate(axes.flat):<br>    ax=show_img(x[i], ax=ax)<br>    show_img(y[i], ax=ax, alpha=0.5)<br>plt.tight_layout(pad=0.1)</pre><figure name="45ad" id="45ad" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_viBgn7WA9biBQ6BkzSEEnw.png"></figure><pre name="afad" id="afad" class="graf graf--pre graf-after--figure">simple_up = nn.Sequential(<br>    nn.ReLU(),<br>    StdUpsample(512,256),<br>    StdUpsample(256,256),<br>    StdUpsample(256,256),<br>    StdUpsample(256,256),<br>    nn.ConvTranspose2d(256, 1, 2, stride=2),<br>    flatten_channel<br>)</pre><pre name="d90a" id="d90a" class="graf graf--pre graf-after--pre">models = ConvnetBuilder(resnet34, 0, 0, 0, custom_head=simple_up)<br>learn = ConvLearner(md, models)<br>learn.opt_fn=optim.Adam<br>learn.crit=nn.BCEWithLogitsLoss()<br>learn.metrics=[accuracy_thresh(0.5)]</pre><pre name="8f27" id="8f27" class="graf graf--pre graf-after--pre">learn.load('0')</pre><pre name="a3e0" id="a3e0" class="graf graf--pre graf-after--pre">learn.lr_find()<br>learn.sched.plot()</pre><pre name="9973" id="9973" class="graf graf--pre graf-after--pre">85%|████████▌ | 218/255 [02:12&lt;00:22,  1.64it/s, loss=8.91]</pre><figure name="4133" id="4133" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_hjhVP2TyYd8FZMvyGevPgA.png"></figure><pre name="4148" id="4148" class="graf graf--pre graf-after--figure">lr=4e-2</pre><pre name="b2b4" id="b2b4" class="graf graf--pre graf-after--pre">learn.fit(lr,1,cycle_len=5,use_clr=(20,5))</pre><pre name="655f" id="655f" class="graf graf--pre graf-after--pre">epoch      trn_loss   val_loss   &lt;lambda&gt;                     <br>    0      0.02178    0.020653   0.991708  <br>    1      0.017927   0.020653   0.990241                     <br>    2      0.015958   0.016115   0.993394                     <br>    3      0.015172   0.015143   0.993696                     <br>    4      0.014315   0.014679   0.99388</pre><pre name="4064" id="4064" class="graf graf--pre graf-after--pre">[0.014679321, 0.99388032489352751]</pre><pre name="53e2" id="53e2" class="graf graf--pre graf-after--pre">learn.save('tmp')</pre><pre name="6543" id="6543" class="graf graf--pre graf-after--pre">learn.load('tmp')</pre><pre name="3a85" id="3a85" class="graf graf--pre graf-after--pre">learn.unfreeze()<br>learn.bn_freeze(<strong class="markup--strong markup--pre-strong">True</strong>)</pre><pre name="15e9" id="15e9" class="graf graf--pre graf-after--pre">lrs = np.array([lr/100,lr/10,lr])/4</pre><pre name="660f" id="660f" class="graf graf--pre graf-after--pre">learn.fit(lrs,1,cycle_len=8,use_clr=(20,8))</pre><pre name="1a7e" id="1a7e" class="graf graf--pre graf-after--pre">epoch      trn_loss   val_loss   mask_acc                     <br>    0      0.038687   0.018685   0.992782  <br>    1      0.024906   0.014355   0.994933                     <br>    2      0.025055   0.014737   0.995526                     <br>    3      0.024155   0.014083   0.995708                     <br>    4      0.013446   0.010564   0.996166                     <br>    5      0.01607    0.010555   0.996096                     <br>    6      0.019197   0.010883   0.99621                      <br>    7      0.016157   0.00998    0.996393</pre><pre name="1ccb" id="1ccb" class="graf graf--pre graf-after--pre">[0.0099797687, 0.99639255659920833]</pre><pre name="a070" id="a070" class="graf graf--pre graf-after--pre">learn.save('512')</pre><pre name="9ed6" id="9ed6" class="graf graf--pre graf-after--pre">x,y = next(iter(md.val_dl))<br>py = to_np(learn.model(V(x)))</pre><pre name="e57e" id="e57e" class="graf graf--pre graf-after--pre">ax = show_img(denorm(x)[0])<br>show_img(py[0]&gt;0, ax=ax, alpha=0.5);</pre><figure name="03dc" id="03dc" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1__nnK8pvyBueihmtg6JhqPA.png"></figure><pre name="c120" id="c120" class="graf graf--pre graf-after--figure">ax = show_img(denorm(x)[0])<br>show_img(y[0], ax=ax, alpha=0.5);</pre><figure name="fd4b" id="fd4b" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_G5zNxkOplWvUIbGlSPs86Q.png"></figure><p name="81d1" id="81d1" class="graf graf--p graf-after--figure">Things keep getting better but we’ve still got quite a few little black blocky bits. so let’s go to 1024 by 1024.</p><h4 name="d0a6" id="d0a6" class="graf graf--h4 graf-after--p">1024x1024 [<a href="https://youtu.be/nG3tT31nPmQ?t=1h43m17s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h43m17s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:43:17</a>]</h4><p name="5b87" id="5b87" class="graf graf--p graf-after--h4">So let’s go to 1024 by 1024, batch size down to 4. This is pretty high res now, and train a bit more, 99.6, 99.8%!</p><pre name="87d3" id="87d3" class="graf graf--pre graf-after--p">sz = 1024<br>bs = 4</pre><pre name="cffb" id="cffb" class="graf graf--pre graf-after--pre">tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO,<br>                         tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)<br>datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), <br>                            (val_x,val_y), tfms, path=PATH)<br>md = ImageData(PATH, datasets, bs, num_workers=8, classes=<strong class="markup--strong markup--pre-strong">None</strong>)</pre><pre name="8c28" id="8c28" class="graf graf--pre graf-after--pre">denorm = md.trn_ds.denorm<br>x,y = next(iter(md.aug_dl))<br>x = denorm(x)<br>y = to_np(y)</pre><pre name="b915" id="b915" class="graf graf--pre graf-after--pre">fig, axes = plt.subplots(2, 2, figsize=(8, 8))<br><strong class="markup--strong markup--pre-strong">for</strong> i,ax <strong class="markup--strong markup--pre-strong">in</strong> enumerate(axes.flat):<br>    show_img(x[i], ax=ax)<br>    show_img(y[i], ax=ax, alpha=0.5)<br>plt.tight_layout(pad=0.1)</pre><figure name="a61e" id="a61e" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_4PrOwKZEYtXv7xdf9rPkhg.png"></figure><pre name="bb11" id="bb11" class="graf graf--pre graf-after--figure">simple_up = nn.Sequential(<br>    nn.ReLU(),<br>    StdUpsample(512,256),<br>    StdUpsample(256,256),<br>    StdUpsample(256,256),<br>    StdUpsample(256,256),<br>    nn.ConvTranspose2d(256, 1, 2, stride=2),<br>    flatten_channel,<br>)</pre><pre name="09d6" id="09d6" class="graf graf--pre graf-after--pre">models = ConvnetBuilder(resnet34, 0, 0, 0, custom_head=simple_up)<br>learn = ConvLearner(md, models)<br>learn.opt_fn=optim.Adam<br>learn.crit=nn.BCEWithLogitsLoss()<br>learn.metrics=[accuracy_thresh(0.5)]</pre><pre name="15e5" id="15e5" class="graf graf--pre graf-after--pre">learn.load('512')</pre><pre name="16bb" id="16bb" class="graf graf--pre graf-after--pre">learn.lr_find()<br>learn.sched.plot()</pre><pre name="652c" id="652c" class="graf graf--pre graf-after--pre">85%|████████▌ | 218/255 [02:12&lt;00:22,  1.64it/s, loss=8.91]</pre><figure name="511e" id="511e" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_hjhVP2TyYd8FZMvyGevPgA.png"></figure><pre name="ed98" id="ed98" class="graf graf--pre graf-after--figure">lr=4e-2</pre><pre name="9540" id="9540" class="graf graf--pre graf-after--pre">learn.fit(lr,1,cycle_len=2,use_clr=(20,4))</pre><pre name="6b85" id="6b85" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">epoch      trn_loss   val_loss   &lt;lambda&gt;                       <br>    0      0.01066    0.011119   0.996227  <br>    1      0.009357   0.009696   0.996553</em></pre><pre name="65c0" id="65c0" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[0.0096957013, 0.99655332546385511]</em></pre><pre name="dfde" id="dfde" class="graf graf--pre graf-after--pre">learn.save('tmp')</pre><pre name="a038" id="a038" class="graf graf--pre graf-after--pre">learn.load('tmp')</pre><pre name="d025" id="d025" class="graf graf--pre graf-after--pre">learn.unfreeze()<br>learn.bn_freeze(<strong class="markup--strong markup--pre-strong">True</strong>)</pre><pre name="de3d" id="de3d" class="graf graf--pre graf-after--pre">lrs = np.array([lr/100,lr/10,lr])/8</pre><pre name="16cb" id="16cb" class="graf graf--pre graf-after--pre">learn.fit(lrs,1,cycle_len=40,use_clr=(20,10))</pre><pre name="0c6c" id="0c6c" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">epoch      trn_loss   val_loss   mask_acc                       <br>    0      0.015565   0.007449   0.997661  <br>    1      0.01979    0.008376   0.997542                       <br>    2      0.014874   0.007826   0.997736                       <br>    3      0.016104   0.007854   0.997347                       <br>    4      0.023386   0.009745   0.997218                       <br>    5      0.018972   0.008453   0.997588                       <br>    6      0.013184   0.007612   0.997588                       <br>    7      0.010686   0.006775   0.997688                       <br>    8      0.0293     0.015299   0.995782                       <br>    9      0.018713   0.00763    0.997638                       <br>    10     0.015432   0.006575   0.9978                         <br>    11     0.110205   0.060062   0.979043                      <br>    12     0.014374   0.007753   0.997451                       <br>    13     0.022286   0.010282   0.997587                       <br>    14     0.015645   0.00739    0.997776                       <br>    15     0.013821   0.00692    0.997869                       <br>    16     0.022389   0.008632   0.997696                       <br>    17     0.014607   0.00677    0.997837                       <br>    18     0.018748   0.008194   0.997657                       <br>    19     0.016447   0.007237   0.997899                       <br>    20     0.023596   0.008211   0.997918                       <br>    21     0.015721   0.00674    0.997848                       <br>    22     0.01572    0.006415   0.998006                       <br>    23     0.019519   0.007591   0.997876                       <br>    24     0.011159   0.005998   0.998053                       <br>    25     0.010291   0.005806   0.998012                       <br>    26     0.010893   0.005755   0.998046                       <br>    27     0.014534   0.006313   0.997901                       <br>    28     0.020971   0.006855   0.998018                       <br>    29     0.014074   0.006107   0.998053                       <br>    30     0.01782    0.006561   0.998114                       <br>    31     0.01742    0.006414   0.997942                       <br>    32     0.016829   0.006514   0.9981                         <br>    33     0.013148   0.005819   0.998033                       <br>    34     0.023495   0.006261   0.997856                       <br>    35     0.010931   0.005516   0.99812                        <br>    36     0.015798   0.006176   0.998126                       <br>    37     0.021636   0.005931   0.998067                       <br>    38     0.012133   0.005496   0.998158                       <br>    39     0.012562   0.005678   0.998172</em></pre><pre name="9653" id="9653" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[0.0056782686, 0.99817223208291195]</em></pre><pre name="8864" id="8864" class="graf graf--pre graf-after--pre">learn.save('1024')</pre><pre name="295a" id="295a" class="graf graf--pre graf-after--pre">x,y = next(iter(md.val_dl))<br>py = to_np(learn.model(V(x)))</pre><pre name="32e6" id="32e6" class="graf graf--pre graf-after--pre">ax = show_img(denorm(x)[0])<br>show_img(py[0][0]&gt;0, ax=ax, alpha=0.5);</pre><figure name="eb5e" id="eb5e" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_8kgJWpP6-nxlDfWT8N25_g.png"></figure><pre name="0d44" id="0d44" class="graf graf--pre graf-after--figure">ax = show_img(denorm(x)[0])<br>show_img(y[0,...,-1], ax=ax, alpha=0.5);</pre><figure name="31d6" id="31d6" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1__-Kx9dC5aTgBSf_aSrBrNQ.png"></figure><pre name="9662" id="9662" class="graf graf--pre graf-after--figure">show_img(py[0][0]&gt;0);</pre><figure name="e0e8" id="e0e8" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_G3C8DPyOB4BC3VLPGjbwcA.png"></figure><pre name="6f0f" id="6f0f" class="graf graf--pre graf-after--figure">show_img(y[0,...,-1]);</pre><figure name="3dcd" id="3dcd" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_fJrWvuzyX0cG5ATWvqaDPg.png"></figure><p name="5df3" id="5df3" class="graf graf--p graf-after--figure">Now if we look at the masks,&nbsp;, they are actually looking not bad. That’s looking pretty good. So can we do better? And the answer is yes, we can.</p><h3 name="0ffa" id="0ffa" class="graf graf--h3 graf-after--p">U-Net [<a href="https://youtu.be/nG3tT31nPmQ?t=1h43m45s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h43m45s" class="markup--anchor markup--h3-anchor" rel="nofollow noopener" target="_blank">1:43:45</a>]</h3><p name="e5cb" id="e5cb" class="graf graf--p graf-after--h3"><a href="https://github.com/fastai/fastai/blob/master/courses/dl2/carvana-unet.ipynb" data-href="https://github.com/fastai/fastai/blob/master/courses/dl2/carvana-unet.ipynb" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">Notebook</a> / <a href="https://arxiv.org/abs/1505.04597" data-href="https://arxiv.org/abs/1505.04597" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">Paper</a></p><p name="b5e6" id="b5e6" class="graf graf--p graf-after--p">U-Net network is quite magnificent. With that previous approach, our pre-trained ImageNet network was being squished down all the way down to 7x7 and then expand it out all the way back up to 224x224 (1024 gets squished down to quite a bit bigger than 7x7). And then expanded out again all this way which means it has to somehow store all the information about the much bigger version in the small version. And actually most of the information about the bigger version was really in the original picture anyway. So it doesn’t seem like a great approach — this squishing and un-squishing.</p><figure name="c410" id="c410" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_PvXW__XxRQIMoFoVFJq-Zw.png"></figure><p name="2d7d" id="2d7d" class="graf graf--p graf-after--figure">So the U-Net idea comes from this fantastic paper where it was literally invented in this very domain-specific area of biomedical image segmentation. But in fact, basically every Kaggle winner in anything even vaguely related to segmentation has end up using U-Net. It’s one of these things that everybody in Kaggle knows it is the best practice, but in more of academic circles, this has been around for a couple of years at least, a lot of people still don’t realize this is by far the best approach.</p><figure name="5547" id="5547" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_9nxe-lIVxXawNsLzItvqcg.png"></figure><p name="09c5" id="09c5" class="graf graf--p graf-after--figure">Here is the basic idea [<a href="https://youtu.be/nG3tT31nPmQ?t=1h45m10s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h45m10s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:45:10</a>]. On the left is the downward path where we start at 572x572 in this case then halve the grid size 4 times, then on the right is the upward path where we double the grid size 4 times. But the thing that we also do is, at every point where we halve the grid size, we actually copy those activations over to the upward path and concatenate them together.</p><p name="ba90" id="ba90" class="graf graf--p graf-after--p">You can see on the bottom right, these red arrows are max pooling operation, these green arrows are upward sampling, and then these gray arrows are copying. So we copy and concat. In other words, the input image after a couple of convs is copied over to the output, concatenated together, and so now we get to use all of the informations gone through all of the informations gone through all the down and all the up, plus also a slightly modified version of the input pixels. And slightly modified version of one thing down from the input pixels because they came up through here. So we have all of the richness of going all the way down and up, but also a slightly less coarse version and a slightly less coarse version and then the really simple version, and they can all be combined together. So that’s U-Net. It’s such a cool idea.</p><p name="0c3f" id="0c3f" class="graf graf--p graf-after--p">Here we are in the carvana-unet notebook. All this is the same code as before.</p><pre name="f105" id="f105" class="graf graf--pre graf-after--p">%matplotlib inline<br>%reload_ext autoreload<br>%autoreload 2</pre><pre name="b9dd" id="b9dd" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">from</strong> <strong class="markup--strong markup--pre-strong">fastai.conv_learner</strong> <strong class="markup--strong markup--pre-strong">import</strong> *<br><strong class="markup--strong markup--pre-strong">from</strong> <strong class="markup--strong markup--pre-strong">fastai.dataset</strong> <strong class="markup--strong markup--pre-strong">import</strong> *<br><strong class="markup--strong markup--pre-strong">from</strong> <strong class="markup--strong markup--pre-strong">fastai.models.resnet</strong> <strong class="markup--strong markup--pre-strong">import</strong> vgg_resnet50<br><br><strong class="markup--strong markup--pre-strong">import</strong> <strong class="markup--strong markup--pre-strong">json</strong></pre><pre name="c574" id="c574" class="graf graf--pre graf-after--pre">torch.backends.cudnn.benchmark=<strong class="markup--strong markup--pre-strong">True</strong></pre><h3 name="a68a" id="a68a" class="graf graf--h3 graf-after--pre">Data</h3><pre name="ac3e" id="ac3e" class="graf graf--pre graf-after--h3">PATH = Path('data/carvana')<br>MASKS_FN = 'train_masks.csv'<br>META_FN = 'metadata.csv'<br>masks_csv = pd.read_csv(PATH/MASKS_FN)<br>meta_csv = pd.read_csv(PATH/META_FN)</pre><pre name="4c94" id="4c94" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">def</strong> show_img(im, figsize=<strong class="markup--strong markup--pre-strong">None</strong>, ax=<strong class="markup--strong markup--pre-strong">None</strong>, alpha=<strong class="markup--strong markup--pre-strong">None</strong>):<br>    <strong class="markup--strong markup--pre-strong">if</strong> <strong class="markup--strong markup--pre-strong">not</strong> ax: fig,ax = plt.subplots(figsize=figsize)<br>    ax.imshow(im, alpha=alpha)<br>    ax.set_axis_off()<br>    <strong class="markup--strong markup--pre-strong">return</strong> ax</pre><pre name="1f89" id="1f89" class="graf graf--pre graf-after--pre">TRAIN_DN = 'train-128'<br>MASKS_DN = 'train_masks-128'<br>sz = 128<br>bs = 64<br>nw = 16</pre><pre name="9e98" id="9e98" class="graf graf--pre graf-after--pre">TRAIN_DN = 'train'<br>MASKS_DN = 'train_masks_png'<br>sz = 128<br>bs = 64<br>nw = 16</pre><pre name="6d6b" id="6d6b" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">MatchedFilesDataset</strong>(FilesDataset):<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, fnames, y, transform, path):<br>        self.y=y<br>        <strong class="markup--strong markup--pre-strong">assert</strong>(len(fnames)==len(y))<br>        super().__init__(fnames, transform, path)<br>    <strong class="markup--strong markup--pre-strong">def</strong> get_y(self, i): <br>        <strong class="markup--strong markup--pre-strong">return</strong> open_image(os.path.join(self.path, self.y[i]))<br>    <strong class="markup--strong markup--pre-strong">def</strong> get_c(self): <strong class="markup--strong markup--pre-strong">return</strong> 0</pre><pre name="18ff" id="18ff" class="graf graf--pre graf-after--pre">x_names = np.array([Path(TRAIN_DN)/o <strong class="markup--strong markup--pre-strong">for</strong> o <strong class="markup--strong markup--pre-strong">in</strong> masks_csv['img']])<br>y_names = np.array([Path(MASKS_DN)/f'<strong class="markup--strong markup--pre-strong">{o[:-4]}</strong>_mask.png' <br>                        <strong class="markup--strong markup--pre-strong">for</strong> o <strong class="markup--strong markup--pre-strong">in</strong> masks_csv['img']])</pre><pre name="ca81" id="ca81" class="graf graf--pre graf-after--pre">val_idxs = list(range(1008))<br>((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names, <br>                                             y_names)</pre><pre name="4f6d" id="4f6d" class="graf graf--pre graf-after--pre">aug_tfms = [RandomRotate(4, tfm_y=TfmType.CLASS),<br>            RandomFlip(tfm_y=TfmType.CLASS),<br>            RandomLighting(0.05, 0.05, tfm_y=TfmType.CLASS)]</pre><pre name="947a" id="947a" class="graf graf--pre graf-after--pre">tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO, <br>                        tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)<br>datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), <br>                             (val_x,val_y), tfms, path=PATH)<br>md = ImageData(PATH, datasets, bs, num_workers=16, classes=<strong class="markup--strong markup--pre-strong">None</strong>)<br>denorm = md.trn_ds.denorm</pre><pre name="d275" id="d275" class="graf graf--pre graf-after--pre">x,y = next(iter(md.trn_dl))</pre><pre name="c095" id="c095" class="graf graf--pre graf-after--pre">x.shape,y.shape</pre><pre name="91d0" id="91d0" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">(torch.Size([64, 3, 128, 128]), torch.Size([64, 128, 128]))</em></pre><h3 name="c5a9" id="c5a9" class="graf graf--h3 graf-after--pre">Simple upsample</h3><p name="6874" id="6874" class="graf graf--p graf-after--h3">And at the start, I’ve got a simple upsample version just to show you again the non U-net version. This time, I’m going to add in something called the dice metric. Dice is very similar, as you see, to Jaccard or I over U. It’s just a minor difference. It’s basically intersection over union with a minor tweak. The reason we are going to use dice is that’s the metric that Kaggle competition used and it’s a little bit harder to get a high dice score than a high accuracy because it’s really looking at what the overlap of the correct pixels are with your pixels. But it’s pretty similar.</p><p name="933f" id="933f" class="graf graf--p graf-after--p">So in the Kaggle competition, people that were doing okay were getting about 99.6 dice and the winners were about 99.7 dice.</p><pre name="62eb" id="62eb" class="graf graf--pre graf-after--p">f = resnet34<br>cut,lr_cut = model_meta[f]</pre><pre name="7461" id="7461" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">def</strong> get_base():<br>    layers = cut_model(f(<strong class="markup--strong markup--pre-strong">True</strong>), cut)<br>    <strong class="markup--strong markup--pre-strong">return</strong> nn.Sequential(*layers)</pre><pre name="dc8d" id="dc8d" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">def</strong> dice(pred, targs):<br>    pred = (pred&gt;0).float()<br>    <strong class="markup--strong markup--pre-strong">return</strong> 2. * (pred*targs).sum() / (pred+targs).sum()</pre><p name="8d29" id="8d29" class="graf graf--p graf-after--pre">Here is our standard upsample.</p><pre name="a159" id="a159" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">StdUpsample</strong>(nn.Module):<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, nin, nout):<br>        super().__init__()<br>        self.conv = nn.ConvTranspose2d(nin, nout, 2, stride=2)<br>        self.bn = nn.BatchNorm2d(nout)<br>        <br>    <strong class="markup--strong markup--pre-strong">def</strong> forward(self, x): <strong class="markup--strong markup--pre-strong">return</strong> self.bn(F.relu(self.conv(x)))</pre><p name="27b2" id="27b2" class="graf graf--p graf-after--pre">This all as before.</p><pre name="4f5a" id="4f5a" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">Upsample34</strong>(nn.Module):<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, rn):<br>        super().__init__()<br>        self.rn = rn<br>        self.features = nn.Sequential(<br>            rn, nn.ReLU(),<br>            StdUpsample(512,256),<br>            StdUpsample(256,256),<br>            StdUpsample(256,256),<br>            StdUpsample(256,256),<br>            nn.ConvTranspose2d(256, 1, 2, stride=2))<br>        <br>    <strong class="markup--strong markup--pre-strong">def</strong> forward(self,x): <strong class="markup--strong markup--pre-strong">return</strong> self.features(x)[:,0]</pre><pre name="32ac" id="32ac" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">UpsampleModel</strong>():<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self,model,name='upsample'):<br>        self.model,self.name = model,name<br><br>    <strong class="markup--strong markup--pre-strong">def</strong> get_layer_groups(self, precompute):<br>        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))<br>        <strong class="markup--strong markup--pre-strong">return</strong> lgs + [children(self.model.features)[1:]]</pre><pre name="c218" id="c218" class="graf graf--pre graf-after--pre">m_base = get_base() </pre><pre name="b10e" id="b10e" class="graf graf--pre graf-after--pre">m = to_gpu(Upsample34(m_base))<br>models = UpsampleModel(m)</pre><pre name="bfc2" id="bfc2" class="graf graf--pre graf-after--pre">learn = ConvLearner(md, models)<br>learn.opt_fn=optim.Adam<br>learn.crit=nn.BCEWithLogitsLoss()<br>learn.metrics=[accuracy_thresh(0.5),dice]</pre><pre name="57f0" id="57f0" class="graf graf--pre graf-after--pre">learn.freeze_to(1)</pre><pre name="c11f" id="c11f" class="graf graf--pre graf-after--pre">learn.lr_find()<br>learn.sched.plot()</pre><pre name="ba37" id="ba37" class="graf graf--pre graf-after--pre">86%|█████████████████████████████████████████████████████████████          | 55/64 [00:22&lt;00:03,  2.46it/s, loss=3.21]</pre><figure name="40ce" id="40ce" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_X_dHSL-SZqkKw31hZgughg.png"></figure><pre name="deaa" id="deaa" class="graf graf--pre graf-after--figure">lr=4e-2<br>wd=1e-7<br>lrs = np.array([lr/100,lr/10,lr])/2</pre><pre name="66ec" id="66ec" class="graf graf--pre graf-after--pre">learn.fit(lr,1, wds=wd, cycle_len=4,use_clr=(20,8))</pre><pre name="b940" id="b940" class="graf graf--pre graf-after--pre">0%|          | 0/64 [00:00&lt;?, ?it/s]<br>epoch      trn_loss   val_loss   &lt;lambda&gt;   dice           <br>    0      0.216882   0.133512   0.938017   0.855221  <br>    1      0.169544   0.115158   0.946518   0.878381       <br>    2      0.153114   0.099104   0.957748   0.903353       <br>    3      0.144105   0.093337   0.964404   0.915084</pre><pre name="0723" id="0723" class="graf graf--pre graf-after--pre">[0.09333742126112893, 0.9644036065964472, 0.9150839788573129]</pre><pre name="8b4c" id="8b4c" class="graf graf--pre graf-after--pre">learn.save('tmp')</pre><pre name="cd9c" id="cd9c" class="graf graf--pre graf-after--pre">learn.load('tmp')</pre><pre name="3ffa" id="3ffa" class="graf graf--pre graf-after--pre">learn.unfreeze()<br>learn.bn_freeze(<strong class="markup--strong markup--pre-strong">True</strong>)</pre><pre name="9578" id="9578" class="graf graf--pre graf-after--pre">learn.fit(lrs,1,cycle_len=4,use_clr=(20,8))</pre><pre name="add2" id="add2" class="graf graf--pre graf-after--pre">epoch      trn_loss   val_loss   &lt;lambda&gt;   dice           <br>    0      0.174897   0.061603   0.976321   0.94382   <br>    1      0.122911   0.053625   0.982206   0.957624       <br>    2      0.106837   0.046653   0.985577   0.965792       <br>    3      0.099075   0.042291   0.986519   0.968925</pre><pre name="0294" id="0294" class="graf graf--pre graf-after--pre">[0.042291240323157536, 0.986519161670927, 0.9689251193924556]</pre><p name="f747" id="f747" class="graf graf--p graf-after--pre">Now we can check our dice metric [<a href="https://youtu.be/nG3tT31nPmQ?t=1h48m" data-href="https://youtu.be/nG3tT31nPmQ?t=1h48m" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">1:48:00</a>]. So you can see on dice metric, we are getting around 96.8 at 128x128. So that’s not great.</p><pre name="b497" id="b497" class="graf graf--pre graf-after--p">learn.save('128')</pre><pre name="55ee" id="55ee" class="graf graf--pre graf-after--pre">x,y = next(iter(md.val_dl))<br>py = to_np(learn.model(V(x)))</pre><pre name="508f" id="508f" class="graf graf--pre graf-after--pre">show_img(py[0]&gt;0);</pre><figure name="1980" id="1980" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_w6f-XvZMeLKt4Fc7O_S4EQ.png"></figure><pre name="a981" id="a981" class="graf graf--pre graf-after--figure">show_img(y[0]);</pre><figure name="8eda" id="8eda" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_SHntdwiyRvupP9SQO5BD5g.png"></figure><h4 name="5e27" id="5e27" class="graf graf--h4 graf-after--figure">U-net (ish) [<a href="https://youtu.be/nG3tT31nPmQ?t=1h48m16s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h48m16s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:48:16</a>]</h4><p name="340c" id="340c" class="graf graf--p graf-after--h4">So let’s try U-Net. I’m calling it U-net(ish) because as per usual I’m creating my own somewhat hacky version — trying to keep things as similar to what you’re used to as possible and doing things that I think makes sense. So there should be plenty of opportunity for you to at least make this more authentically U-net by looking at the exact grid sizes and see how here (the top left convs) the size is going down a little bit. So they are obviously not adding any padding and then there are some cropping going on — there’s a few differences. But one of the things is because I want to take advantage of transfer learning — that means I can’t quite use U-Net.</p><p name="e4c3" id="e4c3" class="graf graf--p graf-after--p">So here is another big opportunity is what if you create the U-Net down path and then add a classifier on the end and then train that on ImageNet. You’ve now got an ImageNet trained classifier which is specifically designed to be a good backbone for U-Net. Then you should be able to now come back and get pretty closed to winning this old competition (it’s actually not that old — it’s fairly recent competition). Because that pre-trained network didn’t exist before. But if you think about what YOLO v3 did, it’s basically that. They created a DarkNet, they pre-trained it on ImageNet, and then they used it as the basis for their bounding boxes. So again, this idea of pre-training things which are designed not just for classification but designed for other things — it’s just something that nobody has done yet. But as we’ve shown, you can train ImageNet for $25 in three hours now. And if people in the community are interested in doing this, hopefully I’ll have credits I can help you with as well so if you do, the work to get it set up and give me a script, I can probably run it for you. For now though, we don’t have that yet. So we are going to use ResNet.</p><pre name="6259" id="6259" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">SaveFeatures</strong>():<br>    features=<strong class="markup--strong markup--pre-strong">None</strong><br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, m):<br>        self.hook = m.register_forward_hook(self.hook_fn)<br>    <strong class="markup--strong markup--pre-strong">def</strong> hook_fn(self, module, input, output): self.features = output<br>    <strong class="markup--strong markup--pre-strong">def</strong> remove(self): self.hook.remove()</pre><p name="b8f8" id="b8f8" class="graf graf--p graf-after--pre">So we are basically going to start with <code class="markup--code markup--p-code">get_base</code> [<a href="https://youtu.be/nG3tT31nPmQ?t=1h50m37s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h50m37s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:50:37</a>]. Base is our base network and that was defined back up in the first section.</p><figure name="1288" id="1288" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_BDJmGsOK8kX9gHUyiQ3Xgw.png"></figure><p name="a160" id="a160" class="graf graf--p graf-after--figure">So get_base is going to be something that calls whatever f is and <code class="markup--code markup--p-code">f</code> is <code class="markup--code markup--p-code">resnet34</code>. So we are going to grab our ResNet34 and cut_model is the first thing that our convnet builder does. It basically removes everything from the adaptive pooling onwards, so that gives us back the backbone of ResNet34. So <code class="markup--code markup--p-code">get_base</code> is going to give us back the ResNet34 backbone.</p><pre name="dfdb" id="dfdb" class="graf graf--pre graf-after--p"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">UnetBlock</strong>(nn.Module):<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, up_in, x_in, n_out):<br>        super().__init__()<br>        up_out = x_out = n_out//2<br>        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)<br>        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, <br>                                          stride=2)<br>        self.bn = nn.BatchNorm2d(n_out)<br>        <br>    <strong class="markup--strong markup--pre-strong">def</strong> forward(self, up_p, x_p):<br>        up_p = self.tr_conv(up_p)<br>        x_p = self.x_conv(x_p)<br>        cat_p = torch.cat([up_p,x_p], dim=1)<br>        <strong class="markup--strong markup--pre-strong">return</strong> self.bn(F.relu(cat_p))</pre><pre name="b098" id="b098" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">Unet34</strong>(nn.Module):<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self, rn):<br>        super().__init__()<br>        self.rn = rn<br>        self.sfs = [SaveFeatures(rn[i]) <strong class="markup--strong markup--pre-strong">for</strong> i <strong class="markup--strong markup--pre-strong">in</strong> [2,4,5,6]]<br>        self.up1 = UnetBlock(512,256,256)<br>        self.up2 = UnetBlock(256,128,256)<br>        self.up3 = UnetBlock(256,64,256)<br>        self.up4 = UnetBlock(256,64,256)<br>        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)<br>        <br>    <strong class="markup--strong markup--pre-strong">def</strong> forward(self,x):<br>        x = F.relu(self.rn(x))<br>        x = self.up1(x, self.sfs[3].features)<br>        x = self.up2(x, self.sfs[2].features)<br>        x = self.up3(x, self.sfs[1].features)<br>        x = self.up4(x, self.sfs[0].features)<br>        x = self.up5(x)<br>        <strong class="markup--strong markup--pre-strong">return</strong> x[:,0]<br>    <br>    <strong class="markup--strong markup--pre-strong">def</strong> close(self):<br>        <strong class="markup--strong markup--pre-strong">for</strong> sf <strong class="markup--strong markup--pre-strong">in</strong> self.sfs: sf.remove()</pre><pre name="1a9f" id="1a9f" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">class</strong> <strong class="markup--strong markup--pre-strong">UnetModel</strong>():<br>    <strong class="markup--strong markup--pre-strong">def</strong> __init__(self,model,name='unet'):<br>        self.model,self.name = model,name<br><br>    <strong class="markup--strong markup--pre-strong">def</strong> get_layer_groups(self, precompute):<br>        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))<br>        <strong class="markup--strong markup--pre-strong">return</strong> lgs + [children(self.model)[1:]]</pre><p name="0992" id="0992" class="graf graf--p graf-after--pre">Then we are going to take that ResNet34 backbone and turn it into a, I call it a, Unet34 [<a href="https://youtu.be/nG3tT31nPmQ?t=1h51m17s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h51m17s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:51:17</a>]. So what that’s going to do is it’s going to save that ResNet that we passed in and then we are going to use a forward hook just like before to save the results at the 2nd, 4th, 5th, and 6th blocks which as before is the layers before each stride 2 convolution. Then we are going to create a bunch of these things we are calling <code class="markup--code markup--p-code">UnetBlock</code>. We need to tell <code class="markup--code markup--p-code">UnetBlock</code> how many things are coming from the previous layer we are upsampling, how many are coming across, and then how many do we want to come out. The amount coming across is entirely defined by whatever the base network was — whatever the downward path was, we need that many layers. So this is a little bit awkward. Actually one of our master’s students here, Kerem, has actually created something called DynamicUnet that you’ll find in <a href="https://github.com/fastai/fastai/blob/d3ef60a96cddf5b503361ed4c95d68dda4a873fc/fastai/models/unet.py#L53" data-href="https://github.com/fastai/fastai/blob/d3ef60a96cddf5b503361ed4c95d68dda4a873fc/fastai/models/unet.py#L53" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">fastai.model.DynamicUnet</a> and it actually calculates this all for you and automatically creates the whole Unet from your base model. It’s got some minor quirks still that I want to fix. By the time the video is out, it’ll definitely be working and I will at least have a notebook showing how to use it and possibly an additional video. But for now you’ll just have to go through and do it yourself. You can easily see it just by, once you’ve got a ResNet, you can just type in its name and it’ll print out the layers. And you can see how many many activations there are in each block. Or you can have it printed out for you for each block automatically. Anyway, I just did this manually.</p><figure name="cfb4" id="cfb4" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_uJ4edTfPiSXfCXkFQ82Svg.png"></figure><p name="673e" id="673e" class="graf graf--p graf-after--figure">So the UnetBlock works like this [<a href="https://youtu.be/nG3tT31nPmQ?t=1h53m29s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h53m29s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:53:29</a>]:</p><ul class="postList"><li name="f390" id="f390" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">up_in</code>&nbsp;: This many are coming up from the previous layer</li><li name="9340" id="9340" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">x_in</code>&nbsp;: This many are coming across (hence <code class="markup--code markup--li-code">x</code>) from the downward path</li><li name="cb92" id="cb92" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">n_out</code>&nbsp;: The amount we want coming out</li></ul><p name="3d2e" id="3d2e" class="graf graf--p graf-after--li">Now what I do is&nbsp;, I then say, okay we’re going to create a certain amount of convolutions from the upward path and a certain amount from the cross path, and so I’m going to be concatenating them together so let’s divide the number we want out by 2. And so we are going to have our cross convolution take our cross path and create number out divided by 2 (<code class="markup--code markup--p-code">n_out//2</code>). And then the upward path is going to be a <code class="markup--code markup--p-code">ConvTranspose2d</code> because we want to increase/upsample. Again here, we’ve got the number out divided by 2 (<code class="markup--code markup--p-code">up_out</code>), then at the end, I just concatenate those together.</p><p name="7b32" id="7b32" class="graf graf--p graf-after--p">So I’ve got an upward sample, I’ve got a cross convolution, I can concatenate the two together. That’s all a UnetBlock is. So that’s actually a pretty easy module to create.</p><figure name="263d" id="263d" class="graf graf--figure graf-after--p"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_cXPJlacjby171FsaalyHcQ.png"></figure><p name="e27e" id="e27e" class="graf graf--p graf-after--figure">Then in my forward path, I need to pass to the forward of the UnetBlock the upward path and the cross path [<a href="https://youtu.be/nG3tT31nPmQ?t=1h54m40s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h54m40s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:54:40</a>]. The upward path is just whatever I am up to so far. But then the cross path is whatever the activations are that I stored on the way down. So as I come up, it’s the last set of saved features that I need first. And as I gradually keep going up farther and farther, eventually it’s the first set of features.</p><p name="7037" id="7037" class="graf graf--p graf-after--p">There are some more tricks we can do to make this a little bit better, but this is a good stuff. So the simple upsampling approach looked horrible and had a dice of&nbsp;.968. A Unet with everything else identical except we’ve now got these UnetBlocks has a dice of&nbsp;…</p><pre name="93b4" id="93b4" class="graf graf--pre graf-after--p">m_base = get_base()<br>m = to_gpu(Unet34(m_base))<br>models = UnetModel(m)</pre><pre name="baf5" id="baf5" class="graf graf--pre graf-after--pre">learn = ConvLearner(md, models)<br>learn.opt_fn=optim.Adam<br>learn.crit=nn.BCEWithLogitsLoss()<br>learn.metrics=[accuracy_thresh(0.5),dice]</pre><pre name="daf1" id="daf1" class="graf graf--pre graf-after--pre">learn.summary()</pre><pre name="8032" id="8032" class="graf graf--pre graf-after--pre">OrderedDict([('Conv2d-1',<br>              OrderedDict([('input_shape', [-1, 3, 128, 128]),<br>                           ('output_shape', [-1, 64, 64, 64]),<br>                           ('trainable', False),<br>                           ('nb_params', 9408)])),<br>             ('BatchNorm2d-2',<br>              OrderedDict([('input_shape', [-1, 64, 64, 64]),<br>                           ('output_shape', [-1, 64, 64, 64]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-3',<br>              OrderedDict([('input_shape', [-1, 64, 64, 64]),<br>                           ('output_shape', [-1, 64, 64, 64]),<br>                           ('nb_params', 0)])),<br>             ('MaxPool2d-4',<br>              OrderedDict([('input_shape', [-1, 64, 64, 64]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-5',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 36864)])),<br>             ('BatchNorm2d-6',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-7',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-8',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 36864)])),<br>             ('BatchNorm2d-9',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-10',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-11',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-12',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 36864)])),<br>             ('BatchNorm2d-13',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-14',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-15',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 36864)])),<br>             ('BatchNorm2d-16',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-17',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-18',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-19',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 36864)])),<br>             ('BatchNorm2d-20',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-21',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-22',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 36864)])),<br>             ('BatchNorm2d-23',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('trainable', False),<br>                           ('nb_params', 128)])),<br>             ('ReLU-24',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-25',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 64, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-26',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 73728)])),<br>             ('BatchNorm2d-27',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-28',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-29',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-30',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('Conv2d-31',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 8192)])),<br>             ('BatchNorm2d-32',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-33',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-34',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-35',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-36',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-37',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-38',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-39',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-40',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-41',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-42',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-43',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-44',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-45',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-46',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-47',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-48',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-49',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-50',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-51',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-52',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 147456)])),<br>             ('BatchNorm2d-53',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', False),<br>                           ('nb_params', 256)])),<br>             ('ReLU-54',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-55',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-56',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 294912)])),<br>             ('BatchNorm2d-57',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-58',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-59',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-60',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('Conv2d-61',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 32768)])),<br>             ('BatchNorm2d-62',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-63',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-64',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-65',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-66',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-67',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-68',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-69',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-70',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-71',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-72',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-73',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-74',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-75',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-76',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-77',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-78',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-79',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-80',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-81',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-82',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-83',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-84',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-85',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-86',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-87',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-88',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-89',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-90',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-91',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-92',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-93',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-94',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-95',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-96',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 589824)])),<br>             ('BatchNorm2d-97',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', False),<br>                           ('nb_params', 512)])),<br>             ('ReLU-98',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-99',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-100',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1179648)])),<br>             ('BatchNorm2d-101',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('ReLU-102',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-103',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 2359296)])),<br>             ('BatchNorm2d-104',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('Conv2d-105',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 131072)])),<br>             ('BatchNorm2d-106',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('ReLU-107',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-108',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-109',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 2359296)])),<br>             ('BatchNorm2d-110',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('ReLU-111',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-112',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 2359296)])),<br>             ('BatchNorm2d-113',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('ReLU-114',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-115',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-116',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 2359296)])),<br>             ('BatchNorm2d-117',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('ReLU-118',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('Conv2d-119',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 2359296)])),<br>             ('BatchNorm2d-120',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('trainable', False),<br>                           ('nb_params', 1024)])),<br>             ('ReLU-121',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('BasicBlock-122',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 512, 4, 4]),<br>                           ('nb_params', 0)])),<br>             ('ConvTranspose2d-123',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 128, 8, 8]),<br>                           ('trainable', True),<br>                           ('nb_params', 262272)])),<br>             ('Conv2d-124',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 128, 8, 8]),<br>                           ('trainable', True),<br>                           ('nb_params', 32896)])),<br>             ('BatchNorm2d-125',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('trainable', True),<br>                           ('nb_params', 512)])),<br>             ('UnetBlock-126',<br>              OrderedDict([('input_shape', [-1, 512, 4, 4]),<br>                           ('output_shape', [-1, 256, 8, 8]),<br>                           ('nb_params', 0)])),<br>             ('ConvTranspose2d-127',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', True),<br>                           ('nb_params', 131200)])),<br>             ('Conv2d-128',<br>              OrderedDict([('input_shape', [-1, 128, 16, 16]),<br>                           ('output_shape', [-1, 128, 16, 16]),<br>                           ('trainable', True),<br>                           ('nb_params', 16512)])),<br>             ('BatchNorm2d-129',<br>              OrderedDict([('input_shape', [-1, 256, 16, 16]),<br>                           ('output_shape', [-1, 256, 16, 16]),<br>                           ('trainable', True),<br>                           ('nb_params', 512)])),<br>             ('UnetBlock-130',<br>              OrderedDict([('input_shape', [-1, 256, 8, 8]),<br>                           ('output_shape', [-1, 256, 16, 16]),<br>                           ('nb_params', 0)])),<br>             ('ConvTranspose2d-131',<br>              OrderedDict([('input_shape', [-1, 256, 16, 16]),<br>                           ('output_shape', [-1, 128, 32, 32]),<br>                           ('trainable', True),<br>                           ('nb_params', 131200)])),<br>             ('Conv2d-132',<br>              OrderedDict([('input_shape', [-1, 64, 32, 32]),<br>                           ('output_shape', [-1, 128, 32, 32]),<br>                           ('trainable', True),<br>                           ('nb_params', 8320)])),<br>             ('BatchNorm2d-133',<br>              OrderedDict([('input_shape', [-1, 256, 32, 32]),<br>                           ('output_shape', [-1, 256, 32, 32]),<br>                           ('trainable', True),<br>                           ('nb_params', 512)])),<br>             ('UnetBlock-134',<br>              OrderedDict([('input_shape', [-1, 256, 16, 16]),<br>                           ('output_shape', [-1, 256, 32, 32]),<br>                           ('nb_params', 0)])),<br>             ('ConvTranspose2d-135',<br>              OrderedDict([('input_shape', [-1, 256, 32, 32]),<br>                           ('output_shape', [-1, 128, 64, 64]),<br>                           ('trainable', True),<br>                           ('nb_params', 131200)])),<br>             ('Conv2d-136',<br>              OrderedDict([('input_shape', [-1, 64, 64, 64]),<br>                           ('output_shape', [-1, 128, 64, 64]),<br>                           ('trainable', True),<br>                           ('nb_params', 8320)])),<br>             ('BatchNorm2d-137',<br>              OrderedDict([('input_shape', [-1, 256, 64, 64]),<br>                           ('output_shape', [-1, 256, 64, 64]),<br>                           ('trainable', True),<br>                           ('nb_params', 512)])),<br>             ('UnetBlock-138',<br>              OrderedDict([('input_shape', [-1, 256, 32, 32]),<br>                           ('output_shape', [-1, 256, 64, 64]),<br>                           ('nb_params', 0)])),<br>             ('ConvTranspose2d-139',<br>              OrderedDict([('input_shape', [-1, 256, 64, 64]),<br>                           ('output_shape', [-1, 1, 128, 128]),<br>                           ('trainable', True),<br>                           ('nb_params', 1025)]))])</pre><pre name="35de" id="35de" class="graf graf--pre graf-after--pre">[o.features.size() <strong class="markup--strong markup--pre-strong">for</strong> o <strong class="markup--strong markup--pre-strong">in</strong> m.sfs]</pre><pre name="9db4" id="9db4" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[torch.Size([3, 64, 64, 64]),<br> torch.Size([3, 64, 32, 32]),<br> torch.Size([3, 128, 16, 16]),<br> torch.Size([3, 256, 8, 8])]</em></pre><pre name="26ea" id="26ea" class="graf graf--pre graf-after--pre">learn.freeze_to(1)</pre><pre name="ff8d" id="ff8d" class="graf graf--pre graf-after--pre">learn.lr_find()<br>learn.sched.plot()</pre><pre name="93a7" id="93a7" class="graf graf--pre graf-after--pre"> 0%|                                                                                           | 0/64 [00:00&lt;?, ?it/s]</pre><pre name="597f" id="597f" class="graf graf--pre graf-after--pre">92%|█████████████████████████████████████████████████████████████████▍     | 59/64 [00:22&lt;00:01,  2.68it/s, loss=2.45]</pre><figure name="ed74" id="ed74" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_kSXmrtfSNjvDnBoLEAiUaw.png"></figure><pre name="b1ac" id="b1ac" class="graf graf--pre graf-after--figure">lr=4e-2<br>wd=1e-7<br><br>lrs = np.array([lr/100,lr/10,lr])</pre><pre name="f56f" id="f56f" class="graf graf--pre graf-after--pre">learn.fit(lr,1,wds=wd,cycle_len=8,use_clr=(5,8))</pre><pre name="1e40" id="1e40" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">epoch      trn_loss   val_loss   &lt;lambda&gt;   dice           <br>    0      0.12936    0.03934    0.988571   0.971385  <br>    1      0.098401   0.039252   0.990438   0.974921        <br>    2      0.087789   0.02539    0.990961   0.978927        <br>    3      0.082625   0.027984   0.988483   0.975948        <br>    4      0.079509   0.025003   0.99171    0.981221        <br>    5      0.076984   0.022514   0.992462   0.981881        <br>    6      0.076822   0.023203   0.992484   0.982321        <br>    7      0.075488   0.021956   0.992327   0.982704</em></pre><pre name="a505" id="a505" class="graf graf--pre graf-after--pre"><em class="markup--em markup--pre-em">[0.021955982234979434, 0.9923273126284281, 0.9827044502137199]</em></pre><pre name="f074" id="f074" class="graf graf--pre graf-after--pre">learn.save('128urn-tmp')</pre><pre name="0b41" id="0b41" class="graf graf--pre graf-after--pre">learn.load('128urn-tmp')</pre><pre name="b057" id="b057" class="graf graf--pre graf-after--pre">learn.unfreeze()<br>learn.bn_freeze(<strong class="markup--strong markup--pre-strong">True</strong>)</pre><pre name="0ee9" id="0ee9" class="graf graf--pre graf-after--pre">learn.fit(lrs/4, 1, wds=wd, cycle_len=20,use_clr=(20,10))</pre><pre name="c6bd" id="c6bd" class="graf graf--pre graf-after--pre">0%|          | 0/64 [00:00&lt;?, ?it/s]<br>epoch      trn_loss   val_loss   &lt;lambda&gt;   dice            <br>    0      0.073786   0.023418   0.99297    0.98283   <br>    1      0.073561   0.020853   0.992142   0.982725        <br>    2      0.075227   0.023357   0.991076   0.980879        <br>    3      0.074245   0.02352    0.993108   0.983659        <br>    4      0.073434   0.021508   0.993024   0.983609        <br>    5      0.073092   0.020956   0.993188   0.983333        <br>    6      0.073617   0.019666   0.993035   0.984102        <br>    7      0.072786   0.019844   0.993196   0.98435         <br>    8      0.072256   0.018479   0.993282   0.984277        <br>    9      0.072052   0.019479   0.993164   0.984147        <br>    10     0.071361   0.019402   0.993344   0.984541        <br>    11     0.070969   0.018904   0.993139   0.984499        <br>    12     0.071588   0.018027   0.9935     0.984543        <br>    13     0.070709   0.018345   0.993491   0.98489         <br>    14     0.072238   0.019096   0.993594   0.984825        <br>    15     0.071407   0.018967   0.993446   0.984919        <br>    16     0.071047   0.01966    0.993366   0.984952        <br>    17     0.072024   0.018133   0.993505   0.98497         <br>    18     0.071517   0.018464   0.993602   0.985192        <br>    19     0.070109   0.018337   0.993614   0.9852</pre><pre name="aabb" id="aabb" class="graf graf--pre graf-after--pre">[0.018336569653853538, 0.9936137114252362, 0.9852004420189631]</pre><p name="df93" id="df93" class="graf graf--p graf-after--pre">.985! That’s like we halved the error with everything else exactly the same [<a href="https://youtu.be/nG3tT31nPmQ?t=1h55m42s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h55m42s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:55:42</a>]. And more the point, you can look at it.</p><pre name="f648" id="f648" class="graf graf--pre graf-after--p">learn.save('128urn-0')</pre><pre name="a362" id="a362" class="graf graf--pre graf-after--pre">learn.load('128urn-0')</pre><pre name="2295" id="2295" class="graf graf--pre graf-after--pre">x,y = next(iter(md.val_dl))<br>py = to_np(learn.model(V(x)))</pre><p name="c62d" id="c62d" class="graf graf--p graf-after--pre">This is actually looking somewhat car-like compared to our non-Unet equivalent which is just a blob. Because trying to do this through down and up paths — it’s just asking too much. Where else, when we actually provide the downward path pixels at every point, it can actually start to create something car-ish.</p><pre name="8a8b" id="8a8b" class="graf graf--pre graf-after--p">show_img(py[0]&gt;0);</pre><figure name="5bae" id="5bae" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_AuMRaTQP4gCUW0iHHvf2uQ.png"></figure><pre name="c36b" id="c36b" class="graf graf--pre graf-after--figure">show_img(y[0]);</pre><figure name="2dba" id="2dba" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_SHntdwiyRvupP9SQO5BD5g.png"></figure><p name="e9a3" id="e9a3" class="graf graf--p graf-after--figure">At the end of that, we’ll do m.close to remove those <code class="markup--code markup--p-code">sfs.features</code> taking up GPU memory.</p><pre name="426d" id="426d" class="graf graf--pre graf-after--p">m.close()</pre><h4 name="f39c" id="f39c" class="graf graf--h4 graf-after--pre">512x512 [<a href="https://youtu.be/nG3tT31nPmQ?t=1h56m26s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h56m26s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:56:26</a>]</h4><p name="09ca" id="09ca" class="graf graf--p graf-after--h4">Go to a smaller batch size, higher size</p><pre name="9e81" id="9e81" class="graf graf--pre graf-after--p">sz=512<br>bs=16</pre><pre name="6b68" id="6b68" class="graf graf--pre graf-after--pre">tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO, <br>                       tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)<br>datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), <br>                            (val_x,val_y), tfms, path=PATH)<br>md = ImageData(PATH, datasets, bs, num_workers=4, classes=<strong class="markup--strong markup--pre-strong">None</strong>)<br>denorm = md.trn_ds.denorm</pre><pre name="134a" id="134a" class="graf graf--pre graf-after--pre">m_base = get_base()<br>m = to_gpu(Unet34(m_base))<br>models = UnetModel(m)</pre><pre name="2824" id="2824" class="graf graf--pre graf-after--pre">learn = ConvLearner(md, models)<br>learn.opt_fn=optim.Adam<br>learn.crit=nn.BCEWithLogitsLoss()<br>learn.metrics=[accuracy_thresh(0.5),dice]</pre><pre name="3395" id="3395" class="graf graf--pre graf-after--pre">learn.freeze_to(1)</pre><pre name="653f" id="653f" class="graf graf--pre graf-after--pre"><strong class="markup--strong markup--pre-strong">learn.load('128urn-0')</strong></pre><pre name="397d" id="397d" class="graf graf--pre graf-after--pre">learn.fit(lr,1,wds=wd, cycle_len=5,use_clr=(5,5))</pre><pre name="6be3" id="6be3" class="graf graf--pre graf-after--pre">epoch      trn_loss   val_loss   &lt;lambda&gt;   dice              <br>    0      0.071421   0.02362    0.996459   0.991772  <br>    1      0.070373   0.014013   0.996558   0.992602          <br>    2      0.067895   0.011482   0.996705   0.992883          <br>    3      0.070653   0.014256   0.996695   0.992771          <br>    4      0.068621   0.013195   0.996993   0.993359</pre><pre name="1bbb" id="1bbb" class="graf graf--pre graf-after--pre">[0.013194938530288046, 0.996993034604996, 0.993358936574724]</pre><p name="eda9" id="eda9" class="graf graf--p graf-after--pre">You can see the dice coefficients really going up [<a href="https://youtu.be/nG3tT31nPmQ?t=1h56m30s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h56m30s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:56:30</a>]. So notice above, I’m loading in the 128x128 version of the network. We are doing this progressive resizing trick again, so that gets us&nbsp;.993.</p><pre name="e673" id="e673" class="graf graf--pre graf-after--p">learn.save('512urn-tmp')</pre><pre name="81f0" id="81f0" class="graf graf--pre graf-after--pre">learn.unfreeze()<br>learn.bn_freeze(<strong class="markup--strong markup--pre-strong">True</strong>)</pre><pre name="c937" id="c937" class="graf graf--pre graf-after--pre">learn.load('512urn-tmp')</pre><pre name="a246" id="a246" class="graf graf--pre graf-after--pre">learn.fit(lrs/4,1,wds=wd, cycle_len=8,use_clr=(20,8))</pre><pre name="ad71" id="ad71" class="graf graf--pre graf-after--pre">epoch      trn_loss   val_loss   &lt;lambda&gt;   dice              <br>    0      0.06605    0.013602   0.997      0.993014  <br>    1      0.066885   0.011252   0.997248   0.993563          <br>    2      0.065796   0.009802   0.997223   0.993817          <br>    3      0.065089   0.009668   0.997296   0.993744          <br>    4      0.064552   0.011683   0.997269   0.993835          <br>    5      0.065089   0.010553   0.997415   0.993827          <br>    6      0.064303   0.009472   0.997431   0.994046          <br>    7      0.062506   0.009623   0.997441   0.994118</pre><pre name="c98d" id="c98d" class="graf graf--pre graf-after--pre">[0.009623114736602894, 0.9974409020136273, 0.9941179137381296]</pre><p name="41d2" id="41d2" class="graf graf--p graf-after--pre">Then unfreeze to get to&nbsp;.994.</p><pre name="57bc" id="57bc" class="graf graf--pre graf-after--p">learn.save('512urn')</pre><pre name="eaeb" id="eaeb" class="graf graf--pre graf-after--pre">learn.load('512urn')</pre><pre name="2914" id="2914" class="graf graf--pre graf-after--pre">x,y = next(iter(md.val_dl))<br>py = to_np(learn.model(V(x)))</pre><p name="052f" id="052f" class="graf graf--p graf-after--pre">And you can see, it’s now looking pretty good.</p><pre name="dda0" id="dda0" class="graf graf--pre graf-after--p">show_img(py[0]&gt;0);</pre><figure name="2e85" id="2e85" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_lW-LsQorUM1UUwRDJiiMKg.png"></figure><pre name="41e9" id="41e9" class="graf graf--pre graf-after--figure">show_img(y[0]);</pre><figure name="4180" id="4180" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_EdCvr3nZIJf6mhwgQActnQ.png"></figure><pre name="f319" id="f319" class="graf graf--pre graf-after--figure">m.close()</pre><h4 name="f028" id="f028" class="graf graf--h4 graf-after--pre">1024x1024 [<a href="https://youtu.be/nG3tT31nPmQ?t=1h56m53s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h56m53s" class="markup--anchor markup--h4-anchor" rel="nofollow noopener" target="_blank">1:56:53</a>]</h4><p name="0df2" id="0df2" class="graf graf--p graf-after--h4">Go down to a batch size of 4, size of 1024.</p><pre name="8416" id="8416" class="graf graf--pre graf-after--p">sz=1024<br>bs=4</pre><pre name="0ece" id="0ece" class="graf graf--pre graf-after--pre">tfms = tfms_from_model(resnet34, sz, crop_type=CropType.NO, <br>                         tfm_y=TfmType.CLASS)<br>datasets = ImageData.get_ds(MatchedFilesDataset, (trn_x,trn_y), <br>                            (val_x,val_y), tfms, path=PATH)<br>md = ImageData(PATH, datasets, bs, num_workers=16, classes=<strong class="markup--strong markup--pre-strong">None</strong>)<br>denorm = md.trn_ds.denorm</pre><pre name="5a4a" id="5a4a" class="graf graf--pre graf-after--pre">m_base = get_base()<br>m = to_gpu(Unet34(m_base))<br>models = UnetModel(m)</pre><pre name="22d8" id="22d8" class="graf graf--pre graf-after--pre">learn = ConvLearner(md, models)<br>learn.opt_fn=optim.Adam<br>learn.crit=nn.BCEWithLogitsLoss()<br>learn.metrics=[accuracy_thresh(0.5),dice]</pre><p name="e9fe" id="e9fe" class="graf graf--p graf-after--pre">Load in what we just saved with the 512.</p><pre name="01bf" id="01bf" class="graf graf--pre graf-after--p">learn.load('512urn')</pre><pre name="813b" id="813b" class="graf graf--pre graf-after--pre">learn.freeze_to(1)</pre><pre name="a020" id="a020" class="graf graf--pre graf-after--pre">learn.fit(lr,1, wds=wd, cycle_len=2,use_clr=(5,4))</pre><pre name="78fc" id="78fc" class="graf graf--pre graf-after--pre">epoch      trn_loss   val_loss   &lt;lambda&gt;   dice                 <br>    0      0.007656   0.008155   0.997247   0.99353   <br>    1      0.004706   0.00509    0.998039   0.995437</pre><pre name="c979" id="c979" class="graf graf--pre graf-after--pre">[0.005090427414942828, 0.9980387706605215, 0.995437301104031]</pre><p name="f808" id="f808" class="graf graf--p graf-after--pre">That gets us to&nbsp;.995.</p><pre name="2f50" id="2f50" class="graf graf--pre graf-after--p">learn.save('1024urn-tmp')</pre><pre name="04c2" id="04c2" class="graf graf--pre graf-after--pre">learn.load('1024urn-tmp')</pre><pre name="9025" id="9025" class="graf graf--pre graf-after--pre">learn.unfreeze()<br>learn.bn_freeze(<strong class="markup--strong markup--pre-strong">True</strong>)</pre><pre name="b82a" id="b82a" class="graf graf--pre graf-after--pre">lrs = np.array([lr/200,lr/30,lr])</pre><pre name="4237" id="4237" class="graf graf--pre graf-after--pre">learn.fit(lrs/10,1, wds=wd,cycle_len=4,use_clr=(20,8))</pre><pre name="1db5" id="1db5" class="graf graf--pre graf-after--pre">epoch      trn_loss   val_loss   &lt;lambda&gt;   dice                 <br>    0      0.005688   0.006135   0.997616   0.994616  <br>    1      0.004412   0.005223   0.997983   0.995349             <br>    2      0.004186   0.004975   0.99806    0.99554              <br>    3      0.004016   0.004899   0.99812    0.995627</pre><pre name="e86a" id="e86a" class="graf graf--pre graf-after--pre">[0.004898778487196458, 0.9981196409180051, 0.9956271404784823]</pre><pre name="ca01" id="ca01" class="graf graf--pre graf-after--pre">learn.fit(lrs/10,1, wds=wd,cycle_len=4,use_clr=(20,8))</pre><pre name="218c" id="218c" class="graf graf--pre graf-after--pre">epoch      trn_loss   val_loss   &lt;lambda&gt;   dice                 <br>    0      0.004169   0.004962   0.998049   0.995517  <br>    1      0.004022   0.004595   0.99823    0.995818             <br>    2      0.003772   0.004497   0.998215   0.995916             <br>    3      0.003618   0.004435   0.998291   0.995991</pre><pre name="ce73" id="ce73" class="graf graf--pre graf-after--pre">[0.004434524739663753, 0.9982911745707194, 0.9959913929776539]</pre><p name="0c5e" id="0c5e" class="graf graf--p graf-after--pre">Unfreeze takes us to… we’ll call that&nbsp;.996.</p><pre name="4fb8" id="4fb8" class="graf graf--pre graf-after--p">learn.sched.plot_loss()</pre><figure name="b088" id="b088" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_b7J9qrMQ0OxTQgj0QebeFw.png"></figure><pre name="9f1f" id="9f1f" class="graf graf--pre graf-after--figure">learn.save('1024urn')</pre><pre name="fc36" id="fc36" class="graf graf--pre graf-after--pre">learn.load('1024urn')</pre><pre name="a16e" id="a16e" class="graf graf--pre graf-after--pre">x,y = next(iter(md.val_dl))<br>py = to_np(learn.model(V(x)))</pre><p name="1907" id="1907" class="graf graf--p graf-after--pre">As you can see, that actually looks good [<a href="https://youtu.be/nG3tT31nPmQ?t=1h57m17s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h57m17s" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">1:57:17</a>]. In accuracy terms, 99.82%. You can see this is looking like something you could just about use to cut out. I think, at this point, there’s a couple of minor tweaks we can do to get up to&nbsp;.997 but really the key thing then, I think, is just maybe to do a few bit of smoothing maybe or a little bit of post-processing. You can go and have a look at the Carvana winners’ blogs and see some of these tricks, but as I say, the difference between where we are at&nbsp;.996 and what the winners got of&nbsp;.997, it’s not heaps. So really that just the Unet on its own pretty much solves that problem.</p><pre name="5f52" id="5f52" class="graf graf--pre graf-after--p">show_img(py[0]&gt;0);</pre><figure name="4412" id="4412" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_A6ghUxP4m0OMKyUZWnv3xQ.png"></figure><pre name="0b0d" id="0b0d" class="graf graf--pre graf-after--figure">show_img(y[0]);</pre><figure name="04ec" id="04ec" class="graf graf--figure graf-after--pre"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="../img/1_1eNTc9dNtmuxTryHf1XGpA.png"></figure><h3 name="2ea9" id="2ea9" class="graf graf--h3 graf-after--figure">Back to Bounding Box [<a href="https://youtu.be/nG3tT31nPmQ?t=1h58m15s" data-href="https://youtu.be/nG3tT31nPmQ?t=1h58m15s" class="markup--anchor markup--h3-anchor" rel="nofollow noopener" target="_blank">1:58:15</a>]</h3><p name="8276" id="8276" class="graf graf--p graf-after--h3">Okay, so that’s it. The last thing I wanted to mention is now to come all the way back to bounding boxes because you might remember, I said our bounding box model was still not doing very well on small objects. So hopefully you might be able to guess where I’m going to go with this which is that for the bounding box model, remember how we had at different grid cells we spat out outputs of the model. And it was those earlier ones with the small grid sizes that weren’t very good. How do we fix it? U-Net it! Let’s have an upward path with cross connections. So then we are just going to do a U-Net and then spit them out of that. Because now those finer grid cells have all of the information of that path, and that path, and that path, and that path for leverage. Now of course, this is deep learning so that means you can’t write a paper saying we just used U-Net for bounding boxes. You have to invent a new word so this is called feature pyramid networks or FPNs. And this was used in RetinaNet paper, it was created in an earlier paper specifically about FPNs. And if memory serves correctly, they did briefly cite the U-Net paper but they kind of made it sound like it was this vaguely slightly connected thing that maybe some people could consider slightly useful. But really, FPNs are U-Nets.</p><p name="7521" id="7521" class="graf graf--p graf-after--p">I don’t have an implementation of it to show you but it will be a fun thing, maybe for some of us to try and I know some of the students have been trying to get it working well on the forums. So yeah, interesting thing to try. So I think a couple of things to look at after this class as well as the other things I mentioned would be playing around with FPNs and also maybe trying Kerem’s DynamicUnet. They would both be interesting things to look at.</p><p name="bdf8" id="bdf8" class="graf graf--p graf-after--p graf--trailing">So you guys have all been through 14 lessons of me talking at you now. So I’m sorry about that. Thanks for putting up with me. I think you’re going to find it hard to find people who actually know them as much about training neural networks and practice as you do. It’ll be really easy for you to overestimate how capable all these other people are and underestimate how capable you are. So the main thing I’d say is, please practice, please. Just because you don’t have this constant thing getting you to come back here every Monday night now. It’s very easy to kind of lose that momentum. So find ways to keep it. Organize a study group, a book reading group, or get together with some friends and work on a project, or do something more than just deciding I want to keep working on X. Unless you are kind of person who’s super motivated and whenever you decide to do something, it happens. That’s not me. It’s like I know, for something to happen, I have to say “yes, David. In October, I will absolutely teach that course” and then it’s like okay I better actually write some material. That’s the only way I can get stuff to happen. So we’ve got a great community there on the forums. If people have ideas for ways to make it better, please tell me. If you think you can help with, if you want to create some new forum or moderated in some different way or whatever, just let me know. You can always PM me and there’s a lot of projects going on through GitHub as well — lots of stuff. So I hope to see you all back here at something else and thanks so much for joining me on this journey.</p><hr class="section-divider"><p name="dcdd" id="dcdd" class="graf graf--p graf--leading graf--trailing">Lessons: <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-1-602f73869197" class="markup--anchor markup--p-anchor" target="_blank">1</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-2-eeae2edd2be4" class="markup--anchor markup--p-anchor" target="_blank">2</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56" class="markup--anchor markup--p-anchor" target="_blank">3</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-4-2048a26d58aa" class="markup--anchor markup--p-anchor" target="_blank">4</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-5-dd904506bee8" class="markup--anchor markup--p-anchor" target="_blank">5</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-6-de70d626976c" class="markup--anchor markup--p-anchor" target="_blank">6</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-7-1b9503aff0c" class="markup--anchor markup--p-anchor" target="_blank">7</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-8-5ae195c49493" class="markup--anchor markup--p-anchor" target="_blank">8</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-9-5f0cf9e4bb5b" class="markup--anchor markup--p-anchor" target="_blank">9</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-10-422d87c3340c" class="markup--anchor markup--p-anchor" target="_blank">10</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-11-61477d24dc34" class="markup--anchor markup--p-anchor" target="_blank">11</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-12-215dfbf04a94" class="markup--anchor markup--p-anchor" target="_blank">12</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-13-43454b21a5d0" class="markup--anchor markup--p-anchor" target="_blank">13</a> ・ <a href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" data-href="https://medium.com/@hiromi_suenaga/deep-learning-2-part-2-lesson-14-e0d23c7a0add" class="markup--anchor markup--p-anchor" target="_blank"><strong class="markup--strong markup--p-strong">14</strong></a></p></body></html>